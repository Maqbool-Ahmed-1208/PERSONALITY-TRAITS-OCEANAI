{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"mount_file_id":"10Fr53d0Tz0uvQlfzxk1PuUyOfir_SvpQ","authorship_tag":"ABX9TyM8JMIqoAQIdnT6xgC3kRSr"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11600280,"sourceType":"datasetVersion","datasetId":7264479},{"sourceId":11671870,"sourceType":"datasetVersion","datasetId":7316563}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport torch.optim as optim\n","metadata":{"id":"3z_btQb0jNk-","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:25:15.036212Z","iopub.execute_input":"2025-05-06T12:25:15.036436Z","iopub.status.idle":"2025-05-06T12:25:21.458347Z","shell.execute_reply.started":"2025-05-06T12:25:15.036408Z","shell.execute_reply":"2025-05-06T12:25:21.457524Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# **Video HC Traits**","metadata":{}},{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split, KFold\nimport torch.optim as optim\nfrom sklearn.preprocessing import StandardScaler\n\n# Load video dataset\ndf = pd.read_csv('/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/video_hc_features.csv')\n\n# Drop unnecessary columns\ndrop_cols = [\"Filename\", \"Segment_ID\", \"interview\", \"Gender\", \"Ethnicity\", \"AgeGroup\"]\ndf.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True, errors='ignore')\n\n# Define label columns\nlabel_columns = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n\n# Separate features and labels\nX = df.drop(columns=label_columns)\ny = df[label_columns]\n\n# Keep only numeric columns\nX = X.select_dtypes(include=[np.number])\n\n# Fill missing values\nX = X.fillna(X.mean())\ny = y.fillna(y.mean())\n\n# Normalize features\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n# Convert to tensors\nX_tensor = torch.tensor(X.values, dtype=torch.float32)\ny_tensors = {trait: torch.tensor(y[trait].values, dtype=torch.float32) for trait in label_columns}\n\n# Dataset class\nclass VideoDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\nclass SimpleTransformerRegressor(nn.Module):\n    \"\"\"\n    Simple Transformer Regressor using batch_first=True convention.\n    Takes tabular features, projects them, passes through a Transformer Encoder,\n    and predicts a single regression value.\n    \"\"\"\n    def __init__(self, input_dim, embed_dim=256, num_heads=4, num_layers=2, dropout=0.3, ff_dim_multiplier=4):\n        \"\"\"\n        Args:\n            input_dim (int): Number of input features.\n            embed_dim (int): Dimension for projecting features and for the Transformer. Must be divisible by num_heads.\n            num_heads (int): Number of attention heads in the Transformer.\n            num_layers (int): Number of layers in the Transformer Encoder.\n            dropout (float): Dropout rate.\n            ff_dim_multiplier (int): Multiplier for the feed-forward layer dimension within the Transformer.\n        \"\"\"\n        super(SimpleTransformerRegressor, self).__init__()\n\n        # Ensure embed_dim is divisible by num_heads\n        if embed_dim % num_heads != 0:\n            # Adjust embed_dim up to the nearest multiple of num_heads\n            original_embed_dim = embed_dim\n            embed_dim = (embed_dim // num_heads + 1) * num_heads\n            print(f\"Warning: embed_dim ({original_embed_dim}) not divisible by num_heads ({num_heads}).\")\n            print(f\"Adjusted embed_dim to {embed_dim}.\")\n\n        self.input_dim = input_dim\n        self.embed_dim = embed_dim\n\n        # Project input features to embedding dimension\n        self.project = nn.Linear(input_dim, embed_dim)\n\n        # Define the Transformer Encoder Layer with batch_first=True\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim,\n            nhead=num_heads,\n            dim_feedforward=embed_dim * ff_dim_multiplier, # Standard practice\n            dropout=dropout,\n            batch_first=True  # <<< Input tensor shape: (batch, seq_len, features)\n        )\n\n        # Stack the encoder layers\n        self.encoder = nn.TransformerEncoder(\n            encoder_layer=encoder_layer,\n            num_layers=num_layers\n        )\n\n        # Classifier head\n        self.classifier = nn.Sequential(\n            nn.LayerNorm(embed_dim),      # Add LayerNorm for stability before classifier\n            nn.Linear(embed_dim, 128),    # Linear layer 1\n            nn.ReLU(),                    # Activation\n            nn.Dropout(dropout),          # Dropout\n            nn.Linear(128, 1)             # Final output layer (regression target)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass.\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_dim).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size).\n        \"\"\"\n        # 1. Project features\n        # x shape: (batch_size, input_dim)\n        x = self.project(x)\n        # x shape: (batch_size, embed_dim)\n\n        # 2. Add sequence dimension for Transformer\n        # TransformerEncoderLayer with batch_first=True expects (batch, seq_len, features)\n        x = x.unsqueeze(1)\n        # x shape: (batch_size, seq_len=1, embed_dim)\n\n        # 3. Pass through Transformer Encoder\n        x = self.encoder(x)\n        # x shape: (batch_size, seq_len=1, embed_dim)\n\n        # 4. Remove sequence dimension\n        x = x.squeeze(1)\n        # x shape: (batch_size, embed_dim)\n\n        # 5. Pass through classifier\n        output = self.classifier(x)\n        # output shape: (batch_size, 1)\n\n        # 6. Squeeze final dimension for regression output\n        return output.squeeze(-1)\n        # final shape: (batch_size)\n\n# Metrics\ndef mean_absolute_error(preds, labels):\n    return torch.mean(torch.abs(preds - labels)).item()\n\ndef concordance_correlation_coefficient(preds, labels):\n    preds_mean = torch.mean(preds)\n    labels_mean = torch.mean(labels)\n    preds_var = torch.var(preds)\n    labels_var = torch.var(labels)\n    covariance = torch.mean((preds - preds_mean) * (labels - labels_mean))\n    ccc = (2 * covariance) / (preds_var + labels_var + (preds_mean - labels_mean) ** 2)\n    return ccc.item()\n\n# Training helpers\ndef train_one_epoch(model, loader, optimizer, scheduler, criterion, device):\n    model.train()\n    total_loss = 0\n    for X_batch, y_batch in loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        preds = model(X_batch)\n        loss = criterion(preds, y_batch)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    scheduler.step()\n    return total_loss / len(loader)\n\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    total_loss, total_mae, total_ccc = 0, 0, 0\n    with torch.no_grad():\n        for X_batch, y_batch in loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            preds = model(X_batch)\n            loss = criterion(preds, y_batch)\n            total_loss += loss.item()\n            total_mae += mean_absolute_error(preds, y_batch)\n            total_ccc += concordance_correlation_coefficient(preds, y_batch)\n    n_batches = len(loader)\n    return total_loss/n_batches, total_mae/n_batches, total_ccc/n_batches\n\ndef generate_random_configs(search_space, num_configs=10):\n    configs = []\n    for _ in range(num_configs):\n        config = {\n            \"embed_dim\": np.random.choice(search_space[\"embed_dim\"]),\n            \"num_heads\": np.random.choice(search_space[\"num_heads\"]),\n            \"num_layers\": np.random.choice(search_space[\"num_layers\"]),\n            \"dropout\": np.random.choice(search_space[\"dropout\"]),\n            \"lr\": np.random.choice(search_space[\"lr\"]),\n            \"batch_size\": np.random.choice(search_space[\"batch_size\"]),\n            \"weight_decay\": np.random.choice(search_space[\"weight_decay\"])\n        }\n        configs.append(config)\n    return configs\n\ndef cross_validate(config, X_tensor, y_tensor, num_folds=3, epochs=10):\n    print(f\"Evaluating Config: {config}\")\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n    fold_metrics = {\"val_ccc\": [], \"val_mae\": [], \"val_loss\": []}\n\n    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_tensor)):\n        print(f\"  Fold {fold+1}/{num_folds}\")\n        X_train_fold, y_train_fold = X_tensor[train_idx], y_tensor[train_idx]\n        X_val_fold, y_val_fold = X_tensor[val_idx], y_tensor[val_idx]\n\n        train_loader = DataLoader(VideoDataset(X_train_fold, y_train_fold), batch_size=int(config[\"batch_size\"]), shuffle=True)\n        val_loader = DataLoader(VideoDataset(X_val_fold, y_val_fold), batch_size=int(config[\"batch_size\"]), shuffle=False)\n\n        model = SimpleTransformerRegressor(\n            input_dim=X_tensor.shape[1],\n            embed_dim=config[\"embed_dim\"],\n            num_heads=config[\"num_heads\"],\n            num_layers=config[\"num_layers\"],\n            dropout=config[\"dropout\"]\n        ).to(device)\n\n        optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n        criterion = nn.MSELoss()\n\n        best_ccc = -1\n        for epoch in range(epochs):\n            train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, device)\n            val_loss, val_mae, val_ccc = evaluate(model, val_loader, criterion, device)\n            print(f\"    Epoch {epoch+1}/{epochs} | Val CCC: {val_ccc:.4f}, MAE: {val_mae:.4f}\")\n            if val_ccc > best_ccc:\n                best_ccc = val_ccc\n                best_metrics = (val_loss, val_mae, val_ccc)\n\n        fold_metrics[\"val_loss\"].append(best_metrics[0])\n        fold_metrics[\"val_mae\"].append(best_metrics[1])\n        fold_metrics[\"val_ccc\"].append(best_metrics[2])\n\n    return {\n        \"ccc\": np.mean(fold_metrics[\"val_ccc\"]),\n        \"mae\": np.mean(fold_metrics[\"val_mae\"]),\n        \"loss\": np.mean(fold_metrics[\"val_loss\"])\n    }\n\ndef hyperparameter_tuning(X_tensor, y_tensor, num_configs=10):\n    search_space = {\n        \"embed_dim\": [128, 256, 512],\n        \"num_heads\": [2, 4, 8],\n        \"num_layers\": [2, 4],\n        \"dropout\": [0.1, 0.3, 0.5],\n        \"lr\": [1e-4, 3e-4, 1e-3],\n        \"batch_size\": [32, 64],\n        \"weight_decay\": [1e-5, 1e-4]\n    }\n    configs = generate_random_configs(search_space, num_configs)\n    best_config = None\n    best_ccc = -1\n\n    for i, config in enumerate(configs):\n        print(f\"\\n>>> Config {i+1}/{num_configs}\")\n        metrics = cross_validate(config, X_tensor, y_tensor)\n        print(f\"  Avg CCC: {metrics['ccc']:.4f}, MAE: {metrics['mae']:.4f}\")\n        if metrics[\"ccc\"] > best_ccc:\n            best_ccc = metrics[\"ccc\"]\n            best_config = config\n\n    print(f\"\\n>>> Best Config Selected: {best_config}\")\n    return best_config\n\ndef final_train_and_evaluate(best_config, X_train, y_train, X_val, y_val, X_test, y_test, trait_name, epochs=10):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    X_final_train = torch.cat([X_train, X_val], dim=0)\n    y_final_train = torch.cat([y_train, y_val], dim=0)\n\n    final_train_loader = DataLoader(VideoDataset(X_final_train, y_final_train), batch_size=int(best_config[\"batch_size\"]), shuffle=True)\n    test_loader = DataLoader(VideoDataset(X_test, y_test), batch_size=int(best_config[\"batch_size\"]), shuffle=False)\n\n    model = SimpleTransformerRegressor(\n        input_dim=X_train.shape[1],\n        embed_dim=best_config[\"embed_dim\"],\n        num_heads=best_config[\"num_heads\"],\n        num_layers=best_config[\"num_layers\"],\n        dropout=best_config[\"dropout\"]\n    ).to(device)\n\n    optimizer = optim.AdamW(model.parameters(), lr=best_config[\"lr\"], weight_decay=best_config[\"weight_decay\"])\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n    criterion = nn.MSELoss()\n\n    print(f\"\\n>>> Final Training for {trait_name.upper()} ({epochs} epochs)\")\n    for epoch in range(epochs):\n        train_loss = train_one_epoch(model, final_train_loader, optimizer, scheduler, criterion, device)\n        print(f\"  Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}\")\n\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for X_batch, y_batch in test_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            preds = model(X_batch)\n            all_preds.append(preds)\n            all_labels.append(y_batch)\n\n    all_preds = torch.cat(all_preds, dim=0)\n    all_labels = torch.cat(all_labels, dim=0)\n\n    final_mae = mean_absolute_error(all_preds, all_labels)\n    final_ccc = concordance_correlation_coefficient(all_preds, all_labels)\n    tolerance = 0.1\n    correct = torch.abs(all_preds - all_labels) < tolerance\n    final_accuracy = correct.float().mean().item()\n\n    print(f\"\\n==== {trait_name.upper()} Evaluation on Test Set ====\")\n    print(f\"Test CCC: {final_ccc:.4f}, Test MAE: {final_mae:.4f}, Accuracy (±{tolerance}): {final_accuracy*100:.2f}%\")\n    torch.save(model.state_dict(), f\"best_video_transformer_model_{trait_name}.pth\")\n    model_save_path = f\"best_video_transformer_model_{trait_name}.pth\"\n    print(f\"Saving final model for {trait_name} to {model_save_path}\")\n    torch.save({\n        'epoch': epochs,\n        'model_state_dict': model.state_dict(), # <<< Weights nested here\n        'optimizer_state_dict': optimizer.state_dict(),\n        'best_config': best_config,           # <<< Config needed\n        'scaler_mean': scaler.mean_,         # <<< Scaler mean needed\n        'scaler_scale': scaler.scale_,         # <<< Scaler scale needed\n        'test_metrics': {'ccc': final_ccc, 'mae': final_mae, f'acc_{tolerance}': final_accuracy}\n    }, model_save_path)\n    \n# Train model per trait\nfor trait in label_columns:\n    print(f\"\\n--- Training for Trait: {trait} ---\")\n    y_trait = y_tensors[trait]\n    train_idx, temp_idx = train_test_split(range(len(X)), test_size=0.3, random_state=42)\n    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n\n    X_train, y_train = X_tensor[train_idx], y_trait[train_idx]\n    X_val, y_val = X_tensor[val_idx], y_trait[val_idx]\n    X_test, y_test = X_tensor[test_idx], y_trait[test_idx]\n\n    best_config = hyperparameter_tuning(X_tensor, y_trait, num_configs=10)\n    final_train_and_evaluate(best_config, X_train, y_train, X_val, y_val, X_test, y_test, trait_name=trait)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:29:38.763697Z","iopub.execute_input":"2025-05-05T15:29:38.764504Z","iopub.status.idle":"2025-05-05T18:21:47.274523Z","shell.execute_reply.started":"2025-05-05T15:29:38.764479Z","shell.execute_reply":"2025-05-05T18:21:47.273748Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/282328445.py:13: DtypeWarning: Columns (0,944) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv('/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/video_hc_features.csv')\n","output_type":"stream"},{"name":"stdout","text":"\n--- Training for Trait: openness ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0609, MAE: 0.1146\n    Epoch 2/10 | Val CCC: 0.1013, MAE: 0.1118\n    Epoch 3/10 | Val CCC: 0.1038, MAE: 0.1131\n    Epoch 4/10 | Val CCC: 0.1826, MAE: 0.1105\n    Epoch 5/10 | Val CCC: 0.1556, MAE: 0.1096\n    Epoch 6/10 | Val CCC: 0.2075, MAE: 0.1106\n    Epoch 7/10 | Val CCC: 0.1374, MAE: 0.1103\n    Epoch 8/10 | Val CCC: 0.1616, MAE: 0.1100\n    Epoch 9/10 | Val CCC: 0.2003, MAE: 0.1089\n    Epoch 10/10 | Val CCC: 0.1774, MAE: 0.1123\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0534, MAE: 0.1143\n    Epoch 2/10 | Val CCC: 0.0893, MAE: 0.1136\n    Epoch 3/10 | Val CCC: 0.1224, MAE: 0.1131\n    Epoch 4/10 | Val CCC: 0.0812, MAE: 0.1146\n    Epoch 5/10 | Val CCC: 0.1639, MAE: 0.1104\n    Epoch 6/10 | Val CCC: 0.1622, MAE: 0.1123\n    Epoch 7/10 | Val CCC: 0.1674, MAE: 0.1103\n    Epoch 8/10 | Val CCC: 0.1652, MAE: 0.1112\n    Epoch 9/10 | Val CCC: 0.1323, MAE: 0.1115\n    Epoch 10/10 | Val CCC: 0.1716, MAE: 0.1098\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0522, MAE: 0.1158\n    Epoch 2/10 | Val CCC: 0.0664, MAE: 0.1171\n    Epoch 3/10 | Val CCC: 0.0894, MAE: 0.1134\n    Epoch 4/10 | Val CCC: 0.1313, MAE: 0.1175\n    Epoch 5/10 | Val CCC: 0.1644, MAE: 0.1125\n    Epoch 6/10 | Val CCC: 0.1874, MAE: 0.1100\n    Epoch 7/10 | Val CCC: 0.0986, MAE: 0.1133\n    Epoch 8/10 | Val CCC: 0.1819, MAE: 0.1109\n    Epoch 9/10 | Val CCC: 0.1693, MAE: 0.1099\n    Epoch 10/10 | Val CCC: 0.1335, MAE: 0.1106\n  Avg CCC: 0.1888, MAE: 0.1101\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0102, MAE: 0.1236\n    Epoch 2/10 | Val CCC: 0.0129, MAE: 0.1154\n    Epoch 3/10 | Val CCC: 0.0336, MAE: 0.1162\n    Epoch 4/10 | Val CCC: 0.0001, MAE: 0.1170\n    Epoch 5/10 | Val CCC: 0.0000, MAE: 0.1159\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1161\n    Epoch 7/10 | Val CCC: -0.0000, MAE: 0.1159\n    Epoch 8/10 | Val CCC: -0.0000, MAE: 0.1160\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1160\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1159\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0166, MAE: 0.1179\n    Epoch 2/10 | Val CCC: 0.0235, MAE: 0.1177\n    Epoch 3/10 | Val CCC: 0.0020, MAE: 0.1171\n    Epoch 4/10 | Val CCC: 0.0041, MAE: 0.1166\n    Epoch 5/10 | Val CCC: 0.0119, MAE: 0.1173\n    Epoch 6/10 | Val CCC: 0.0113, MAE: 0.1170\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1168\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1163\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1166\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1164\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0096, MAE: 0.1159\n    Epoch 2/10 | Val CCC: 0.0237, MAE: 0.1171\n    Epoch 3/10 | Val CCC: 0.0239, MAE: 0.1181\n    Epoch 4/10 | Val CCC: 0.0097, MAE: 0.1175\n    Epoch 5/10 | Val CCC: 0.0262, MAE: 0.1189\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1177\n    Epoch 7/10 | Val CCC: -0.0000, MAE: 0.1166\n    Epoch 8/10 | Val CCC: -0.0000, MAE: 0.1165\n    Epoch 9/10 | Val CCC: -0.0000, MAE: 0.1165\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1164\n  Avg CCC: 0.0278, MAE: 0.1176\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0267, MAE: 0.1148\n    Epoch 2/10 | Val CCC: 0.0372, MAE: 0.1295\n    Epoch 3/10 | Val CCC: 0.1000, MAE: 0.1170\n    Epoch 4/10 | Val CCC: 0.1162, MAE: 0.1144\n    Epoch 5/10 | Val CCC: 0.1470, MAE: 0.1219\n    Epoch 6/10 | Val CCC: 0.1388, MAE: 0.1119\n    Epoch 7/10 | Val CCC: 0.1044, MAE: 0.1130\n    Epoch 8/10 | Val CCC: 0.1743, MAE: 0.1121\n    Epoch 9/10 | Val CCC: 0.1590, MAE: 0.1127\n    Epoch 10/10 | Val CCC: 0.1107, MAE: 0.1145\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0422, MAE: 0.1210\n    Epoch 2/10 | Val CCC: 0.0966, MAE: 0.1156\n    Epoch 3/10 | Val CCC: 0.1145, MAE: 0.1166\n    Epoch 4/10 | Val CCC: 0.1252, MAE: 0.1189\n    Epoch 5/10 | Val CCC: 0.0964, MAE: 0.1193\n    Epoch 6/10 | Val CCC: 0.1551, MAE: 0.1151\n    Epoch 7/10 | Val CCC: 0.1434, MAE: 0.1145\n    Epoch 8/10 | Val CCC: 0.1751, MAE: 0.1147\n    Epoch 9/10 | Val CCC: 0.1540, MAE: 0.1120\n    Epoch 10/10 | Val CCC: 0.1995, MAE: 0.1112\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0371, MAE: 0.1159\n    Epoch 2/10 | Val CCC: 0.0648, MAE: 0.1277\n    Epoch 3/10 | Val CCC: 0.0927, MAE: 0.1172\n    Epoch 4/10 | Val CCC: 0.0866, MAE: 0.1164\n    Epoch 5/10 | Val CCC: 0.1356, MAE: 0.1169\n    Epoch 6/10 | Val CCC: 0.1579, MAE: 0.1129\n    Epoch 7/10 | Val CCC: 0.1169, MAE: 0.1181\n    Epoch 8/10 | Val CCC: 0.1429, MAE: 0.1136\n    Epoch 9/10 | Val CCC: 0.1307, MAE: 0.1156\n    Epoch 10/10 | Val CCC: 0.1679, MAE: 0.1105\n  Avg CCC: 0.1806, MAE: 0.1113\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0313, MAE: 0.1154\n    Epoch 2/10 | Val CCC: 0.1054, MAE: 0.1160\n    Epoch 3/10 | Val CCC: 0.0835, MAE: 0.1161\n    Epoch 4/10 | Val CCC: 0.1478, MAE: 0.1120\n    Epoch 5/10 | Val CCC: 0.1383, MAE: 0.1146\n    Epoch 6/10 | Val CCC: 0.1670, MAE: 0.1098\n    Epoch 7/10 | Val CCC: 0.1580, MAE: 0.1104\n    Epoch 8/10 | Val CCC: 0.1418, MAE: 0.1174\n    Epoch 9/10 | Val CCC: 0.1413, MAE: 0.1101\n    Epoch 10/10 | Val CCC: 0.1762, MAE: 0.1179\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0602, MAE: 0.1144\n    Epoch 2/10 | Val CCC: 0.0911, MAE: 0.1141\n    Epoch 3/10 | Val CCC: 0.1461, MAE: 0.1119\n    Epoch 4/10 | Val CCC: 0.1384, MAE: 0.1108\n    Epoch 5/10 | Val CCC: 0.1362, MAE: 0.1111\n    Epoch 6/10 | Val CCC: 0.1324, MAE: 0.1130\n    Epoch 7/10 | Val CCC: 0.1211, MAE: 0.1125\n    Epoch 8/10 | Val CCC: 0.1888, MAE: 0.1106\n    Epoch 9/10 | Val CCC: 0.1594, MAE: 0.1097\n    Epoch 10/10 | Val CCC: 0.1768, MAE: 0.1102\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0461, MAE: 0.1170\n    Epoch 2/10 | Val CCC: 0.0961, MAE: 0.1151\n    Epoch 3/10 | Val CCC: 0.1173, MAE: 0.1139\n    Epoch 4/10 | Val CCC: 0.1301, MAE: 0.1120\n    Epoch 5/10 | Val CCC: 0.1423, MAE: 0.1107\n    Epoch 6/10 | Val CCC: 0.1373, MAE: 0.1103\n    Epoch 7/10 | Val CCC: 0.1689, MAE: 0.1116\n    Epoch 8/10 | Val CCC: 0.1774, MAE: 0.1103\n    Epoch 9/10 | Val CCC: 0.1901, MAE: 0.1093\n    Epoch 10/10 | Val CCC: 0.1989, MAE: 0.1155\n  Avg CCC: 0.1880, MAE: 0.1147\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1043, MAE: 0.1211\n    Epoch 2/10 | Val CCC: 0.0600, MAE: 0.1463\n    Epoch 3/10 | Val CCC: 0.0637, MAE: 0.1352\n    Epoch 4/10 | Val CCC: 0.0719, MAE: 0.1365\n    Epoch 5/10 | Val CCC: 0.0974, MAE: 0.1341\n    Epoch 6/10 | Val CCC: 0.1051, MAE: 0.1319\n    Epoch 7/10 | Val CCC: 0.1432, MAE: 0.1280\n    Epoch 8/10 | Val CCC: 0.1217, MAE: 0.1358\n    Epoch 9/10 | Val CCC: 0.1282, MAE: 0.1380\n    Epoch 10/10 | Val CCC: 0.1563, MAE: 0.1338\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0511, MAE: 0.1171\n    Epoch 2/10 | Val CCC: 0.0693, MAE: 0.1173\n    Epoch 3/10 | Val CCC: 0.0782, MAE: 0.1265\n    Epoch 4/10 | Val CCC: 0.0818, MAE: 0.1249\n    Epoch 5/10 | Val CCC: 0.1028, MAE: 0.1265\n    Epoch 6/10 | Val CCC: 0.0880, MAE: 0.1372\n    Epoch 7/10 | Val CCC: 0.1354, MAE: 0.1288\n    Epoch 8/10 | Val CCC: 0.1441, MAE: 0.1288\n    Epoch 9/10 | Val CCC: 0.1492, MAE: 0.1252\n    Epoch 10/10 | Val CCC: 0.1507, MAE: 0.1267\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0826, MAE: 0.1185\n    Epoch 2/10 | Val CCC: 0.0741, MAE: 0.1167\n    Epoch 3/10 | Val CCC: 0.0841, MAE: 0.1235\n    Epoch 4/10 | Val CCC: 0.0944, MAE: 0.1226\n    Epoch 5/10 | Val CCC: 0.1007, MAE: 0.1289\n    Epoch 6/10 | Val CCC: 0.1005, MAE: 0.1364\n    Epoch 7/10 | Val CCC: 0.1105, MAE: 0.1335\n    Epoch 8/10 | Val CCC: 0.1326, MAE: 0.1226\n    Epoch 9/10 | Val CCC: 0.1765, MAE: 0.1250\n    Epoch 10/10 | Val CCC: 0.1626, MAE: 0.1236\n  Avg CCC: 0.1612, MAE: 0.1285\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0801, MAE: 0.1150\n    Epoch 2/10 | Val CCC: 0.0778, MAE: 0.1159\n    Epoch 3/10 | Val CCC: 0.0726, MAE: 0.1144\n    Epoch 4/10 | Val CCC: 0.0950, MAE: 0.1207\n    Epoch 5/10 | Val CCC: 0.1098, MAE: 0.1188\n    Epoch 6/10 | Val CCC: 0.1213, MAE: 0.1185\n    Epoch 7/10 | Val CCC: 0.1219, MAE: 0.1201\n    Epoch 8/10 | Val CCC: 0.1615, MAE: 0.1155\n    Epoch 9/10 | Val CCC: 0.1872, MAE: 0.1118\n    Epoch 10/10 | Val CCC: 0.1707, MAE: 0.1180\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0557, MAE: 0.1147\n    Epoch 2/10 | Val CCC: 0.0593, MAE: 0.1173\n    Epoch 3/10 | Val CCC: 0.0664, MAE: 0.1183\n    Epoch 4/10 | Val CCC: 0.0862, MAE: 0.1162\n    Epoch 5/10 | Val CCC: 0.0894, MAE: 0.1212\n    Epoch 6/10 | Val CCC: 0.1143, MAE: 0.1188\n    Epoch 7/10 | Val CCC: 0.1297, MAE: 0.1175\n    Epoch 8/10 | Val CCC: 0.1313, MAE: 0.1210\n    Epoch 9/10 | Val CCC: 0.1336, MAE: 0.1207\n    Epoch 10/10 | Val CCC: 0.1812, MAE: 0.1118\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0473, MAE: 0.1155\n    Epoch 2/10 | Val CCC: 0.0750, MAE: 0.1156\n    Epoch 3/10 | Val CCC: 0.0685, MAE: 0.1151\n    Epoch 4/10 | Val CCC: 0.1007, MAE: 0.1144\n    Epoch 5/10 | Val CCC: 0.1147, MAE: 0.1181\n    Epoch 6/10 | Val CCC: 0.1218, MAE: 0.1159\n    Epoch 7/10 | Val CCC: 0.1564, MAE: 0.1134\n    Epoch 8/10 | Val CCC: 0.1572, MAE: 0.1127\n    Epoch 9/10 | Val CCC: 0.1740, MAE: 0.1129\n    Epoch 10/10 | Val CCC: 0.1820, MAE: 0.1130\n  Avg CCC: 0.1835, MAE: 0.1122\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0462, MAE: 0.1162\n    Epoch 2/10 | Val CCC: 0.0637, MAE: 0.1139\n    Epoch 3/10 | Val CCC: 0.1349, MAE: 0.1140\n    Epoch 4/10 | Val CCC: 0.1062, MAE: 0.1168\n    Epoch 5/10 | Val CCC: 0.1422, MAE: 0.1110\n    Epoch 6/10 | Val CCC: 0.1609, MAE: 0.1145\n    Epoch 7/10 | Val CCC: 0.1515, MAE: 0.1112\n    Epoch 8/10 | Val CCC: 0.2036, MAE: 0.1119\n    Epoch 9/10 | Val CCC: 0.1826, MAE: 0.1162\n    Epoch 10/10 | Val CCC: 0.2080, MAE: 0.1109\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0586, MAE: 0.1151\n    Epoch 2/10 | Val CCC: 0.0821, MAE: 0.1132\n    Epoch 3/10 | Val CCC: 0.0839, MAE: 0.1170\n    Epoch 4/10 | Val CCC: 0.1201, MAE: 0.1156\n    Epoch 5/10 | Val CCC: 0.1140, MAE: 0.1150\n    Epoch 6/10 | Val CCC: 0.1835, MAE: 0.1114\n    Epoch 7/10 | Val CCC: 0.1389, MAE: 0.1130\n    Epoch 8/10 | Val CCC: 0.1649, MAE: 0.1103\n    Epoch 9/10 | Val CCC: 0.2040, MAE: 0.1099\n    Epoch 10/10 | Val CCC: 0.1684, MAE: 0.1114\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0299, MAE: 0.1162\n    Epoch 2/10 | Val CCC: 0.0523, MAE: 0.1156\n    Epoch 3/10 | Val CCC: 0.0742, MAE: 0.1187\n    Epoch 4/10 | Val CCC: 0.1067, MAE: 0.1173\n    Epoch 5/10 | Val CCC: 0.1522, MAE: 0.1122\n    Epoch 6/10 | Val CCC: 0.1557, MAE: 0.1127\n    Epoch 7/10 | Val CCC: 0.1523, MAE: 0.1131\n    Epoch 8/10 | Val CCC: 0.1718, MAE: 0.1114\n    Epoch 9/10 | Val CCC: 0.2385, MAE: 0.1111\n    Epoch 10/10 | Val CCC: 0.1289, MAE: 0.1137\n  Avg CCC: 0.2168, MAE: 0.1106\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0302, MAE: 0.1181\n    Epoch 2/10 | Val CCC: 0.0795, MAE: 0.1155\n    Epoch 3/10 | Val CCC: 0.0704, MAE: 0.1197\n    Epoch 4/10 | Val CCC: 0.1436, MAE: 0.1131\n    Epoch 5/10 | Val CCC: 0.1319, MAE: 0.1118\n    Epoch 6/10 | Val CCC: 0.0278, MAE: 0.1202\n    Epoch 7/10 | Val CCC: 0.0292, MAE: 0.1164\n    Epoch 8/10 | Val CCC: 0.0161, MAE: 0.1153\n    Epoch 9/10 | Val CCC: 0.0190, MAE: 0.1192\n    Epoch 10/10 | Val CCC: 0.0156, MAE: 0.1153\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0392, MAE: 0.1195\n    Epoch 2/10 | Val CCC: 0.0261, MAE: 0.1328\n    Epoch 3/10 | Val CCC: 0.0538, MAE: 0.1260\n    Epoch 4/10 | Val CCC: 0.0619, MAE: 0.1211\n    Epoch 5/10 | Val CCC: 0.1029, MAE: 0.1170\n    Epoch 6/10 | Val CCC: 0.1742, MAE: 0.1153\n    Epoch 7/10 | Val CCC: 0.0557, MAE: 0.1149\n    Epoch 8/10 | Val CCC: 0.0361, MAE: 0.1190\n    Epoch 9/10 | Val CCC: 0.1549, MAE: 0.1161\n    Epoch 10/10 | Val CCC: 0.0164, MAE: 0.1166\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0305, MAE: 0.1170\n    Epoch 2/10 | Val CCC: 0.0999, MAE: 0.1172\n    Epoch 3/10 | Val CCC: 0.0839, MAE: 0.1162\n    Epoch 4/10 | Val CCC: 0.0402, MAE: 0.1214\n    Epoch 5/10 | Val CCC: 0.0739, MAE: 0.1180\n    Epoch 6/10 | Val CCC: 0.0271, MAE: 0.1193\n    Epoch 7/10 | Val CCC: 0.0230, MAE: 0.1161\n    Epoch 8/10 | Val CCC: 0.0170, MAE: 0.1160\n    Epoch 9/10 | Val CCC: 0.0065, MAE: 0.1168\n    Epoch 10/10 | Val CCC: 0.0037, MAE: 0.1173\n  Avg CCC: 0.1393, MAE: 0.1152\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0625, MAE: 0.1172\n    Epoch 2/10 | Val CCC: 0.0642, MAE: 0.1200\n    Epoch 3/10 | Val CCC: 0.1156, MAE: 0.1163\n    Epoch 4/10 | Val CCC: 0.1417, MAE: 0.1123\n    Epoch 5/10 | Val CCC: 0.1538, MAE: 0.1151\n    Epoch 6/10 | Val CCC: 0.1523, MAE: 0.1164\n    Epoch 7/10 | Val CCC: 0.1746, MAE: 0.1162\n    Epoch 8/10 | Val CCC: 0.1875, MAE: 0.1106\n    Epoch 9/10 | Val CCC: 0.1830, MAE: 0.1137\n    Epoch 10/10 | Val CCC: 0.1550, MAE: 0.1214\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0409, MAE: 0.1171\n    Epoch 2/10 | Val CCC: 0.0783, MAE: 0.1197\n    Epoch 3/10 | Val CCC: 0.1309, MAE: 0.1135\n    Epoch 4/10 | Val CCC: 0.1205, MAE: 0.1175\n    Epoch 5/10 | Val CCC: 0.1559, MAE: 0.1141\n    Epoch 6/10 | Val CCC: 0.1604, MAE: 0.1142\n    Epoch 7/10 | Val CCC: 0.1764, MAE: 0.1121\n    Epoch 8/10 | Val CCC: 0.1796, MAE: 0.1149\n    Epoch 9/10 | Val CCC: 0.1638, MAE: 0.1108\n    Epoch 10/10 | Val CCC: 0.2164, MAE: 0.1108\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0199, MAE: 0.1199\n    Epoch 2/10 | Val CCC: 0.0719, MAE: 0.1310\n    Epoch 3/10 | Val CCC: 0.1087, MAE: 0.1133\n    Epoch 4/10 | Val CCC: 0.1345, MAE: 0.1168\n    Epoch 5/10 | Val CCC: 0.0972, MAE: 0.1243\n    Epoch 6/10 | Val CCC: 0.1752, MAE: 0.1120\n    Epoch 7/10 | Val CCC: 0.1636, MAE: 0.1114\n    Epoch 8/10 | Val CCC: 0.1581, MAE: 0.1189\n    Epoch 9/10 | Val CCC: 0.1651, MAE: 0.1111\n    Epoch 10/10 | Val CCC: 0.2029, MAE: 0.1171\n  Avg CCC: 0.2023, MAE: 0.1129\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0209, MAE: 0.1154\n    Epoch 2/10 | Val CCC: 0.0099, MAE: 0.1168\n    Epoch 3/10 | Val CCC: -0.0014, MAE: 0.1167\n    Epoch 4/10 | Val CCC: 0.0012, MAE: 0.1161\n    Epoch 5/10 | Val CCC: 0.0004, MAE: 0.1159\n    Epoch 6/10 | Val CCC: -0.0000, MAE: 0.1161\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1162\n    Epoch 8/10 | Val CCC: -0.0000, MAE: 0.1159\n    Epoch 9/10 | Val CCC: -0.0000, MAE: 0.1160\n    Epoch 10/10 | Val CCC: -0.0000, MAE: 0.1160\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0288, MAE: 0.1178\n    Epoch 2/10 | Val CCC: 0.0208, MAE: 0.1166\n    Epoch 3/10 | Val CCC: 0.0401, MAE: 0.1155\n    Epoch 4/10 | Val CCC: 0.0303, MAE: 0.1162\n    Epoch 5/10 | Val CCC: 0.0231, MAE: 0.1157\n    Epoch 6/10 | Val CCC: 0.0185, MAE: 0.1179\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1163\n    Epoch 8/10 | Val CCC: -0.0000, MAE: 0.1176\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1163\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1163\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0364, MAE: 0.1156\n    Epoch 2/10 | Val CCC: 0.0311, MAE: 0.1160\n    Epoch 3/10 | Val CCC: 0.0198, MAE: 0.1164\n    Epoch 4/10 | Val CCC: 0.0216, MAE: 0.1159\n    Epoch 5/10 | Val CCC: 0.0302, MAE: 0.1193\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1167\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1178\n    Epoch 8/10 | Val CCC: -0.0000, MAE: 0.1164\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1164\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1165\n  Avg CCC: 0.0325, MAE: 0.1155\n\n>>> Best Config Selected: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 1e-05}\n\n>>> Final Training for OPENNESS (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0300\n  Epoch 2/10 - Train Loss: 0.0244\n  Epoch 3/10 - Train Loss: 0.0230\n  Epoch 4/10 - Train Loss: 0.0222\n  Epoch 5/10 - Train Loss: 0.0216\n  Epoch 6/10 - Train Loss: 0.0211\n  Epoch 7/10 - Train Loss: 0.0207\n  Epoch 8/10 - Train Loss: 0.0203\n  Epoch 9/10 - Train Loss: 0.0201\n  Epoch 10/10 - Train Loss: 0.0198\n\n==== OPENNESS Evaluation on Test Set ====\nTest CCC: 0.1816, Test MAE: 0.1109, Accuracy (±0.1): 52.63%\nSaving final model for openness to best_video_transformer_model_openness.pth\n\n--- Training for Trait: conscientiousness ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0513, MAE: 0.1240\n    Epoch 2/10 | Val CCC: 0.0835, MAE: 0.1238\n    Epoch 3/10 | Val CCC: 0.0563, MAE: 0.1230\n    Epoch 4/10 | Val CCC: 0.0955, MAE: 0.1220\n    Epoch 5/10 | Val CCC: 0.0915, MAE: 0.1210\n    Epoch 6/10 | Val CCC: 0.0774, MAE: 0.1244\n    Epoch 7/10 | Val CCC: 0.0822, MAE: 0.1226\n    Epoch 8/10 | Val CCC: 0.1135, MAE: 0.1207\n    Epoch 9/10 | Val CCC: 0.1022, MAE: 0.1212\n    Epoch 10/10 | Val CCC: 0.0990, MAE: 0.1207\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0360, MAE: 0.1282\n    Epoch 2/10 | Val CCC: 0.1072, MAE: 0.1214\n    Epoch 3/10 | Val CCC: 0.0869, MAE: 0.1210\n    Epoch 4/10 | Val CCC: 0.0974, MAE: 0.1212\n    Epoch 5/10 | Val CCC: 0.0968, MAE: 0.1211\n    Epoch 6/10 | Val CCC: 0.1023, MAE: 0.1204\n    Epoch 7/10 | Val CCC: 0.0780, MAE: 0.1207\n    Epoch 8/10 | Val CCC: 0.1290, MAE: 0.1194\n    Epoch 9/10 | Val CCC: 0.1134, MAE: 0.1215\n    Epoch 10/10 | Val CCC: 0.1427, MAE: 0.1231\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0361, MAE: 0.1320\n    Epoch 2/10 | Val CCC: 0.0825, MAE: 0.1220\n    Epoch 3/10 | Val CCC: 0.0875, MAE: 0.1223\n    Epoch 4/10 | Val CCC: 0.1138, MAE: 0.1209\n    Epoch 5/10 | Val CCC: 0.1392, MAE: 0.1223\n    Epoch 6/10 | Val CCC: 0.1001, MAE: 0.1258\n    Epoch 7/10 | Val CCC: 0.1118, MAE: 0.1209\n    Epoch 8/10 | Val CCC: 0.0883, MAE: 0.1208\n    Epoch 9/10 | Val CCC: 0.0951, MAE: 0.1207\n    Epoch 10/10 | Val CCC: 0.1022, MAE: 0.1213\n  Avg CCC: 0.1318, MAE: 0.1221\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0497, MAE: 0.1242\n    Epoch 2/10 | Val CCC: 0.0985, MAE: 0.1238\n    Epoch 3/10 | Val CCC: 0.1220, MAE: 0.1236\n    Epoch 4/10 | Val CCC: 0.1507, MAE: 0.1280\n    Epoch 5/10 | Val CCC: 0.1473, MAE: 0.1216\n    Epoch 6/10 | Val CCC: 0.1533, MAE: 0.1226\n    Epoch 7/10 | Val CCC: 0.1758, MAE: 0.1197\n    Epoch 8/10 | Val CCC: 0.1445, MAE: 0.1203\n    Epoch 9/10 | Val CCC: 0.1593, MAE: 0.1210\n    Epoch 10/10 | Val CCC: 0.1672, MAE: 0.1228\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0531, MAE: 0.1237\n    Epoch 2/10 | Val CCC: 0.0800, MAE: 0.1225\n    Epoch 3/10 | Val CCC: 0.0960, MAE: 0.1231\n    Epoch 4/10 | Val CCC: 0.0989, MAE: 0.1314\n    Epoch 5/10 | Val CCC: 0.1258, MAE: 0.1256\n    Epoch 6/10 | Val CCC: 0.1188, MAE: 0.1198\n    Epoch 7/10 | Val CCC: 0.1014, MAE: 0.1302\n    Epoch 8/10 | Val CCC: 0.1607, MAE: 0.1233\n    Epoch 9/10 | Val CCC: 0.1497, MAE: 0.1219\n    Epoch 10/10 | Val CCC: 0.1837, MAE: 0.1195\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0521, MAE: 0.1239\n    Epoch 2/10 | Val CCC: 0.0760, MAE: 0.1227\n    Epoch 3/10 | Val CCC: 0.1090, MAE: 0.1216\n    Epoch 4/10 | Val CCC: 0.1277, MAE: 0.1239\n    Epoch 5/10 | Val CCC: 0.1590, MAE: 0.1226\n    Epoch 6/10 | Val CCC: 0.1523, MAE: 0.1216\n    Epoch 7/10 | Val CCC: 0.1562, MAE: 0.1190\n    Epoch 8/10 | Val CCC: 0.1428, MAE: 0.1190\n    Epoch 9/10 | Val CCC: 0.1819, MAE: 0.1204\n    Epoch 10/10 | Val CCC: 0.1754, MAE: 0.1190\n  Avg CCC: 0.1805, MAE: 0.1199\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0209, MAE: 0.1807\n    Epoch 2/10 | Val CCC: 0.0483, MAE: 0.1347\n    Epoch 3/10 | Val CCC: 0.0201, MAE: 0.1251\n    Epoch 4/10 | Val CCC: 0.0332, MAE: 0.1244\n    Epoch 5/10 | Val CCC: 0.0328, MAE: 0.1245\n    Epoch 6/10 | Val CCC: 0.0175, MAE: 0.1247\n    Epoch 7/10 | Val CCC: 0.0084, MAE: 0.1251\n    Epoch 8/10 | Val CCC: 0.0244, MAE: 0.1248\n    Epoch 9/10 | Val CCC: 0.0106, MAE: 0.1251\n    Epoch 10/10 | Val CCC: 0.0143, MAE: 0.1250\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0270, MAE: 0.1324\n    Epoch 2/10 | Val CCC: 0.0444, MAE: 0.1294\n    Epoch 3/10 | Val CCC: 0.0530, MAE: 0.1233\n    Epoch 4/10 | Val CCC: 0.0478, MAE: 0.1245\n    Epoch 5/10 | Val CCC: 0.0696, MAE: 0.1251\n    Epoch 6/10 | Val CCC: 0.0275, MAE: 0.1239\n    Epoch 7/10 | Val CCC: 0.0386, MAE: 0.1274\n    Epoch 8/10 | Val CCC: 0.0036, MAE: 0.1248\n    Epoch 9/10 | Val CCC: 0.0057, MAE: 0.1246\n    Epoch 10/10 | Val CCC: -0.0000, MAE: 0.1250\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0328, MAE: 0.1385\n    Epoch 2/10 | Val CCC: 0.0568, MAE: 0.1245\n    Epoch 3/10 | Val CCC: 0.0105, MAE: 0.1247\n    Epoch 4/10 | Val CCC: 0.0177, MAE: 0.1244\n    Epoch 5/10 | Val CCC: 0.0181, MAE: 0.1245\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1253\n    Epoch 7/10 | Val CCC: 0.0203, MAE: 0.1244\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1253\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1252\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1254\n  Avg CCC: 0.0582, MAE: 0.1281\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0833, MAE: 0.1224\n    Epoch 2/10 | Val CCC: 0.0992, MAE: 0.1224\n    Epoch 3/10 | Val CCC: 0.1305, MAE: 0.1208\n    Epoch 4/10 | Val CCC: 0.1532, MAE: 0.1201\n    Epoch 5/10 | Val CCC: 0.1733, MAE: 0.1196\n    Epoch 6/10 | Val CCC: 0.1739, MAE: 0.1187\n    Epoch 7/10 | Val CCC: 0.1641, MAE: 0.1206\n    Epoch 8/10 | Val CCC: 0.1880, MAE: 0.1187\n    Epoch 9/10 | Val CCC: 0.1977, MAE: 0.1183\n    Epoch 10/10 | Val CCC: 0.1558, MAE: 0.1214\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0860, MAE: 0.1237\n    Epoch 2/10 | Val CCC: 0.0900, MAE: 0.1213\n    Epoch 3/10 | Val CCC: 0.1233, MAE: 0.1228\n    Epoch 4/10 | Val CCC: 0.1469, MAE: 0.1202\n    Epoch 5/10 | Val CCC: 0.1273, MAE: 0.1202\n    Epoch 6/10 | Val CCC: 0.1462, MAE: 0.1187\n    Epoch 7/10 | Val CCC: 0.1574, MAE: 0.1213\n    Epoch 8/10 | Val CCC: 0.1555, MAE: 0.1183\n    Epoch 9/10 | Val CCC: 0.1822, MAE: 0.1185\n    Epoch 10/10 | Val CCC: 0.1383, MAE: 0.1182\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0974, MAE: 0.1233\n    Epoch 2/10 | Val CCC: 0.0640, MAE: 0.1244\n    Epoch 3/10 | Val CCC: 0.1239, MAE: 0.1203\n    Epoch 4/10 | Val CCC: 0.1585, MAE: 0.1215\n    Epoch 5/10 | Val CCC: 0.1266, MAE: 0.1195\n    Epoch 6/10 | Val CCC: 0.1583, MAE: 0.1204\n    Epoch 7/10 | Val CCC: 0.1724, MAE: 0.1180\n    Epoch 8/10 | Val CCC: 0.1665, MAE: 0.1193\n    Epoch 9/10 | Val CCC: 0.1957, MAE: 0.1170\n    Epoch 10/10 | Val CCC: 0.2121, MAE: 0.1167\n  Avg CCC: 0.1973, MAE: 0.1179\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0482, MAE: 0.1236\n    Epoch 2/10 | Val CCC: 0.0599, MAE: 0.1302\n    Epoch 3/10 | Val CCC: 0.0761, MAE: 0.1417\n    Epoch 4/10 | Val CCC: 0.1052, MAE: 0.1332\n    Epoch 5/10 | Val CCC: 0.1010, MAE: 0.1312\n    Epoch 6/10 | Val CCC: 0.1390, MAE: 0.1306\n    Epoch 7/10 | Val CCC: 0.1291, MAE: 0.1325\n    Epoch 8/10 | Val CCC: 0.1250, MAE: 0.1366\n    Epoch 9/10 | Val CCC: 0.1622, MAE: 0.1254\n    Epoch 10/10 | Val CCC: 0.1499, MAE: 0.1309\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0633, MAE: 0.1275\n    Epoch 2/10 | Val CCC: 0.0651, MAE: 0.1329\n    Epoch 3/10 | Val CCC: 0.0732, MAE: 0.1304\n    Epoch 4/10 | Val CCC: 0.0957, MAE: 0.1321\n    Epoch 5/10 | Val CCC: 0.0976, MAE: 0.1328\n    Epoch 6/10 | Val CCC: 0.1428, MAE: 0.1273\n    Epoch 7/10 | Val CCC: 0.1223, MAE: 0.1264\n    Epoch 8/10 | Val CCC: 0.1580, MAE: 0.1225\n    Epoch 9/10 | Val CCC: 0.1316, MAE: 0.1244\n    Epoch 10/10 | Val CCC: 0.1755, MAE: 0.1209\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0276, MAE: 0.1266\n    Epoch 2/10 | Val CCC: 0.0544, MAE: 0.1291\n    Epoch 3/10 | Val CCC: 0.0650, MAE: 0.1391\n    Epoch 4/10 | Val CCC: 0.1169, MAE: 0.1286\n    Epoch 5/10 | Val CCC: 0.1160, MAE: 0.1280\n    Epoch 6/10 | Val CCC: 0.1031, MAE: 0.1294\n    Epoch 7/10 | Val CCC: 0.1085, MAE: 0.1328\n    Epoch 8/10 | Val CCC: 0.1633, MAE: 0.1234\n    Epoch 9/10 | Val CCC: 0.1523, MAE: 0.1256\n    Epoch 10/10 | Val CCC: 0.1414, MAE: 0.1266\n  Avg CCC: 0.1670, MAE: 0.1232\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0303, MAE: 0.1420\n    Epoch 2/10 | Val CCC: 0.0180, MAE: 0.1426\n    Epoch 3/10 | Val CCC: 0.0390, MAE: 0.1353\n    Epoch 4/10 | Val CCC: 0.0535, MAE: 0.1335\n    Epoch 5/10 | Val CCC: 0.0405, MAE: 0.1282\n    Epoch 6/10 | Val CCC: 0.0354, MAE: 0.1241\n    Epoch 7/10 | Val CCC: 0.1006, MAE: 0.1262\n    Epoch 8/10 | Val CCC: 0.0634, MAE: 0.1237\n    Epoch 9/10 | Val CCC: 0.0380, MAE: 0.1238\n    Epoch 10/10 | Val CCC: 0.0288, MAE: 0.1240\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0132, MAE: 0.1498\n    Epoch 2/10 | Val CCC: 0.0428, MAE: 0.1246\n    Epoch 3/10 | Val CCC: 0.0426, MAE: 0.1245\n    Epoch 4/10 | Val CCC: 0.0311, MAE: 0.1248\n    Epoch 5/10 | Val CCC: 0.0334, MAE: 0.1234\n    Epoch 6/10 | Val CCC: 0.0579, MAE: 0.1247\n    Epoch 7/10 | Val CCC: 0.0742, MAE: 0.1229\n    Epoch 8/10 | Val CCC: 0.0775, MAE: 0.1224\n    Epoch 9/10 | Val CCC: 0.0998, MAE: 0.1211\n    Epoch 10/10 | Val CCC: 0.0599, MAE: 0.1219\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0287, MAE: 0.1276\n    Epoch 2/10 | Val CCC: 0.0248, MAE: 0.1398\n    Epoch 3/10 | Val CCC: 0.0337, MAE: 0.1460\n    Epoch 4/10 | Val CCC: 0.0414, MAE: 0.1288\n    Epoch 5/10 | Val CCC: 0.0479, MAE: 0.1252\n    Epoch 6/10 | Val CCC: 0.0422, MAE: 0.1262\n    Epoch 7/10 | Val CCC: 0.0891, MAE: 0.1219\n    Epoch 8/10 | Val CCC: 0.0848, MAE: 0.1226\n    Epoch 9/10 | Val CCC: 0.0778, MAE: 0.1223\n    Epoch 10/10 | Val CCC: 0.0708, MAE: 0.1223\n  Avg CCC: 0.0965, MAE: 0.1231\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1021, MAE: 0.1232\n    Epoch 2/10 | Val CCC: 0.1168, MAE: 0.1222\n    Epoch 3/10 | Val CCC: 0.0872, MAE: 0.1245\n    Epoch 4/10 | Val CCC: 0.0874, MAE: 0.1233\n    Epoch 5/10 | Val CCC: 0.1445, MAE: 0.1209\n    Epoch 6/10 | Val CCC: 0.1604, MAE: 0.1197\n    Epoch 7/10 | Val CCC: 0.1605, MAE: 0.1194\n    Epoch 8/10 | Val CCC: 0.1420, MAE: 0.1191\n    Epoch 9/10 | Val CCC: 0.1323, MAE: 0.1203\n    Epoch 10/10 | Val CCC: 0.1982, MAE: 0.1177\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0773, MAE: 0.1219\n    Epoch 2/10 | Val CCC: 0.0776, MAE: 0.1215\n    Epoch 3/10 | Val CCC: 0.1149, MAE: 0.1201\n    Epoch 4/10 | Val CCC: 0.1357, MAE: 0.1197\n    Epoch 5/10 | Val CCC: 0.1353, MAE: 0.1206\n    Epoch 6/10 | Val CCC: 0.1442, MAE: 0.1185\n    Epoch 7/10 | Val CCC: 0.1507, MAE: 0.1186\n    Epoch 8/10 | Val CCC: 0.1482, MAE: 0.1191\n    Epoch 9/10 | Val CCC: 0.1865, MAE: 0.1174\n    Epoch 10/10 | Val CCC: 0.1920, MAE: 0.1181\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0808, MAE: 0.1220\n    Epoch 2/10 | Val CCC: 0.1150, MAE: 0.1206\n    Epoch 3/10 | Val CCC: 0.1206, MAE: 0.1214\n    Epoch 4/10 | Val CCC: 0.1449, MAE: 0.1194\n    Epoch 5/10 | Val CCC: 0.1568, MAE: 0.1219\n    Epoch 6/10 | Val CCC: 0.1571, MAE: 0.1187\n    Epoch 7/10 | Val CCC: 0.1714, MAE: 0.1181\n    Epoch 8/10 | Val CCC: 0.1889, MAE: 0.1186\n    Epoch 9/10 | Val CCC: 0.1793, MAE: 0.1172\n    Epoch 10/10 | Val CCC: 0.1758, MAE: 0.1177\n  Avg CCC: 0.1930, MAE: 0.1181\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0581, MAE: 0.1233\n    Epoch 2/10 | Val CCC: 0.1049, MAE: 0.1222\n    Epoch 3/10 | Val CCC: 0.1056, MAE: 0.1209\n    Epoch 4/10 | Val CCC: 0.1273, MAE: 0.1208\n    Epoch 5/10 | Val CCC: 0.1163, MAE: 0.1204\n    Epoch 6/10 | Val CCC: 0.1659, MAE: 0.1190\n    Epoch 7/10 | Val CCC: 0.1566, MAE: 0.1190\n    Epoch 8/10 | Val CCC: 0.1251, MAE: 0.1215\n    Epoch 9/10 | Val CCC: 0.1717, MAE: 0.1189\n    Epoch 10/10 | Val CCC: 0.1951, MAE: 0.1178\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0419, MAE: 0.1291\n    Epoch 2/10 | Val CCC: 0.1005, MAE: 0.1213\n    Epoch 3/10 | Val CCC: 0.0982, MAE: 0.1209\n    Epoch 4/10 | Val CCC: 0.1008, MAE: 0.1201\n    Epoch 5/10 | Val CCC: 0.1191, MAE: 0.1221\n    Epoch 6/10 | Val CCC: 0.0923, MAE: 0.1215\n    Epoch 7/10 | Val CCC: 0.1483, MAE: 0.1189\n    Epoch 8/10 | Val CCC: 0.1379, MAE: 0.1216\n    Epoch 9/10 | Val CCC: 0.1728, MAE: 0.1187\n    Epoch 10/10 | Val CCC: 0.1499, MAE: 0.1211\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0843, MAE: 0.1241\n    Epoch 2/10 | Val CCC: 0.0747, MAE: 0.1232\n    Epoch 3/10 | Val CCC: 0.0391, MAE: 0.1230\n    Epoch 4/10 | Val CCC: 0.0913, MAE: 0.1205\n    Epoch 5/10 | Val CCC: 0.1233, MAE: 0.1197\n    Epoch 6/10 | Val CCC: 0.1627, MAE: 0.1186\n    Epoch 7/10 | Val CCC: 0.1833, MAE: 0.1217\n    Epoch 8/10 | Val CCC: 0.1674, MAE: 0.1184\n    Epoch 9/10 | Val CCC: 0.1514, MAE: 0.1188\n    Epoch 10/10 | Val CCC: 0.1931, MAE: 0.1179\n  Avg CCC: 0.1870, MAE: 0.1181\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0429, MAE: 0.1238\n    Epoch 2/10 | Val CCC: 0.0957, MAE: 0.1231\n    Epoch 3/10 | Val CCC: 0.1237, MAE: 0.1218\n    Epoch 4/10 | Val CCC: 0.1146, MAE: 0.1282\n    Epoch 5/10 | Val CCC: 0.1213, MAE: 0.1209\n    Epoch 6/10 | Val CCC: 0.1403, MAE: 0.1271\n    Epoch 7/10 | Val CCC: 0.1486, MAE: 0.1261\n    Epoch 8/10 | Val CCC: 0.1526, MAE: 0.1221\n    Epoch 9/10 | Val CCC: 0.1098, MAE: 0.1337\n    Epoch 10/10 | Val CCC: 0.1358, MAE: 0.1243\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0619, MAE: 0.1267\n    Epoch 2/10 | Val CCC: 0.1018, MAE: 0.1239\n    Epoch 3/10 | Val CCC: 0.1066, MAE: 0.1238\n    Epoch 4/10 | Val CCC: 0.1663, MAE: 0.1216\n    Epoch 5/10 | Val CCC: 0.1230, MAE: 0.1229\n    Epoch 6/10 | Val CCC: 0.1438, MAE: 0.1250\n    Epoch 7/10 | Val CCC: 0.1308, MAE: 0.1268\n    Epoch 8/10 | Val CCC: 0.1417, MAE: 0.1228\n    Epoch 9/10 | Val CCC: 0.1458, MAE: 0.1254\n    Epoch 10/10 | Val CCC: 0.1794, MAE: 0.1274\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0453, MAE: 0.1294\n    Epoch 2/10 | Val CCC: 0.0896, MAE: 0.1244\n    Epoch 3/10 | Val CCC: 0.1062, MAE: 0.1251\n    Epoch 4/10 | Val CCC: 0.1268, MAE: 0.1253\n    Epoch 5/10 | Val CCC: 0.1294, MAE: 0.1243\n    Epoch 6/10 | Val CCC: 0.1393, MAE: 0.1287\n    Epoch 7/10 | Val CCC: 0.1243, MAE: 0.1303\n    Epoch 8/10 | Val CCC: 0.1511, MAE: 0.1250\n    Epoch 9/10 | Val CCC: 0.1756, MAE: 0.1243\n    Epoch 10/10 | Val CCC: 0.1187, MAE: 0.1223\n  Avg CCC: 0.1692, MAE: 0.1246\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0230, MAE: 0.1282\n    Epoch 2/10 | Val CCC: 0.0275, MAE: 0.1252\n    Epoch 3/10 | Val CCC: 0.0283, MAE: 0.1245\n    Epoch 4/10 | Val CCC: 0.0452, MAE: 0.1246\n    Epoch 5/10 | Val CCC: 0.0592, MAE: 0.1241\n    Epoch 6/10 | Val CCC: 0.0813, MAE: 0.1246\n    Epoch 7/10 | Val CCC: 0.1081, MAE: 0.1219\n    Epoch 8/10 | Val CCC: 0.0517, MAE: 0.1230\n    Epoch 9/10 | Val CCC: 0.1265, MAE: 0.1210\n    Epoch 10/10 | Val CCC: 0.1353, MAE: 0.1198\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0501, MAE: 0.1253\n    Epoch 2/10 | Val CCC: 0.0258, MAE: 0.1248\n    Epoch 3/10 | Val CCC: 0.0376, MAE: 0.1257\n    Epoch 4/10 | Val CCC: 0.0359, MAE: 0.1234\n    Epoch 5/10 | Val CCC: 0.0453, MAE: 0.1233\n    Epoch 6/10 | Val CCC: 0.0984, MAE: 0.1209\n    Epoch 7/10 | Val CCC: 0.1178, MAE: 0.1227\n    Epoch 8/10 | Val CCC: 0.0784, MAE: 0.1210\n    Epoch 9/10 | Val CCC: 0.0955, MAE: 0.1219\n    Epoch 10/10 | Val CCC: 0.1094, MAE: 0.1202\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0169, MAE: 0.1246\n    Epoch 2/10 | Val CCC: 0.0252, MAE: 0.1255\n    Epoch 3/10 | Val CCC: 0.0441, MAE: 0.1269\n    Epoch 4/10 | Val CCC: 0.0324, MAE: 0.1241\n    Epoch 5/10 | Val CCC: 0.0365, MAE: 0.1248\n    Epoch 6/10 | Val CCC: 0.0586, MAE: 0.1255\n    Epoch 7/10 | Val CCC: 0.0651, MAE: 0.1229\n    Epoch 8/10 | Val CCC: 0.0875, MAE: 0.1219\n    Epoch 9/10 | Val CCC: 0.1199, MAE: 0.1222\n    Epoch 10/10 | Val CCC: 0.1234, MAE: 0.1225\n  Avg CCC: 0.1255, MAE: 0.1216\n\n>>> Best Config Selected: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n\n>>> Final Training for CONSCIENTIOUSNESS (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0279\n  Epoch 2/10 - Train Loss: 0.0246\n  Epoch 3/10 - Train Loss: 0.0237\n  Epoch 4/10 - Train Loss: 0.0232\n  Epoch 5/10 - Train Loss: 0.0229\n  Epoch 6/10 - Train Loss: 0.0226\n  Epoch 7/10 - Train Loss: 0.0225\n  Epoch 8/10 - Train Loss: 0.0222\n  Epoch 9/10 - Train Loss: 0.0222\n  Epoch 10/10 - Train Loss: 0.0221\n\n==== CONSCIENTIOUSNESS Evaluation on Test Set ====\nTest CCC: 0.1849, Test MAE: 0.1194, Accuracy (±0.1): 49.29%\nSaving final model for conscientiousness to best_video_transformer_model_conscientiousness.pth\n\n--- Training for Trait: extraversion ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0374, MAE: 0.1280\n    Epoch 2/10 | Val CCC: 0.0371, MAE: 0.1232\n    Epoch 3/10 | Val CCC: 0.0366, MAE: 0.1209\n    Epoch 4/10 | Val CCC: 0.0320, MAE: 0.1218\n    Epoch 5/10 | Val CCC: 0.0560, MAE: 0.1216\n    Epoch 6/10 | Val CCC: 0.0685, MAE: 0.1216\n    Epoch 7/10 | Val CCC: 0.0437, MAE: 0.1209\n    Epoch 8/10 | Val CCC: 0.0278, MAE: 0.1215\n    Epoch 9/10 | Val CCC: 0.0132, MAE: 0.1219\n    Epoch 10/10 | Val CCC: 0.0332, MAE: 0.1209\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0282, MAE: 0.1301\n    Epoch 2/10 | Val CCC: 0.0349, MAE: 0.1301\n    Epoch 3/10 | Val CCC: 0.0388, MAE: 0.1254\n    Epoch 4/10 | Val CCC: 0.0295, MAE: 0.1211\n    Epoch 5/10 | Val CCC: 0.0535, MAE: 0.1200\n    Epoch 6/10 | Val CCC: 0.0430, MAE: 0.1201\n    Epoch 7/10 | Val CCC: 0.0444, MAE: 0.1199\n    Epoch 8/10 | Val CCC: 0.0351, MAE: 0.1202\n    Epoch 9/10 | Val CCC: 0.0322, MAE: 0.1200\n    Epoch 10/10 | Val CCC: 0.0411, MAE: 0.1200\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0393, MAE: 0.1210\n    Epoch 2/10 | Val CCC: 0.0274, MAE: 0.1212\n    Epoch 3/10 | Val CCC: 0.0269, MAE: 0.1209\n    Epoch 4/10 | Val CCC: 0.0294, MAE: 0.1220\n    Epoch 5/10 | Val CCC: 0.0241, MAE: 0.1204\n    Epoch 6/10 | Val CCC: 0.0450, MAE: 0.1206\n    Epoch 7/10 | Val CCC: 0.0405, MAE: 0.1201\n    Epoch 8/10 | Val CCC: 0.0361, MAE: 0.1203\n    Epoch 9/10 | Val CCC: 0.0354, MAE: 0.1208\n    Epoch 10/10 | Val CCC: 0.0183, MAE: 0.1205\n  Avg CCC: 0.0557, MAE: 0.1207\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0234, MAE: 0.1564\n    Epoch 2/10 | Val CCC: 0.0414, MAE: 0.1304\n    Epoch 3/10 | Val CCC: 0.0604, MAE: 0.1278\n    Epoch 4/10 | Val CCC: 0.1087, MAE: 0.1245\n    Epoch 5/10 | Val CCC: 0.1516, MAE: 0.1202\n    Epoch 6/10 | Val CCC: 0.0946, MAE: 0.1243\n    Epoch 7/10 | Val CCC: 0.1370, MAE: 0.1334\n    Epoch 8/10 | Val CCC: 0.2164, MAE: 0.1230\n    Epoch 9/10 | Val CCC: 0.2151, MAE: 0.1233\n    Epoch 10/10 | Val CCC: 0.1923, MAE: 0.1159\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0361, MAE: 0.1495\n    Epoch 2/10 | Val CCC: 0.0334, MAE: 0.1502\n    Epoch 3/10 | Val CCC: 0.0441, MAE: 0.1494\n    Epoch 4/10 | Val CCC: 0.0856, MAE: 0.1288\n    Epoch 5/10 | Val CCC: 0.1209, MAE: 0.1249\n    Epoch 6/10 | Val CCC: 0.2087, MAE: 0.1248\n    Epoch 7/10 | Val CCC: 0.1516, MAE: 0.1323\n    Epoch 8/10 | Val CCC: 0.2175, MAE: 0.1210\n    Epoch 9/10 | Val CCC: 0.2263, MAE: 0.1257\n    Epoch 10/10 | Val CCC: 0.2018, MAE: 0.1216\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0304, MAE: 0.1465\n    Epoch 2/10 | Val CCC: 0.0300, MAE: 0.1389\n    Epoch 3/10 | Val CCC: 0.0478, MAE: 0.1291\n    Epoch 4/10 | Val CCC: 0.1009, MAE: 0.1188\n    Epoch 5/10 | Val CCC: 0.1409, MAE: 0.1184\n    Epoch 6/10 | Val CCC: 0.2133, MAE: 0.1168\n    Epoch 7/10 | Val CCC: 0.2197, MAE: 0.1192\n    Epoch 8/10 | Val CCC: 0.1726, MAE: 0.1179\n    Epoch 9/10 | Val CCC: 0.1629, MAE: 0.1160\n    Epoch 10/10 | Val CCC: 0.2072, MAE: 0.1151\n  Avg CCC: 0.2208, MAE: 0.1226\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0329, MAE: 0.1211\n    Epoch 2/10 | Val CCC: 0.0384, MAE: 0.1257\n    Epoch 3/10 | Val CCC: 0.0253, MAE: 0.1210\n    Epoch 4/10 | Val CCC: 0.0323, MAE: 0.1210\n    Epoch 5/10 | Val CCC: 0.0396, MAE: 0.1208\n    Epoch 6/10 | Val CCC: 0.0570, MAE: 0.1202\n    Epoch 7/10 | Val CCC: 0.0265, MAE: 0.1229\n    Epoch 8/10 | Val CCC: 0.0863, MAE: 0.1211\n    Epoch 9/10 | Val CCC: 0.0289, MAE: 0.1211\n    Epoch 10/10 | Val CCC: 0.0131, MAE: 0.1215\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0335, MAE: 0.1207\n    Epoch 2/10 | Val CCC: 0.0451, MAE: 0.1213\n    Epoch 3/10 | Val CCC: 0.0373, MAE: 0.1236\n    Epoch 4/10 | Val CCC: 0.0320, MAE: 0.1201\n    Epoch 5/10 | Val CCC: 0.0479, MAE: 0.1197\n    Epoch 6/10 | Val CCC: 0.0778, MAE: 0.1179\n    Epoch 7/10 | Val CCC: 0.0985, MAE: 0.1170\n    Epoch 8/10 | Val CCC: 0.1500, MAE: 0.1154\n    Epoch 9/10 | Val CCC: 0.1840, MAE: 0.1136\n    Epoch 10/10 | Val CCC: 0.2137, MAE: 0.1132\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0483, MAE: 0.1208\n    Epoch 2/10 | Val CCC: 0.0420, MAE: 0.1208\n    Epoch 3/10 | Val CCC: 0.0348, MAE: 0.1202\n    Epoch 4/10 | Val CCC: 0.0265, MAE: 0.1229\n    Epoch 5/10 | Val CCC: 0.0433, MAE: 0.1210\n    Epoch 6/10 | Val CCC: 0.0554, MAE: 0.1196\n    Epoch 7/10 | Val CCC: 0.0699, MAE: 0.1195\n    Epoch 8/10 | Val CCC: 0.0763, MAE: 0.1189\n    Epoch 9/10 | Val CCC: 0.0471, MAE: 0.1202\n    Epoch 10/10 | Val CCC: 0.0023, MAE: 0.1213\n  Avg CCC: 0.1254, MAE: 0.1177\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0506, MAE: 0.1217\n    Epoch 2/10 | Val CCC: 0.1127, MAE: 0.1189\n    Epoch 3/10 | Val CCC: 0.1134, MAE: 0.1182\n    Epoch 4/10 | Val CCC: 0.2029, MAE: 0.1171\n    Epoch 5/10 | Val CCC: 0.1451, MAE: 0.1166\n    Epoch 6/10 | Val CCC: 0.1904, MAE: 0.1176\n    Epoch 7/10 | Val CCC: 0.1995, MAE: 0.1178\n    Epoch 8/10 | Val CCC: 0.1704, MAE: 0.1166\n    Epoch 9/10 | Val CCC: 0.2745, MAE: 0.1128\n    Epoch 10/10 | Val CCC: 0.2272, MAE: 0.1131\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0967, MAE: 0.1185\n    Epoch 2/10 | Val CCC: 0.1461, MAE: 0.1153\n    Epoch 3/10 | Val CCC: 0.0975, MAE: 0.1197\n    Epoch 4/10 | Val CCC: 0.1657, MAE: 0.1150\n    Epoch 5/10 | Val CCC: 0.1844, MAE: 0.1140\n    Epoch 6/10 | Val CCC: 0.2052, MAE: 0.1126\n    Epoch 7/10 | Val CCC: 0.2160, MAE: 0.1122\n    Epoch 8/10 | Val CCC: 0.2393, MAE: 0.1125\n    Epoch 9/10 | Val CCC: 0.2290, MAE: 0.1116\n    Epoch 10/10 | Val CCC: 0.2579, MAE: 0.1107\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0712, MAE: 0.1193\n    Epoch 2/10 | Val CCC: 0.1529, MAE: 0.1157\n    Epoch 3/10 | Val CCC: 0.1662, MAE: 0.1157\n    Epoch 4/10 | Val CCC: 0.1909, MAE: 0.1131\n    Epoch 5/10 | Val CCC: 0.2051, MAE: 0.1138\n    Epoch 6/10 | Val CCC: 0.2449, MAE: 0.1122\n    Epoch 7/10 | Val CCC: 0.2272, MAE: 0.1120\n    Epoch 8/10 | Val CCC: 0.2091, MAE: 0.1125\n    Epoch 9/10 | Val CCC: 0.2117, MAE: 0.1130\n    Epoch 10/10 | Val CCC: 0.2579, MAE: 0.1114\n  Avg CCC: 0.2635, MAE: 0.1117\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0642, MAE: 0.1197\n    Epoch 2/10 | Val CCC: 0.1088, MAE: 0.1179\n    Epoch 3/10 | Val CCC: 0.1280, MAE: 0.1178\n    Epoch 4/10 | Val CCC: 0.1431, MAE: 0.1156\n    Epoch 5/10 | Val CCC: 0.1115, MAE: 0.1168\n    Epoch 6/10 | Val CCC: 0.1951, MAE: 0.1133\n    Epoch 7/10 | Val CCC: 0.1838, MAE: 0.1136\n    Epoch 8/10 | Val CCC: 0.2303, MAE: 0.1154\n    Epoch 9/10 | Val CCC: 0.1627, MAE: 0.1138\n    Epoch 10/10 | Val CCC: 0.2260, MAE: 0.1119\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0566, MAE: 0.1190\n    Epoch 2/10 | Val CCC: 0.0826, MAE: 0.1188\n    Epoch 3/10 | Val CCC: 0.1496, MAE: 0.1204\n    Epoch 4/10 | Val CCC: 0.1364, MAE: 0.1180\n    Epoch 5/10 | Val CCC: 0.1595, MAE: 0.1147\n    Epoch 6/10 | Val CCC: 0.1565, MAE: 0.1140\n    Epoch 7/10 | Val CCC: 0.1811, MAE: 0.1136\n    Epoch 8/10 | Val CCC: 0.2335, MAE: 0.1153\n    Epoch 9/10 | Val CCC: 0.2324, MAE: 0.1122\n    Epoch 10/10 | Val CCC: 0.2284, MAE: 0.1122\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0345, MAE: 0.1205\n    Epoch 2/10 | Val CCC: 0.1021, MAE: 0.1240\n    Epoch 3/10 | Val CCC: 0.0801, MAE: 0.1168\n    Epoch 4/10 | Val CCC: 0.2248, MAE: 0.1153\n    Epoch 5/10 | Val CCC: 0.0901, MAE: 0.1185\n    Epoch 6/10 | Val CCC: 0.1768, MAE: 0.1152\n    Epoch 7/10 | Val CCC: 0.1961, MAE: 0.1137\n    Epoch 8/10 | Val CCC: 0.2049, MAE: 0.1128\n    Epoch 9/10 | Val CCC: 0.1807, MAE: 0.1125\n    Epoch 10/10 | Val CCC: 0.2469, MAE: 0.1109\n  Avg CCC: 0.2369, MAE: 0.1139\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0339, MAE: 0.1319\n    Epoch 2/10 | Val CCC: 0.0349, MAE: 0.1306\n    Epoch 3/10 | Val CCC: 0.0790, MAE: 0.1210\n    Epoch 4/10 | Val CCC: 0.0895, MAE: 0.1230\n    Epoch 5/10 | Val CCC: 0.0834, MAE: 0.1192\n    Epoch 6/10 | Val CCC: 0.1319, MAE: 0.1171\n    Epoch 7/10 | Val CCC: 0.1166, MAE: 0.1175\n    Epoch 8/10 | Val CCC: 0.0797, MAE: 0.1187\n    Epoch 9/10 | Val CCC: 0.1457, MAE: 0.1165\n    Epoch 10/10 | Val CCC: 0.1479, MAE: 0.1159\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0287, MAE: 0.1446\n    Epoch 2/10 | Val CCC: 0.0433, MAE: 0.1356\n    Epoch 3/10 | Val CCC: 0.0819, MAE: 0.1263\n    Epoch 4/10 | Val CCC: 0.0989, MAE: 0.1185\n    Epoch 5/10 | Val CCC: 0.0894, MAE: 0.1196\n    Epoch 6/10 | Val CCC: 0.1501, MAE: 0.1159\n    Epoch 7/10 | Val CCC: 0.1429, MAE: 0.1171\n    Epoch 8/10 | Val CCC: 0.1387, MAE: 0.1165\n    Epoch 9/10 | Val CCC: 0.1195, MAE: 0.1208\n    Epoch 10/10 | Val CCC: 0.1439, MAE: 0.1155\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0316, MAE: 0.1295\n    Epoch 2/10 | Val CCC: 0.0330, MAE: 0.1363\n    Epoch 3/10 | Val CCC: 0.0619, MAE: 0.1241\n    Epoch 4/10 | Val CCC: 0.1012, MAE: 0.1224\n    Epoch 5/10 | Val CCC: 0.0971, MAE: 0.1184\n    Epoch 6/10 | Val CCC: 0.1084, MAE: 0.1159\n    Epoch 7/10 | Val CCC: 0.0789, MAE: 0.1184\n    Epoch 8/10 | Val CCC: 0.1074, MAE: 0.1184\n    Epoch 9/10 | Val CCC: 0.1682, MAE: 0.1155\n    Epoch 10/10 | Val CCC: 0.1288, MAE: 0.1184\n  Avg CCC: 0.1554, MAE: 0.1157\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0625, MAE: 0.1222\n    Epoch 2/10 | Val CCC: 0.0957, MAE: 0.1201\n    Epoch 3/10 | Val CCC: 0.1159, MAE: 0.1166\n    Epoch 4/10 | Val CCC: 0.2008, MAE: 0.1143\n    Epoch 5/10 | Val CCC: 0.1956, MAE: 0.1158\n    Epoch 6/10 | Val CCC: 0.1990, MAE: 0.1144\n    Epoch 7/10 | Val CCC: 0.2265, MAE: 0.1131\n    Epoch 8/10 | Val CCC: 0.2496, MAE: 0.1132\n    Epoch 9/10 | Val CCC: 0.2071, MAE: 0.1125\n    Epoch 10/10 | Val CCC: 0.1789, MAE: 0.1163\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0586, MAE: 0.1197\n    Epoch 2/10 | Val CCC: 0.0888, MAE: 0.1181\n    Epoch 3/10 | Val CCC: 0.1674, MAE: 0.1150\n    Epoch 4/10 | Val CCC: 0.1579, MAE: 0.1139\n    Epoch 5/10 | Val CCC: 0.1646, MAE: 0.1143\n    Epoch 6/10 | Val CCC: 0.1716, MAE: 0.1154\n    Epoch 7/10 | Val CCC: 0.1925, MAE: 0.1179\n    Epoch 8/10 | Val CCC: 0.2184, MAE: 0.1119\n    Epoch 9/10 | Val CCC: 0.2147, MAE: 0.1163\n    Epoch 10/10 | Val CCC: 0.2193, MAE: 0.1128\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0893, MAE: 0.1188\n    Epoch 2/10 | Val CCC: 0.1214, MAE: 0.1173\n    Epoch 3/10 | Val CCC: 0.1391, MAE: 0.1153\n    Epoch 4/10 | Val CCC: 0.1305, MAE: 0.1179\n    Epoch 5/10 | Val CCC: 0.1935, MAE: 0.1127\n    Epoch 6/10 | Val CCC: 0.2203, MAE: 0.1113\n    Epoch 7/10 | Val CCC: 0.2381, MAE: 0.1111\n    Epoch 8/10 | Val CCC: 0.2214, MAE: 0.1119\n    Epoch 9/10 | Val CCC: 0.2375, MAE: 0.1117\n    Epoch 10/10 | Val CCC: 0.2057, MAE: 0.1120\n  Avg CCC: 0.2357, MAE: 0.1124\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0482, MAE: 0.1331\n    Epoch 2/10 | Val CCC: 0.0752, MAE: 0.1311\n    Epoch 3/10 | Val CCC: 0.0946, MAE: 0.1355\n    Epoch 4/10 | Val CCC: 0.1246, MAE: 0.1389\n    Epoch 5/10 | Val CCC: 0.1491, MAE: 0.1291\n    Epoch 6/10 | Val CCC: 0.1776, MAE: 0.1344\n    Epoch 7/10 | Val CCC: 0.1632, MAE: 0.1267\n    Epoch 8/10 | Val CCC: 0.2114, MAE: 0.1180\n    Epoch 9/10 | Val CCC: 0.2048, MAE: 0.1154\n    Epoch 10/10 | Val CCC: 0.2331, MAE: 0.1164\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0576, MAE: 0.1323\n    Epoch 2/10 | Val CCC: 0.0597, MAE: 0.1326\n    Epoch 3/10 | Val CCC: 0.0759, MAE: 0.1432\n    Epoch 4/10 | Val CCC: 0.1430, MAE: 0.1310\n    Epoch 5/10 | Val CCC: 0.1144, MAE: 0.1286\n    Epoch 6/10 | Val CCC: 0.1341, MAE: 0.1254\n    Epoch 7/10 | Val CCC: 0.2077, MAE: 0.1249\n    Epoch 8/10 | Val CCC: 0.1884, MAE: 0.1228\n    Epoch 9/10 | Val CCC: 0.2195, MAE: 0.1214\n    Epoch 10/10 | Val CCC: 0.2059, MAE: 0.1238\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0480, MAE: 0.1364\n    Epoch 2/10 | Val CCC: 0.0556, MAE: 0.1314\n    Epoch 3/10 | Val CCC: 0.1047, MAE: 0.1307\n    Epoch 4/10 | Val CCC: 0.1344, MAE: 0.1322\n    Epoch 5/10 | Val CCC: 0.1619, MAE: 0.1183\n    Epoch 6/10 | Val CCC: 0.1462, MAE: 0.1376\n    Epoch 7/10 | Val CCC: 0.1779, MAE: 0.1196\n    Epoch 8/10 | Val CCC: 0.1813, MAE: 0.1191\n    Epoch 9/10 | Val CCC: 0.2375, MAE: 0.1181\n    Epoch 10/10 | Val CCC: 0.2263, MAE: 0.1167\n  Avg CCC: 0.2300, MAE: 0.1186\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0280, MAE: 0.1212\n    Epoch 2/10 | Val CCC: 0.0141, MAE: 0.1216\n    Epoch 3/10 | Val CCC: 0.0549, MAE: 0.1214\n    Epoch 4/10 | Val CCC: 0.0331, MAE: 0.1210\n    Epoch 5/10 | Val CCC: 0.0634, MAE: 0.1225\n    Epoch 6/10 | Val CCC: 0.0834, MAE: 0.1214\n    Epoch 7/10 | Val CCC: 0.0865, MAE: 0.1200\n    Epoch 8/10 | Val CCC: 0.0687, MAE: 0.1193\n    Epoch 9/10 | Val CCC: 0.0636, MAE: 0.1191\n    Epoch 10/10 | Val CCC: 0.0965, MAE: 0.1183\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0307, MAE: 0.1209\n    Epoch 2/10 | Val CCC: 0.0256, MAE: 0.1223\n    Epoch 3/10 | Val CCC: 0.0305, MAE: 0.1201\n    Epoch 4/10 | Val CCC: 0.0438, MAE: 0.1198\n    Epoch 5/10 | Val CCC: 0.0609, MAE: 0.1192\n    Epoch 6/10 | Val CCC: 0.0297, MAE: 0.1226\n    Epoch 7/10 | Val CCC: 0.1218, MAE: 0.1176\n    Epoch 8/10 | Val CCC: 0.0871, MAE: 0.1180\n    Epoch 9/10 | Val CCC: 0.1235, MAE: 0.1170\n    Epoch 10/10 | Val CCC: 0.1695, MAE: 0.1137\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0286, MAE: 0.1211\n    Epoch 2/10 | Val CCC: 0.0234, MAE: 0.1228\n    Epoch 3/10 | Val CCC: 0.0164, MAE: 0.1239\n    Epoch 4/10 | Val CCC: 0.0333, MAE: 0.1212\n    Epoch 5/10 | Val CCC: 0.0123, MAE: 0.1230\n    Epoch 6/10 | Val CCC: 0.0580, MAE: 0.1194\n    Epoch 7/10 | Val CCC: 0.1014, MAE: 0.1172\n    Epoch 8/10 | Val CCC: -0.0022, MAE: 0.1224\n    Epoch 9/10 | Val CCC: 0.0296, MAE: 0.1198\n    Epoch 10/10 | Val CCC: 0.0398, MAE: 0.1198\n  Avg CCC: 0.1225, MAE: 0.1164\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0893, MAE: 0.1218\n    Epoch 2/10 | Val CCC: 0.1063, MAE: 0.1223\n    Epoch 3/10 | Val CCC: 0.1743, MAE: 0.1155\n    Epoch 4/10 | Val CCC: 0.2141, MAE: 0.1135\n    Epoch 5/10 | Val CCC: 0.1948, MAE: 0.1151\n    Epoch 6/10 | Val CCC: 0.1943, MAE: 0.1148\n    Epoch 7/10 | Val CCC: 0.1355, MAE: 0.1261\n    Epoch 8/10 | Val CCC: 0.2164, MAE: 0.1124\n    Epoch 9/10 | Val CCC: 0.2155, MAE: 0.1152\n    Epoch 10/10 | Val CCC: 0.2054, MAE: 0.1154\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1065, MAE: 0.1179\n    Epoch 2/10 | Val CCC: 0.1386, MAE: 0.1177\n    Epoch 3/10 | Val CCC: 0.1501, MAE: 0.1155\n    Epoch 4/10 | Val CCC: 0.1294, MAE: 0.1153\n    Epoch 5/10 | Val CCC: 0.2148, MAE: 0.1129\n    Epoch 6/10 | Val CCC: 0.2366, MAE: 0.1122\n    Epoch 7/10 | Val CCC: 0.2379, MAE: 0.1113\n    Epoch 8/10 | Val CCC: 0.2175, MAE: 0.1136\n    Epoch 9/10 | Val CCC: 0.2152, MAE: 0.1120\n    Epoch 10/10 | Val CCC: 0.1765, MAE: 0.1128\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0567, MAE: 0.1191\n    Epoch 2/10 | Val CCC: 0.0904, MAE: 0.1204\n    Epoch 3/10 | Val CCC: 0.1331, MAE: 0.1172\n    Epoch 4/10 | Val CCC: 0.1549, MAE: 0.1139\n    Epoch 5/10 | Val CCC: 0.1341, MAE: 0.1143\n    Epoch 6/10 | Val CCC: 0.1380, MAE: 0.1144\n    Epoch 7/10 | Val CCC: 0.1872, MAE: 0.1139\n    Epoch 8/10 | Val CCC: 0.2546, MAE: 0.1121\n    Epoch 9/10 | Val CCC: 0.2152, MAE: 0.1116\n    Epoch 10/10 | Val CCC: 0.2461, MAE: 0.1116\n  Avg CCC: 0.2363, MAE: 0.1119\n\n>>> Best Config Selected: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n\n>>> Final Training for EXTRAVERSION (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0259\n  Epoch 2/10 - Train Loss: 0.0227\n  Epoch 3/10 - Train Loss: 0.0215\n  Epoch 4/10 - Train Loss: 0.0210\n  Epoch 5/10 - Train Loss: 0.0208\n  Epoch 6/10 - Train Loss: 0.0205\n  Epoch 7/10 - Train Loss: 0.0204\n  Epoch 8/10 - Train Loss: 0.0204\n  Epoch 9/10 - Train Loss: 0.0204\n  Epoch 10/10 - Train Loss: 0.0203\n\n==== EXTRAVERSION Evaluation on Test Set ====\nTest CCC: 0.2529, Test MAE: 0.1166, Accuracy (±0.1): 50.54%\nSaving final model for extraversion to best_video_transformer_model_extraversion.pth\n\n--- Training for Trait: agreeableness ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0194, MAE: 0.1102\n    Epoch 2/10 | Val CCC: 0.0419, MAE: 0.1059\n    Epoch 3/10 | Val CCC: 0.0470, MAE: 0.1059\n    Epoch 4/10 | Val CCC: 0.0449, MAE: 0.1087\n    Epoch 5/10 | Val CCC: 0.0576, MAE: 0.1071\n    Epoch 6/10 | Val CCC: 0.0606, MAE: 0.1093\n    Epoch 7/10 | Val CCC: 0.0636, MAE: 0.1090\n    Epoch 8/10 | Val CCC: 0.0720, MAE: 0.1097\n    Epoch 9/10 | Val CCC: 0.0762, MAE: 0.1092\n    Epoch 10/10 | Val CCC: 0.0906, MAE: 0.1069\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0238, MAE: 0.1160\n    Epoch 2/10 | Val CCC: 0.0291, MAE: 0.1077\n    Epoch 3/10 | Val CCC: 0.0394, MAE: 0.1048\n    Epoch 4/10 | Val CCC: 0.0528, MAE: 0.1090\n    Epoch 5/10 | Val CCC: 0.0580, MAE: 0.1095\n    Epoch 6/10 | Val CCC: 0.0657, MAE: 0.1098\n    Epoch 7/10 | Val CCC: 0.0582, MAE: 0.1157\n    Epoch 8/10 | Val CCC: 0.0673, MAE: 0.1124\n    Epoch 9/10 | Val CCC: 0.0647, MAE: 0.1162\n    Epoch 10/10 | Val CCC: 0.0637, MAE: 0.1149\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0481, MAE: 0.1065\n    Epoch 2/10 | Val CCC: 0.0531, MAE: 0.1049\n    Epoch 3/10 | Val CCC: 0.0581, MAE: 0.1082\n    Epoch 4/10 | Val CCC: 0.0563, MAE: 0.1095\n    Epoch 5/10 | Val CCC: 0.0641, MAE: 0.1077\n    Epoch 6/10 | Val CCC: 0.0600, MAE: 0.1141\n    Epoch 7/10 | Val CCC: 0.0641, MAE: 0.1194\n    Epoch 8/10 | Val CCC: 0.0750, MAE: 0.1136\n    Epoch 9/10 | Val CCC: 0.0936, MAE: 0.1089\n    Epoch 10/10 | Val CCC: 0.0784, MAE: 0.1109\n  Avg CCC: 0.0838, MAE: 0.1094\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0141, MAE: 0.1059\n    Epoch 2/10 | Val CCC: 0.0129, MAE: 0.1081\n    Epoch 3/10 | Val CCC: 0.0160, MAE: 0.1170\n    Epoch 4/10 | Val CCC: 0.0263, MAE: 0.1163\n    Epoch 5/10 | Val CCC: 0.0527, MAE: 0.1125\n    Epoch 6/10 | Val CCC: 0.0529, MAE: 0.1123\n    Epoch 7/10 | Val CCC: 0.0560, MAE: 0.1123\n    Epoch 8/10 | Val CCC: 0.0567, MAE: 0.1131\n    Epoch 9/10 | Val CCC: 0.0776, MAE: 0.1115\n    Epoch 10/10 | Val CCC: 0.0635, MAE: 0.1097\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0199, MAE: 0.1060\n    Epoch 2/10 | Val CCC: 0.0167, MAE: 0.1129\n    Epoch 3/10 | Val CCC: 0.0267, MAE: 0.1134\n    Epoch 4/10 | Val CCC: 0.0427, MAE: 0.1149\n    Epoch 5/10 | Val CCC: 0.0541, MAE: 0.1106\n    Epoch 6/10 | Val CCC: 0.0482, MAE: 0.1137\n    Epoch 7/10 | Val CCC: 0.0590, MAE: 0.1123\n    Epoch 8/10 | Val CCC: 0.0666, MAE: 0.1082\n    Epoch 9/10 | Val CCC: 0.0756, MAE: 0.1113\n    Epoch 10/10 | Val CCC: 0.0784, MAE: 0.1079\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0156, MAE: 0.1053\n    Epoch 2/10 | Val CCC: 0.0168, MAE: 0.1076\n    Epoch 3/10 | Val CCC: 0.0444, MAE: 0.1111\n    Epoch 4/10 | Val CCC: 0.0549, MAE: 0.1157\n    Epoch 5/10 | Val CCC: 0.0667, MAE: 0.1080\n    Epoch 6/10 | Val CCC: 0.0648, MAE: 0.1089\n    Epoch 7/10 | Val CCC: 0.0532, MAE: 0.1121\n    Epoch 8/10 | Val CCC: 0.0717, MAE: 0.1064\n    Epoch 9/10 | Val CCC: 0.0785, MAE: 0.1073\n    Epoch 10/10 | Val CCC: 0.0768, MAE: 0.1067\n  Avg CCC: 0.0781, MAE: 0.1089\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0041, MAE: 0.1189\n    Epoch 2/10 | Val CCC: 0.0245, MAE: 0.1066\n    Epoch 3/10 | Val CCC: 0.0062, MAE: 0.1058\n    Epoch 4/10 | Val CCC: 0.0070, MAE: 0.1058\n    Epoch 5/10 | Val CCC: -0.0021, MAE: 0.1066\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1062\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1064\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1062\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1064\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1062\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0040, MAE: 0.1069\n    Epoch 2/10 | Val CCC: 0.0127, MAE: 0.1065\n    Epoch 3/10 | Val CCC: 0.0053, MAE: 0.1070\n    Epoch 4/10 | Val CCC: 0.0049, MAE: 0.1063\n    Epoch 5/10 | Val CCC: 0.0079, MAE: 0.1057\n    Epoch 6/10 | Val CCC: 0.0001, MAE: 0.1059\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1061\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1063\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1059\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1062\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0030, MAE: 0.1110\n    Epoch 2/10 | Val CCC: 0.0204, MAE: 0.1073\n    Epoch 3/10 | Val CCC: 0.0068, MAE: 0.1053\n    Epoch 4/10 | Val CCC: 0.0077, MAE: 0.1052\n    Epoch 5/10 | Val CCC: 0.0001, MAE: 0.1055\n    Epoch 6/10 | Val CCC: 0.0015, MAE: 0.1054\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1055\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1057\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1054\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1054\n  Avg CCC: 0.0192, MAE: 0.1068\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0042, MAE: 0.1226\n    Epoch 2/10 | Val CCC: 0.0089, MAE: 0.1059\n    Epoch 3/10 | Val CCC: 0.0172, MAE: 0.1057\n    Epoch 4/10 | Val CCC: 0.0054, MAE: 0.1059\n    Epoch 5/10 | Val CCC: 0.0000, MAE: 0.1061\n    Epoch 6/10 | Val CCC: 0.0008, MAE: 0.1061\n    Epoch 7/10 | Val CCC: 0.0004, MAE: 0.1061\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1061\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1061\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1061\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0042, MAE: 0.1059\n    Epoch 2/10 | Val CCC: 0.0113, MAE: 0.1081\n    Epoch 3/10 | Val CCC: 0.0111, MAE: 0.1102\n    Epoch 4/10 | Val CCC: 0.0095, MAE: 0.1057\n    Epoch 5/10 | Val CCC: 0.0017, MAE: 0.1058\n    Epoch 6/10 | Val CCC: 0.0003, MAE: 0.1059\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1060\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1059\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1059\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1059\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0058, MAE: 0.1051\n    Epoch 2/10 | Val CCC: 0.0072, MAE: 0.1168\n    Epoch 3/10 | Val CCC: 0.0089, MAE: 0.1057\n    Epoch 4/10 | Val CCC: 0.0005, MAE: 0.1056\n    Epoch 5/10 | Val CCC: 0.0000, MAE: 0.1057\n    Epoch 6/10 | Val CCC: -0.0000, MAE: 0.1059\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1055\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1054\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1054\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1054\n  Avg CCC: 0.0125, MAE: 0.1065\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0035, MAE: 0.1130\n    Epoch 2/10 | Val CCC: 0.0027, MAE: 0.1118\n    Epoch 3/10 | Val CCC: 0.0128, MAE: 0.1073\n    Epoch 4/10 | Val CCC: 0.0029, MAE: 0.1061\n    Epoch 5/10 | Val CCC: 0.0000, MAE: 0.1061\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1061\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1061\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1063\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1061\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1061\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0000, MAE: 0.1303\n    Epoch 2/10 | Val CCC: -0.0001, MAE: 0.1127\n    Epoch 3/10 | Val CCC: 0.0051, MAE: 0.1078\n    Epoch 4/10 | Val CCC: -0.0002, MAE: 0.1059\n    Epoch 5/10 | Val CCC: -0.0001, MAE: 0.1060\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1059\n    Epoch 7/10 | Val CCC: 0.0001, MAE: 0.1058\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1064\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1060\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1062\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0004, MAE: 0.1085\n    Epoch 2/10 | Val CCC: 0.0018, MAE: 0.1146\n    Epoch 3/10 | Val CCC: 0.0029, MAE: 0.1101\n    Epoch 4/10 | Val CCC: 0.0000, MAE: 0.1062\n    Epoch 5/10 | Val CCC: -0.0000, MAE: 0.1054\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1054\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1058\n    Epoch 8/10 | Val CCC: -0.0000, MAE: 0.1053\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1058\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1055\n  Avg CCC: 0.0069, MAE: 0.1084\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0536, MAE: 0.1048\n    Epoch 2/10 | Val CCC: 0.0635, MAE: 0.1070\n    Epoch 3/10 | Val CCC: 0.0661, MAE: 0.1045\n    Epoch 4/10 | Val CCC: 0.0792, MAE: 0.1047\n    Epoch 5/10 | Val CCC: 0.0685, MAE: 0.1039\n    Epoch 6/10 | Val CCC: 0.0763, MAE: 0.1040\n    Epoch 7/10 | Val CCC: 0.1012, MAE: 0.1035\n    Epoch 8/10 | Val CCC: 0.0999, MAE: 0.1029\n    Epoch 9/10 | Val CCC: 0.1036, MAE: 0.1032\n    Epoch 10/10 | Val CCC: 0.1163, MAE: 0.1026\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0406, MAE: 0.1054\n    Epoch 2/10 | Val CCC: 0.0465, MAE: 0.1050\n    Epoch 3/10 | Val CCC: 0.0618, MAE: 0.1045\n    Epoch 4/10 | Val CCC: 0.0760, MAE: 0.1033\n    Epoch 5/10 | Val CCC: 0.0687, MAE: 0.1049\n    Epoch 6/10 | Val CCC: 0.0705, MAE: 0.1047\n    Epoch 7/10 | Val CCC: 0.0898, MAE: 0.1033\n    Epoch 8/10 | Val CCC: 0.0984, MAE: 0.1058\n    Epoch 9/10 | Val CCC: 0.0901, MAE: 0.1028\n    Epoch 10/10 | Val CCC: 0.0809, MAE: 0.1030\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0345, MAE: 0.1042\n    Epoch 2/10 | Val CCC: 0.0572, MAE: 0.1038\n    Epoch 3/10 | Val CCC: 0.0739, MAE: 0.1035\n    Epoch 4/10 | Val CCC: 0.0845, MAE: 0.1034\n    Epoch 5/10 | Val CCC: 0.0791, MAE: 0.1042\n    Epoch 6/10 | Val CCC: 0.1069, MAE: 0.1022\n    Epoch 7/10 | Val CCC: 0.0929, MAE: 0.1030\n    Epoch 8/10 | Val CCC: 0.1051, MAE: 0.1019\n    Epoch 9/10 | Val CCC: 0.1072, MAE: 0.1049\n    Epoch 10/10 | Val CCC: 0.1076, MAE: 0.1019\n  Avg CCC: 0.1074, MAE: 0.1034\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0059, MAE: 0.1173\n    Epoch 2/10 | Val CCC: 0.0269, MAE: 0.1090\n    Epoch 3/10 | Val CCC: 0.0542, MAE: 0.1081\n    Epoch 4/10 | Val CCC: 0.0399, MAE: 0.1043\n    Epoch 5/10 | Val CCC: 0.0524, MAE: 0.1070\n    Epoch 6/10 | Val CCC: 0.0551, MAE: 0.1073\n    Epoch 7/10 | Val CCC: 0.0617, MAE: 0.1054\n    Epoch 8/10 | Val CCC: 0.0864, MAE: 0.1047\n    Epoch 9/10 | Val CCC: 0.0666, MAE: 0.1043\n    Epoch 10/10 | Val CCC: 0.0343, MAE: 0.1045\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0122, MAE: 0.1108\n    Epoch 2/10 | Val CCC: 0.0357, MAE: 0.1052\n    Epoch 3/10 | Val CCC: 0.0380, MAE: 0.1075\n    Epoch 4/10 | Val CCC: 0.0518, MAE: 0.1050\n    Epoch 5/10 | Val CCC: 0.0449, MAE: 0.1043\n    Epoch 6/10 | Val CCC: 0.0542, MAE: 0.1043\n    Epoch 7/10 | Val CCC: 0.0260, MAE: 0.1056\n    Epoch 8/10 | Val CCC: 0.0523, MAE: 0.1038\n    Epoch 9/10 | Val CCC: 0.0534, MAE: 0.1042\n    Epoch 10/10 | Val CCC: 0.0473, MAE: 0.1051\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0069, MAE: 0.1052\n    Epoch 2/10 | Val CCC: 0.0424, MAE: 0.1043\n    Epoch 3/10 | Val CCC: 0.0523, MAE: 0.1034\n    Epoch 4/10 | Val CCC: 0.0400, MAE: 0.1046\n    Epoch 5/10 | Val CCC: 0.0409, MAE: 0.1091\n    Epoch 6/10 | Val CCC: 0.0656, MAE: 0.1043\n    Epoch 7/10 | Val CCC: 0.0425, MAE: 0.1067\n    Epoch 8/10 | Val CCC: 0.0446, MAE: 0.1042\n    Epoch 9/10 | Val CCC: 0.0583, MAE: 0.1054\n    Epoch 10/10 | Val CCC: 0.0634, MAE: 0.1041\n  Avg CCC: 0.0688, MAE: 0.1044\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0435, MAE: 0.1064\n    Epoch 2/10 | Val CCC: 0.0533, MAE: 0.1069\n    Epoch 3/10 | Val CCC: 0.0627, MAE: 0.1043\n    Epoch 4/10 | Val CCC: 0.0666, MAE: 0.1046\n    Epoch 5/10 | Val CCC: 0.0778, MAE: 0.1042\n    Epoch 6/10 | Val CCC: 0.0777, MAE: 0.1050\n    Epoch 7/10 | Val CCC: 0.0879, MAE: 0.1040\n    Epoch 8/10 | Val CCC: 0.0820, MAE: 0.1037\n    Epoch 9/10 | Val CCC: 0.0913, MAE: 0.1042\n    Epoch 10/10 | Val CCC: 0.1061, MAE: 0.1037\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0326, MAE: 0.1068\n    Epoch 2/10 | Val CCC: 0.0498, MAE: 0.1071\n    Epoch 3/10 | Val CCC: 0.0393, MAE: 0.1058\n    Epoch 4/10 | Val CCC: 0.0627, MAE: 0.1048\n    Epoch 5/10 | Val CCC: 0.0610, MAE: 0.1042\n    Epoch 6/10 | Val CCC: 0.0668, MAE: 0.1043\n    Epoch 7/10 | Val CCC: 0.0757, MAE: 0.1044\n    Epoch 8/10 | Val CCC: 0.0784, MAE: 0.1057\n    Epoch 9/10 | Val CCC: 0.0927, MAE: 0.1045\n    Epoch 10/10 | Val CCC: 0.0990, MAE: 0.1050\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0452, MAE: 0.1061\n    Epoch 2/10 | Val CCC: 0.0465, MAE: 0.1043\n    Epoch 3/10 | Val CCC: 0.0664, MAE: 0.1035\n    Epoch 4/10 | Val CCC: 0.0690, MAE: 0.1040\n    Epoch 5/10 | Val CCC: 0.0831, MAE: 0.1034\n    Epoch 6/10 | Val CCC: 0.0889, MAE: 0.1043\n    Epoch 7/10 | Val CCC: 0.0863, MAE: 0.1028\n    Epoch 8/10 | Val CCC: 0.0969, MAE: 0.1028\n    Epoch 9/10 | Val CCC: 0.1019, MAE: 0.1021\n    Epoch 10/10 | Val CCC: 0.0918, MAE: 0.1045\n  Avg CCC: 0.1023, MAE: 0.1036\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0044, MAE: 0.1110\n    Epoch 2/10 | Val CCC: 0.0107, MAE: 0.1075\n    Epoch 3/10 | Val CCC: 0.0175, MAE: 0.1056\n    Epoch 4/10 | Val CCC: 0.0053, MAE: 0.1058\n    Epoch 5/10 | Val CCC: 0.0064, MAE: 0.1057\n    Epoch 6/10 | Val CCC: 0.0016, MAE: 0.1061\n    Epoch 7/10 | Val CCC: 0.0016, MAE: 0.1060\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1061\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1061\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1061\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0059, MAE: 0.1278\n    Epoch 2/10 | Val CCC: 0.0159, MAE: 0.1056\n    Epoch 3/10 | Val CCC: 0.0137, MAE: 0.1059\n    Epoch 4/10 | Val CCC: 0.0118, MAE: 0.1060\n    Epoch 5/10 | Val CCC: 0.0257, MAE: 0.1052\n    Epoch 6/10 | Val CCC: 0.0115, MAE: 0.1058\n    Epoch 7/10 | Val CCC: 0.0006, MAE: 0.1059\n    Epoch 8/10 | Val CCC: 0.0030, MAE: 0.1058\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1059\n    Epoch 10/10 | Val CCC: 0.0001, MAE: 0.1061\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0053, MAE: 0.1318\n    Epoch 2/10 | Val CCC: 0.0078, MAE: 0.1056\n    Epoch 3/10 | Val CCC: 0.0102, MAE: 0.1050\n    Epoch 4/10 | Val CCC: 0.0061, MAE: 0.1055\n    Epoch 5/10 | Val CCC: 0.0005, MAE: 0.1055\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1054\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1055\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1054\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1054\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1063\n  Avg CCC: 0.0178, MAE: 0.1053\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0496, MAE: 0.1051\n    Epoch 2/10 | Val CCC: 0.0692, MAE: 0.1045\n    Epoch 3/10 | Val CCC: 0.0607, MAE: 0.1050\n    Epoch 4/10 | Val CCC: 0.0770, MAE: 0.1044\n    Epoch 5/10 | Val CCC: 0.0723, MAE: 0.1037\n    Epoch 6/10 | Val CCC: 0.0871, MAE: 0.1044\n    Epoch 7/10 | Val CCC: 0.0817, MAE: 0.1042\n    Epoch 8/10 | Val CCC: 0.0699, MAE: 0.1055\n    Epoch 9/10 | Val CCC: 0.1073, MAE: 0.1033\n    Epoch 10/10 | Val CCC: 0.1009, MAE: 0.1040\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0309, MAE: 0.1062\n    Epoch 2/10 | Val CCC: 0.0673, MAE: 0.1050\n    Epoch 3/10 | Val CCC: 0.0658, MAE: 0.1042\n    Epoch 4/10 | Val CCC: 0.0734, MAE: 0.1041\n    Epoch 5/10 | Val CCC: 0.0728, MAE: 0.1035\n    Epoch 6/10 | Val CCC: 0.0722, MAE: 0.1052\n    Epoch 7/10 | Val CCC: 0.0862, MAE: 0.1033\n    Epoch 8/10 | Val CCC: 0.0871, MAE: 0.1030\n    Epoch 9/10 | Val CCC: 0.0953, MAE: 0.1032\n    Epoch 10/10 | Val CCC: 0.1070, MAE: 0.1035\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0751, MAE: 0.1067\n    Epoch 2/10 | Val CCC: 0.0537, MAE: 0.1054\n    Epoch 3/10 | Val CCC: 0.0743, MAE: 0.1053\n    Epoch 4/10 | Val CCC: 0.0586, MAE: 0.1041\n    Epoch 5/10 | Val CCC: 0.0929, MAE: 0.1033\n    Epoch 6/10 | Val CCC: 0.0880, MAE: 0.1027\n    Epoch 7/10 | Val CCC: 0.0998, MAE: 0.1024\n    Epoch 8/10 | Val CCC: 0.0804, MAE: 0.1044\n    Epoch 9/10 | Val CCC: 0.1076, MAE: 0.1022\n    Epoch 10/10 | Val CCC: 0.0971, MAE: 0.1035\n  Avg CCC: 0.1073, MAE: 0.1030\n\n>>> Best Config Selected: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n\n>>> Final Training for AGREEABLENESS (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0226\n  Epoch 2/10 - Train Loss: 0.0191\n  Epoch 3/10 - Train Loss: 0.0185\n  Epoch 4/10 - Train Loss: 0.0182\n  Epoch 5/10 - Train Loss: 0.0181\n  Epoch 6/10 - Train Loss: 0.0179\n  Epoch 7/10 - Train Loss: 0.0178\n  Epoch 8/10 - Train Loss: 0.0177\n  Epoch 9/10 - Train Loss: 0.0175\n  Epoch 10/10 - Train Loss: 0.0176\n\n==== AGREEABLENESS Evaluation on Test Set ====\nTest CCC: 0.1152, Test MAE: 0.1037, Accuracy (±0.1): 56.23%\nSaving final model for agreeableness to best_video_transformer_model_agreeableness.pth\n\n--- Training for Trait: neuroticism ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0206, MAE: 0.1248\n    Epoch 2/10 | Val CCC: 0.0335, MAE: 0.1327\n    Epoch 3/10 | Val CCC: 0.0419, MAE: 0.1355\n    Epoch 4/10 | Val CCC: 0.0661, MAE: 0.1341\n    Epoch 5/10 | Val CCC: 0.1029, MAE: 0.1347\n    Epoch 6/10 | Val CCC: 0.1071, MAE: 0.1302\n    Epoch 7/10 | Val CCC: 0.1175, MAE: 0.1271\n    Epoch 8/10 | Val CCC: 0.1416, MAE: 0.1263\n    Epoch 9/10 | Val CCC: 0.1284, MAE: 0.1255\n    Epoch 10/10 | Val CCC: 0.1485, MAE: 0.1254\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0427, MAE: 0.1226\n    Epoch 2/10 | Val CCC: 0.0442, MAE: 0.1223\n    Epoch 3/10 | Val CCC: 0.0830, MAE: 0.1248\n    Epoch 4/10 | Val CCC: 0.0750, MAE: 0.1379\n    Epoch 5/10 | Val CCC: 0.0701, MAE: 0.1273\n    Epoch 6/10 | Val CCC: 0.1152, MAE: 0.1253\n    Epoch 7/10 | Val CCC: 0.1304, MAE: 0.1230\n    Epoch 8/10 | Val CCC: 0.1352, MAE: 0.1226\n    Epoch 9/10 | Val CCC: 0.1580, MAE: 0.1244\n    Epoch 10/10 | Val CCC: 0.1177, MAE: 0.1207\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0440, MAE: 0.1223\n    Epoch 2/10 | Val CCC: 0.0483, MAE: 0.1329\n    Epoch 3/10 | Val CCC: 0.0774, MAE: 0.1297\n    Epoch 4/10 | Val CCC: 0.1247, MAE: 0.1265\n    Epoch 5/10 | Val CCC: 0.0894, MAE: 0.1285\n    Epoch 6/10 | Val CCC: 0.1365, MAE: 0.1232\n    Epoch 7/10 | Val CCC: 0.1501, MAE: 0.1260\n    Epoch 8/10 | Val CCC: 0.1366, MAE: 0.1269\n    Epoch 9/10 | Val CCC: 0.1562, MAE: 0.1208\n    Epoch 10/10 | Val CCC: 0.1566, MAE: 0.1182\n  Avg CCC: 0.1544, MAE: 0.1227\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0238, MAE: 0.1219\n    Epoch 2/10 | Val CCC: 0.0259, MAE: 0.1217\n    Epoch 3/10 | Val CCC: 0.0288, MAE: 0.1215\n    Epoch 4/10 | Val CCC: 0.0078, MAE: 0.1233\n    Epoch 5/10 | Val CCC: 0.0000, MAE: 0.1236\n    Epoch 6/10 | Val CCC: 0.0124, MAE: 0.1222\n    Epoch 7/10 | Val CCC: -0.0000, MAE: 0.1227\n    Epoch 8/10 | Val CCC: 0.0001, MAE: 0.1234\n    Epoch 9/10 | Val CCC: -0.0000, MAE: 0.1228\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1227\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0294, MAE: 0.1221\n    Epoch 2/10 | Val CCC: 0.0269, MAE: 0.1216\n    Epoch 3/10 | Val CCC: 0.0161, MAE: 0.1219\n    Epoch 4/10 | Val CCC: 0.0292, MAE: 0.1218\n    Epoch 5/10 | Val CCC: -0.0007, MAE: 0.1226\n    Epoch 6/10 | Val CCC: 0.0149, MAE: 0.1254\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1244\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1240\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1225\n    Epoch 10/10 | Val CCC: -0.0000, MAE: 0.1231\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0378, MAE: 0.1214\n    Epoch 2/10 | Val CCC: 0.0217, MAE: 0.1222\n    Epoch 3/10 | Val CCC: 0.0145, MAE: 0.1280\n    Epoch 4/10 | Val CCC: 0.0182, MAE: 0.1212\n    Epoch 5/10 | Val CCC: 0.0056, MAE: 0.1235\n    Epoch 6/10 | Val CCC: 0.0126, MAE: 0.1223\n    Epoch 7/10 | Val CCC: 0.0001, MAE: 0.1251\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1226\n    Epoch 9/10 | Val CCC: 0.0290, MAE: 0.1213\n    Epoch 10/10 | Val CCC: 0.0183, MAE: 0.1215\n  Avg CCC: 0.0320, MAE: 0.1217\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0518, MAE: 0.1230\n    Epoch 2/10 | Val CCC: 0.0993, MAE: 0.1197\n    Epoch 3/10 | Val CCC: 0.0743, MAE: 0.1211\n    Epoch 4/10 | Val CCC: 0.0498, MAE: 0.1204\n    Epoch 5/10 | Val CCC: 0.0744, MAE: 0.1194\n    Epoch 6/10 | Val CCC: 0.0707, MAE: 0.1220\n    Epoch 7/10 | Val CCC: 0.0790, MAE: 0.1199\n    Epoch 8/10 | Val CCC: 0.1173, MAE: 0.1200\n    Epoch 9/10 | Val CCC: 0.0875, MAE: 0.1212\n    Epoch 10/10 | Val CCC: 0.1229, MAE: 0.1186\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0460, MAE: 0.1208\n    Epoch 2/10 | Val CCC: 0.0743, MAE: 0.1228\n    Epoch 3/10 | Val CCC: 0.0868, MAE: 0.1198\n    Epoch 4/10 | Val CCC: 0.0783, MAE: 0.1202\n    Epoch 5/10 | Val CCC: 0.1106, MAE: 0.1270\n    Epoch 6/10 | Val CCC: 0.0887, MAE: 0.1187\n    Epoch 7/10 | Val CCC: 0.1028, MAE: 0.1194\n    Epoch 8/10 | Val CCC: 0.0986, MAE: 0.1218\n    Epoch 9/10 | Val CCC: 0.0799, MAE: 0.1183\n    Epoch 10/10 | Val CCC: 0.1086, MAE: 0.1180\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0332, MAE: 0.1306\n    Epoch 2/10 | Val CCC: 0.0641, MAE: 0.1198\n    Epoch 3/10 | Val CCC: 0.0720, MAE: 0.1200\n    Epoch 4/10 | Val CCC: 0.1204, MAE: 0.1182\n    Epoch 5/10 | Val CCC: 0.0861, MAE: 0.1196\n    Epoch 6/10 | Val CCC: 0.0973, MAE: 0.1181\n    Epoch 7/10 | Val CCC: 0.1461, MAE: 0.1161\n    Epoch 8/10 | Val CCC: 0.0613, MAE: 0.1245\n    Epoch 9/10 | Val CCC: 0.1348, MAE: 0.1183\n    Epoch 10/10 | Val CCC: 0.1377, MAE: 0.1170\n  Avg CCC: 0.1265, MAE: 0.1206\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0237, MAE: 0.1218\n    Epoch 2/10 | Val CCC: 0.0202, MAE: 0.1308\n    Epoch 3/10 | Val CCC: 0.0343, MAE: 0.1264\n    Epoch 4/10 | Val CCC: 0.0337, MAE: 0.1223\n    Epoch 5/10 | Val CCC: 0.0163, MAE: 0.1221\n    Epoch 6/10 | Val CCC: -0.0000, MAE: 0.1241\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1237\n    Epoch 8/10 | Val CCC: -0.0000, MAE: 0.1237\n    Epoch 9/10 | Val CCC: -0.0000, MAE: 0.1231\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1227\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0217, MAE: 0.1244\n    Epoch 2/10 | Val CCC: 0.0229, MAE: 0.1257\n    Epoch 3/10 | Val CCC: 0.0123, MAE: 0.1218\n    Epoch 4/10 | Val CCC: 0.0200, MAE: 0.1270\n    Epoch 5/10 | Val CCC: 0.0005, MAE: 0.1229\n    Epoch 6/10 | Val CCC: 0.0156, MAE: 0.1236\n    Epoch 7/10 | Val CCC: 0.0150, MAE: 0.1224\n    Epoch 8/10 | Val CCC: -0.0006, MAE: 0.1233\n    Epoch 9/10 | Val CCC: 0.0197, MAE: 0.1225\n    Epoch 10/10 | Val CCC: 0.0002, MAE: 0.1225\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0196, MAE: 0.1212\n    Epoch 2/10 | Val CCC: 0.0476, MAE: 0.1217\n    Epoch 3/10 | Val CCC: 0.0220, MAE: 0.1214\n    Epoch 4/10 | Val CCC: 0.0297, MAE: 0.1210\n    Epoch 5/10 | Val CCC: 0.0085, MAE: 0.1216\n    Epoch 6/10 | Val CCC: 0.0112, MAE: 0.1218\n    Epoch 7/10 | Val CCC: -0.0000, MAE: 0.1220\n    Epoch 8/10 | Val CCC: 0.0008, MAE: 0.1225\n    Epoch 9/10 | Val CCC: 0.0106, MAE: 0.1221\n    Epoch 10/10 | Val CCC: -0.0000, MAE: 0.1221\n  Avg CCC: 0.0349, MAE: 0.1246\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0405, MAE: 0.1285\n    Epoch 2/10 | Val CCC: 0.0612, MAE: 0.1217\n    Epoch 3/10 | Val CCC: 0.0606, MAE: 0.1200\n    Epoch 4/10 | Val CCC: 0.1014, MAE: 0.1205\n    Epoch 5/10 | Val CCC: 0.0959, MAE: 0.1211\n    Epoch 6/10 | Val CCC: 0.0956, MAE: 0.1192\n    Epoch 7/10 | Val CCC: 0.0942, MAE: 0.1192\n    Epoch 8/10 | Val CCC: 0.1160, MAE: 0.1189\n    Epoch 9/10 | Val CCC: 0.1592, MAE: 0.1205\n    Epoch 10/10 | Val CCC: 0.1155, MAE: 0.1180\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0289, MAE: 0.1272\n    Epoch 2/10 | Val CCC: 0.0391, MAE: 0.1313\n    Epoch 3/10 | Val CCC: 0.0891, MAE: 0.1249\n    Epoch 4/10 | Val CCC: 0.0765, MAE: 0.1213\n    Epoch 5/10 | Val CCC: 0.0713, MAE: 0.1207\n    Epoch 6/10 | Val CCC: 0.1245, MAE: 0.1228\n    Epoch 7/10 | Val CCC: 0.0943, MAE: 0.1217\n    Epoch 8/10 | Val CCC: 0.1281, MAE: 0.1206\n    Epoch 9/10 | Val CCC: 0.1363, MAE: 0.1189\n    Epoch 10/10 | Val CCC: 0.0640, MAE: 0.1221\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0399, MAE: 0.1223\n    Epoch 2/10 | Val CCC: 0.0749, MAE: 0.1225\n    Epoch 3/10 | Val CCC: 0.0948, MAE: 0.1213\n    Epoch 4/10 | Val CCC: 0.0857, MAE: 0.1193\n    Epoch 5/10 | Val CCC: 0.0736, MAE: 0.1199\n    Epoch 6/10 | Val CCC: 0.0478, MAE: 0.1196\n    Epoch 7/10 | Val CCC: 0.1367, MAE: 0.1188\n    Epoch 8/10 | Val CCC: 0.0987, MAE: 0.1174\n    Epoch 9/10 | Val CCC: 0.0910, MAE: 0.1177\n    Epoch 10/10 | Val CCC: 0.1281, MAE: 0.1160\n  Avg CCC: 0.1441, MAE: 0.1194\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0191, MAE: 0.1339\n    Epoch 2/10 | Val CCC: 0.0431, MAE: 0.1289\n    Epoch 3/10 | Val CCC: 0.0631, MAE: 0.1352\n    Epoch 4/10 | Val CCC: 0.0869, MAE: 0.1338\n    Epoch 5/10 | Val CCC: 0.0820, MAE: 0.1254\n    Epoch 6/10 | Val CCC: 0.1387, MAE: 0.1204\n    Epoch 7/10 | Val CCC: 0.1308, MAE: 0.1216\n    Epoch 8/10 | Val CCC: 0.1437, MAE: 0.1221\n    Epoch 9/10 | Val CCC: 0.1854, MAE: 0.1174\n    Epoch 10/10 | Val CCC: 0.1642, MAE: 0.1215\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0565, MAE: 0.1269\n    Epoch 2/10 | Val CCC: 0.0386, MAE: 0.1405\n    Epoch 3/10 | Val CCC: 0.0757, MAE: 0.1316\n    Epoch 4/10 | Val CCC: 0.0978, MAE: 0.1323\n    Epoch 5/10 | Val CCC: 0.0825, MAE: 0.1250\n    Epoch 6/10 | Val CCC: 0.1128, MAE: 0.1232\n    Epoch 7/10 | Val CCC: 0.1607, MAE: 0.1226\n    Epoch 8/10 | Val CCC: 0.1130, MAE: 0.1193\n    Epoch 9/10 | Val CCC: 0.0845, MAE: 0.1227\n    Epoch 10/10 | Val CCC: 0.1460, MAE: 0.1192\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0397, MAE: 0.1250\n    Epoch 2/10 | Val CCC: 0.0308, MAE: 0.1419\n    Epoch 3/10 | Val CCC: 0.0454, MAE: 0.1248\n    Epoch 4/10 | Val CCC: 0.0845, MAE: 0.1209\n    Epoch 5/10 | Val CCC: 0.1181, MAE: 0.1268\n    Epoch 6/10 | Val CCC: 0.1452, MAE: 0.1198\n    Epoch 7/10 | Val CCC: 0.1502, MAE: 0.1184\n    Epoch 8/10 | Val CCC: 0.1582, MAE: 0.1199\n    Epoch 9/10 | Val CCC: 0.1639, MAE: 0.1166\n    Epoch 10/10 | Val CCC: 0.1630, MAE: 0.1197\n  Avg CCC: 0.1700, MAE: 0.1189\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0169, MAE: 0.1418\n    Epoch 2/10 | Val CCC: 0.0300, MAE: 0.1327\n    Epoch 3/10 | Val CCC: 0.0247, MAE: 0.1311\n    Epoch 4/10 | Val CCC: 0.0283, MAE: 0.1260\n    Epoch 5/10 | Val CCC: 0.0280, MAE: 0.1226\n    Epoch 6/10 | Val CCC: 0.0474, MAE: 0.1216\n    Epoch 7/10 | Val CCC: 0.0445, MAE: 0.1214\n    Epoch 8/10 | Val CCC: 0.0453, MAE: 0.1207\n    Epoch 9/10 | Val CCC: 0.0458, MAE: 0.1213\n    Epoch 10/10 | Val CCC: 0.0487, MAE: 0.1211\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0215, MAE: 0.1263\n    Epoch 2/10 | Val CCC: 0.0320, MAE: 0.1256\n    Epoch 3/10 | Val CCC: 0.0335, MAE: 0.1215\n    Epoch 4/10 | Val CCC: 0.0462, MAE: 0.1221\n    Epoch 5/10 | Val CCC: 0.0356, MAE: 0.1213\n    Epoch 6/10 | Val CCC: 0.0409, MAE: 0.1239\n    Epoch 7/10 | Val CCC: 0.0605, MAE: 0.1203\n    Epoch 8/10 | Val CCC: 0.0836, MAE: 0.1195\n    Epoch 9/10 | Val CCC: 0.0717, MAE: 0.1222\n    Epoch 10/10 | Val CCC: 0.0847, MAE: 0.1194\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0265, MAE: 0.1238\n    Epoch 2/10 | Val CCC: 0.0215, MAE: 0.1285\n    Epoch 3/10 | Val CCC: 0.0252, MAE: 0.1261\n    Epoch 4/10 | Val CCC: 0.0285, MAE: 0.1208\n    Epoch 5/10 | Val CCC: 0.0361, MAE: 0.1218\n    Epoch 6/10 | Val CCC: 0.0346, MAE: 0.1207\n    Epoch 7/10 | Val CCC: 0.0647, MAE: 0.1199\n    Epoch 8/10 | Val CCC: 0.0619, MAE: 0.1204\n    Epoch 9/10 | Val CCC: 0.0451, MAE: 0.1206\n    Epoch 10/10 | Val CCC: 0.0354, MAE: 0.1206\n  Avg CCC: 0.0661, MAE: 0.1201\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0358, MAE: 0.1218\n    Epoch 2/10 | Val CCC: 0.0356, MAE: 0.1344\n    Epoch 3/10 | Val CCC: 0.0367, MAE: 0.1220\n    Epoch 4/10 | Val CCC: 0.0351, MAE: 0.1218\n    Epoch 5/10 | Val CCC: 0.0472, MAE: 0.1205\n    Epoch 6/10 | Val CCC: 0.0325, MAE: 0.1214\n    Epoch 7/10 | Val CCC: 0.0834, MAE: 0.1203\n    Epoch 8/10 | Val CCC: 0.0083, MAE: 0.1221\n    Epoch 9/10 | Val CCC: 0.0226, MAE: 0.1217\n    Epoch 10/10 | Val CCC: 0.0302, MAE: 0.1217\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0272, MAE: 0.1214\n    Epoch 2/10 | Val CCC: 0.0347, MAE: 0.1211\n    Epoch 3/10 | Val CCC: 0.0417, MAE: 0.1210\n    Epoch 4/10 | Val CCC: 0.0052, MAE: 0.1223\n    Epoch 5/10 | Val CCC: 0.0762, MAE: 0.1210\n    Epoch 6/10 | Val CCC: 0.0604, MAE: 0.1200\n    Epoch 7/10 | Val CCC: 0.0427, MAE: 0.1203\n    Epoch 8/10 | Val CCC: 0.0382, MAE: 0.1210\n    Epoch 9/10 | Val CCC: 0.0431, MAE: 0.1214\n    Epoch 10/10 | Val CCC: 0.0524, MAE: 0.1204\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0251, MAE: 0.1227\n    Epoch 2/10 | Val CCC: 0.0361, MAE: 0.1213\n    Epoch 3/10 | Val CCC: 0.0602, MAE: 0.1204\n    Epoch 4/10 | Val CCC: 0.0499, MAE: 0.1208\n    Epoch 5/10 | Val CCC: 0.0442, MAE: 0.1209\n    Epoch 6/10 | Val CCC: 0.0460, MAE: 0.1209\n    Epoch 7/10 | Val CCC: 0.0517, MAE: 0.1208\n    Epoch 8/10 | Val CCC: 0.0130, MAE: 0.1218\n    Epoch 9/10 | Val CCC: 0.0121, MAE: 0.1215\n    Epoch 10/10 | Val CCC: 0.0145, MAE: 0.1215\n  Avg CCC: 0.0733, MAE: 0.1206\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0181, MAE: 0.1226\n    Epoch 2/10 | Val CCC: 0.0255, MAE: 0.1283\n    Epoch 3/10 | Val CCC: 0.0315, MAE: 0.1280\n    Epoch 4/10 | Val CCC: 0.0384, MAE: 0.1212\n    Epoch 5/10 | Val CCC: 0.0620, MAE: 0.1209\n    Epoch 6/10 | Val CCC: 0.0785, MAE: 0.1192\n    Epoch 7/10 | Val CCC: 0.1343, MAE: 0.1190\n    Epoch 8/10 | Val CCC: 0.1212, MAE: 0.1181\n    Epoch 9/10 | Val CCC: 0.1479, MAE: 0.1189\n    Epoch 10/10 | Val CCC: 0.1259, MAE: 0.1180\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0235, MAE: 0.1220\n    Epoch 2/10 | Val CCC: 0.0227, MAE: 0.1214\n    Epoch 3/10 | Val CCC: 0.0583, MAE: 0.1230\n    Epoch 4/10 | Val CCC: 0.0504, MAE: 0.1204\n    Epoch 5/10 | Val CCC: 0.0704, MAE: 0.1228\n    Epoch 6/10 | Val CCC: 0.0644, MAE: 0.1212\n    Epoch 7/10 | Val CCC: 0.1291, MAE: 0.1195\n    Epoch 8/10 | Val CCC: 0.1045, MAE: 0.1195\n    Epoch 9/10 | Val CCC: 0.1447, MAE: 0.1173\n    Epoch 10/10 | Val CCC: 0.1208, MAE: 0.1181\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0250, MAE: 0.1226\n    Epoch 2/10 | Val CCC: 0.0260, MAE: 0.1267\n    Epoch 3/10 | Val CCC: 0.0400, MAE: 0.1221\n    Epoch 4/10 | Val CCC: 0.0889, MAE: 0.1217\n    Epoch 5/10 | Val CCC: 0.0705, MAE: 0.1195\n    Epoch 6/10 | Val CCC: 0.0927, MAE: 0.1208\n    Epoch 7/10 | Val CCC: 0.0896, MAE: 0.1187\n    Epoch 8/10 | Val CCC: 0.0956, MAE: 0.1190\n    Epoch 9/10 | Val CCC: 0.0734, MAE: 0.1183\n    Epoch 10/10 | Val CCC: 0.1588, MAE: 0.1165\n  Avg CCC: 0.1505, MAE: 0.1176\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0766, MAE: 0.1204\n    Epoch 2/10 | Val CCC: 0.1022, MAE: 0.1181\n    Epoch 3/10 | Val CCC: 0.1174, MAE: 0.1206\n    Epoch 4/10 | Val CCC: 0.1109, MAE: 0.1184\n    Epoch 5/10 | Val CCC: 0.1425, MAE: 0.1181\n    Epoch 6/10 | Val CCC: 0.1421, MAE: 0.1174\n    Epoch 7/10 | Val CCC: 0.1220, MAE: 0.1172\n    Epoch 8/10 | Val CCC: 0.1248, MAE: 0.1182\n    Epoch 9/10 | Val CCC: 0.1541, MAE: 0.1170\n    Epoch 10/10 | Val CCC: 0.1837, MAE: 0.1173\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0686, MAE: 0.1202\n    Epoch 2/10 | Val CCC: 0.1003, MAE: 0.1187\n    Epoch 3/10 | Val CCC: 0.1226, MAE: 0.1181\n    Epoch 4/10 | Val CCC: 0.1124, MAE: 0.1178\n    Epoch 5/10 | Val CCC: 0.1385, MAE: 0.1168\n    Epoch 6/10 | Val CCC: 0.1524, MAE: 0.1168\n    Epoch 7/10 | Val CCC: 0.1624, MAE: 0.1202\n    Epoch 8/10 | Val CCC: 0.1711, MAE: 0.1186\n    Epoch 9/10 | Val CCC: 0.1763, MAE: 0.1161\n    Epoch 10/10 | Val CCC: 0.0888, MAE: 0.1192\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0311, MAE: 0.1224\n    Epoch 2/10 | Val CCC: 0.1182, MAE: 0.1198\n    Epoch 3/10 | Val CCC: 0.0821, MAE: 0.1179\n    Epoch 4/10 | Val CCC: 0.1127, MAE: 0.1169\n    Epoch 5/10 | Val CCC: 0.1350, MAE: 0.1173\n    Epoch 6/10 | Val CCC: 0.1249, MAE: 0.1166\n    Epoch 7/10 | Val CCC: 0.1328, MAE: 0.1158\n    Epoch 8/10 | Val CCC: 0.1746, MAE: 0.1159\n    Epoch 9/10 | Val CCC: 0.1653, MAE: 0.1147\n    Epoch 10/10 | Val CCC: 0.1649, MAE: 0.1160\n  Avg CCC: 0.1782, MAE: 0.1164\n\n>>> Best Config Selected: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n\n>>> Final Training for NEUROTICISM (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0258\n  Epoch 2/10 - Train Loss: 0.0233\n  Epoch 3/10 - Train Loss: 0.0225\n  Epoch 4/10 - Train Loss: 0.0222\n  Epoch 5/10 - Train Loss: 0.0221\n  Epoch 6/10 - Train Loss: 0.0218\n  Epoch 7/10 - Train Loss: 0.0217\n  Epoch 8/10 - Train Loss: 0.0216\n  Epoch 9/10 - Train Loss: 0.0215\n  Epoch 10/10 - Train Loss: 0.0213\n\n==== NEUROTICISM Evaluation on Test Set ====\nTest CCC: 0.1938, Test MAE: 0.1167, Accuracy (±0.1): 49.92%\nSaving final model for neuroticism to best_video_transformer_model_neuroticism.pth\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **Audio HC Traits**","metadata":{}},{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split, KFold\nimport torch.optim as optim\nfrom sklearn.preprocessing import StandardScaler\n\n# Load audio dataset\ndf = pd.read_csv('/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/audio_hc_features.csv')\n\n# Drop unnecessary columns\ndrop_cols = [\"Filename\", \"Segment_ID\", \"interview\", \"Gender\", \"Ethnicity\", \"AgeGroup\"]\ndf.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True, errors='ignore')\n\n# Define label columns\nlabel_columns = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n\n# Separate features and labels\nX = df.drop(columns=label_columns)\ny = df[label_columns]\n\n# Keep only numeric columns\nX = X.select_dtypes(include=[np.number])\n\n# Fill missing values\nX = X.fillna(X.mean())\ny = y.fillna(y.mean())\n\n# Normalize features\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n# Convert to tensors\nX_tensor = torch.tensor(X.values, dtype=torch.float32)\ny_tensors = {trait: torch.tensor(y[trait].values, dtype=torch.float32) for trait in label_columns}\n\n# Dataset class\nclass AudioDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\nclass SimpleTransformerRegressor(nn.Module):\n    \"\"\"\n    Simple Transformer Regressor using batch_first=True convention.\n    Takes tabular features, projects them, passes through a Transformer Encoder,\n    and predicts a single regression value.\n    \"\"\"\n    def __init__(self, input_dim, embed_dim=256, num_heads=4, num_layers=2, dropout=0.3, ff_dim_multiplier=4):\n        \"\"\"\n        Args:\n            input_dim (int): Number of input features.\n            embed_dim (int): Dimension for projecting features and for the Transformer. Must be divisible by num_heads.\n            num_heads (int): Number of attention heads in the Transformer.\n            num_layers (int): Number of layers in the Transformer Encoder.\n            dropout (float): Dropout rate.\n            ff_dim_multiplier (int): Multiplier for the feed-forward layer dimension within the Transformer.\n        \"\"\"\n        super(SimpleTransformerRegressor, self).__init__()\n\n        # Ensure embed_dim is divisible by num_heads\n        if embed_dim % num_heads != 0:\n            # Adjust embed_dim up to the nearest multiple of num_heads\n            original_embed_dim = embed_dim\n            embed_dim = (embed_dim // num_heads + 1) * num_heads\n            print(f\"Warning: embed_dim ({original_embed_dim}) not divisible by num_heads ({num_heads}).\")\n            print(f\"Adjusted embed_dim to {embed_dim}.\")\n\n        self.input_dim = input_dim\n        self.embed_dim = embed_dim\n\n        # Project input features to embedding dimension\n        self.project = nn.Linear(input_dim, embed_dim)\n\n        # Define the Transformer Encoder Layer with batch_first=True\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim,\n            nhead=num_heads,\n            dim_feedforward=embed_dim * ff_dim_multiplier, # Standard practice\n            dropout=dropout,\n            batch_first=True  # <<< Input tensor shape: (batch, seq_len, features)\n        )\n\n        # Stack the encoder layers\n        self.encoder = nn.TransformerEncoder(\n            encoder_layer=encoder_layer,\n            num_layers=num_layers\n        )\n\n        # Classifier head\n        self.classifier = nn.Sequential(\n            nn.LayerNorm(embed_dim),      # Add LayerNorm for stability before classifier\n            nn.Linear(embed_dim, 128),    # Linear layer 1\n            nn.ReLU(),                    # Activation\n            nn.Dropout(dropout),          # Dropout\n            nn.Linear(128, 1)             # Final output layer (regression target)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass.\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_dim).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size).\n        \"\"\"\n        # 1. Project features\n        # x shape: (batch_size, input_dim)\n        x = self.project(x)\n        # x shape: (batch_size, embed_dim)\n\n        # 2. Add sequence dimension for Transformer\n        # TransformerEncoderLayer with batch_first=True expects (batch, seq_len, features)\n        x = x.unsqueeze(1)\n        # x shape: (batch_size, seq_len=1, embed_dim)\n\n        # 3. Pass through Transformer Encoder\n        x = self.encoder(x)\n        # x shape: (batch_size, seq_len=1, embed_dim)\n\n        # 4. Remove sequence dimension\n        x = x.squeeze(1)\n        # x shape: (batch_size, embed_dim)\n\n        # 5. Pass through classifier\n        output = self.classifier(x)\n        # output shape: (batch_size, 1)\n\n        # 6. Squeeze final dimension for regression output\n        return output.squeeze(-1)\n        # final shape: (batch_size)\n\n# Metrics\ndef mean_absolute_error(preds, labels):\n    return torch.mean(torch.abs(preds - labels)).item()\n\ndef concordance_correlation_coefficient(preds, labels):\n    preds_mean = torch.mean(preds)\n    labels_mean = torch.mean(labels)\n    preds_var = torch.var(preds)\n    labels_var = torch.var(labels)\n    covariance = torch.mean((preds - preds_mean) * (labels - labels_mean))\n    ccc = (2 * covariance) / (preds_var + labels_var + (preds_mean - labels_mean) ** 2)\n    return ccc.item()\n\n# Training helpers\ndef train_one_epoch(model, loader, optimizer, scheduler, criterion, device):\n    model.train()\n    total_loss = 0\n    for i, (X_batch, y_batch) in enumerate(loader):\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        preds = model(X_batch)\n        loss = criterion(preds, y_batch)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    scheduler.step()\n    return total_loss / len(loader)\n\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    total_loss, total_mae, total_ccc = 0, 0, 0\n    with torch.no_grad():\n        for X_batch, y_batch in loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            preds = model(X_batch)\n            loss = criterion(preds, y_batch)\n            total_loss += loss.item()\n            total_mae += mean_absolute_error(preds, y_batch)\n            total_ccc += concordance_correlation_coefficient(preds, y_batch)\n    n_batches = len(loader)\n    return total_loss/n_batches, total_mae/n_batches, total_ccc/n_batches\n\ndef generate_random_configs(search_space, num_configs=10):\n    configs = []\n    for _ in range(num_configs):\n        config = {\n            \"embed_dim\": np.random.choice(search_space[\"embed_dim\"]),\n            \"num_heads\": np.random.choice(search_space[\"num_heads\"]),\n            \"num_layers\": np.random.choice(search_space[\"num_layers\"]),\n            \"dropout\": np.random.choice(search_space[\"dropout\"]),\n            \"lr\": np.random.choice(search_space[\"lr\"]),\n            \"batch_size\": np.random.choice(search_space[\"batch_size\"]),\n            \"weight_decay\": np.random.choice(search_space[\"weight_decay\"])\n        }\n        configs.append(config)\n    return configs\n\ndef cross_validate(config, X_tensor, y_tensor, num_folds=3, epochs=10):\n    print(f\"Evaluating Config: {config}\")\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n    fold_metrics = {\"val_ccc\": [], \"val_mae\": [], \"val_loss\": []}\n\n    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_tensor)):\n        print(f\"  Fold {fold+1}/{num_folds}\")\n        X_train_fold, y_train_fold = X_tensor[train_idx], y_tensor[train_idx]\n        X_val_fold, y_val_fold = X_tensor[val_idx], y_tensor[val_idx]\n\n        train_loader = DataLoader(AudioDataset(X_train_fold, y_train_fold), batch_size=int(config[\"batch_size\"]), shuffle=True)\n        val_loader = DataLoader(AudioDataset(X_val_fold, y_val_fold), batch_size=int(config[\"batch_size\"]), shuffle=False)\n\n        model = SimpleTransformerRegressor(\n            input_dim=X_tensor.shape[1],\n            embed_dim=config[\"embed_dim\"],\n            num_heads=config[\"num_heads\"],\n            num_layers=config[\"num_layers\"],\n            dropout=config[\"dropout\"]\n        ).to(device)\n\n        optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n        criterion = nn.MSELoss()\n\n        best_ccc = -1\n        for epoch in range(epochs):\n            print(f\"    Epoch {epoch+1}/{epochs}\", end=' | ')\n            train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, device)\n            val_loss, val_mae, val_ccc = evaluate(model, val_loader, criterion, device)\n            print(f\"Val CCC: {val_ccc:.4f}, MAE: {val_mae:.4f}\")\n            if val_ccc > best_ccc:\n                best_ccc = val_ccc\n                best_metrics = (val_loss, val_mae, val_ccc)\n\n        fold_metrics[\"val_loss\"].append(best_metrics[0])\n        fold_metrics[\"val_mae\"].append(best_metrics[1])\n        fold_metrics[\"val_ccc\"].append(best_metrics[2])\n\n    return {\n        \"ccc\": np.mean(fold_metrics[\"val_ccc\"]),\n        \"mae\": np.mean(fold_metrics[\"val_mae\"]),\n        \"loss\": np.mean(fold_metrics[\"val_loss\"])\n    }\n\ndef hyperparameter_tuning(X_tensor, y_tensor, num_configs=10):\n    search_space = {\n        \"embed_dim\": [128, 256, 512],\n        \"num_heads\": [2, 4, 8],\n        \"num_layers\": [2, 4],\n        \"dropout\": [0.1, 0.3, 0.5],\n        \"lr\": [1e-4, 3e-4, 1e-3],\n        \"batch_size\": [32, 64],\n        \"weight_decay\": [1e-5, 1e-4]\n    }\n    configs = generate_random_configs(search_space, num_configs)\n    best_config = None\n    best_ccc = -1\n\n    for i, config in enumerate(configs):\n        print(f\"\\n>>> Config {i+1}/{num_configs}\")\n        metrics = cross_validate(config, X_tensor, y_tensor)\n        print(f\"  Avg CCC: {metrics['ccc']:.4f}, MAE: {metrics['mae']:.4f}\")\n        if metrics[\"ccc\"] > best_ccc:\n            best_ccc = metrics[\"ccc\"]\n            best_config = config\n\n    print(f\"\\n>>> Best Config Selected: {best_config}\")\n    return best_config\n\ndef final_train_and_evaluate(best_config, X_train, y_train, X_val, y_val, X_test, y_test, trait_name, epochs=10):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    X_final_train = torch.cat([X_train, X_val], dim=0)\n    y_final_train = torch.cat([y_train, y_val], dim=0)\n\n    final_train_loader = DataLoader(AudioDataset(X_final_train, y_final_train), batch_size=int(best_config[\"batch_size\"]), shuffle=True)\n    test_loader = DataLoader(AudioDataset(X_test, y_test), batch_size=int(best_config[\"batch_size\"]), shuffle=False)\n\n    model = SimpleTransformerRegressor(\n        input_dim=X_train.shape[1],\n        embed_dim=best_config[\"embed_dim\"],\n        num_heads=best_config[\"num_heads\"],\n        num_layers=best_config[\"num_layers\"],\n        dropout=best_config[\"dropout\"]\n    ).to(device)\n\n    optimizer = optim.AdamW(model.parameters(), lr=best_config[\"lr\"], weight_decay=best_config[\"weight_decay\"])\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n    criterion = nn.MSELoss()\n\n    print(f\"\\n>>> Final Training for {trait_name.upper()} ({epochs} epochs)\")\n    for epoch in range(epochs):\n        train_loss = train_one_epoch(model, final_train_loader, optimizer, scheduler, criterion, device)\n        print(f\"  Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}\")\n\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for X_batch, y_batch in test_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            preds = model(X_batch)\n            all_preds.append(preds)\n            all_labels.append(y_batch)\n\n    all_preds = torch.cat(all_preds, dim=0)\n    all_labels = torch.cat(all_labels, dim=0)\n\n    final_mae = mean_absolute_error(all_preds, all_labels)\n    final_ccc = concordance_correlation_coefficient(all_preds, all_labels)\n    tolerance = 0.1\n    correct = torch.abs(all_preds - all_labels) < tolerance\n    final_accuracy = correct.float().mean().item()\n\n    print(f\"\\n==== {trait_name.upper()} Evaluation on Test Set ====\")\n    print(f\"Test CCC: {final_ccc:.4f}, Test MAE: {final_mae:.4f}, Accuracy (±{tolerance}): {final_accuracy*100:.2f}%\")\n    torch.save(model.state_dict(), f\"best_audio_transformer_model_{trait_name}.pth\")\n    model_save_path = f\"best_audio_transformer_model_{trait_name}.pth\"\n    print(f\"Saving final model for {trait_name} to {model_save_path}\")\n    torch.save({\n        'epoch': epochs,\n        'model_state_dict': model.state_dict(), # <<< Weights nested here\n        'optimizer_state_dict': optimizer.state_dict(),\n        'best_config': best_config,           # <<< Config needed\n        'scaler_mean': scaler.mean_,         # <<< Scaler mean needed\n        'scaler_scale': scaler.scale_,         # <<< Scaler scale needed\n        'test_metrics': {'ccc': final_ccc, 'mae': final_mae, f'acc_{tolerance}': final_accuracy}\n    }, model_save_path)\n\n# Train model per trait\nfor trait in label_columns:\n    print(f\"\\n--- Training for Trait: {trait} ---\")\n    y_trait = y_tensors[trait]\n    train_idx, temp_idx = train_test_split(range(len(X)), test_size=0.3, random_state=42)\n    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n\n    X_train, y_train = X_tensor[train_idx], y_trait[train_idx]\n    X_val, y_val = X_tensor[val_idx], y_trait[val_idx]\n    X_test, y_test = X_tensor[test_idx], y_trait[test_idx]\n\n    best_config = hyperparameter_tuning(X_tensor, y_trait, num_configs=10)\n    final_train_and_evaluate(best_config, X_train, y_train, X_val, y_val, X_test, y_test, trait_name=trait)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:30:12.349569Z","iopub.execute_input":"2025-05-05T18:30:12.349878Z","iopub.status.idle":"2025-05-05T21:32:39.774669Z","shell.execute_reply.started":"2025-05-05T18:30:12.349856Z","shell.execute_reply":"2025-05-05T21:32:39.773951Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2207556778.py:13: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv('/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/audio_hc_features.csv')\n","output_type":"stream"},{"name":"stdout","text":"\n--- Training for Trait: openness ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0347, MAE: 0.1155\n    Epoch 2/10 | Val CCC: 0.0460, MAE: 0.1150\n    Epoch 3/10 | Val CCC: 0.0513, MAE: 0.1153\n    Epoch 4/10 | Val CCC: 0.0516, MAE: 0.1147\n    Epoch 5/10 | Val CCC: 0.0713, MAE: 0.1156\n    Epoch 6/10 | Val CCC: 0.0721, MAE: 0.1147\n    Epoch 7/10 | Val CCC: 0.0769, MAE: 0.1147\n    Epoch 8/10 | Val CCC: 0.0860, MAE: 0.1152\n    Epoch 9/10 | Val CCC: 0.0517, MAE: 0.1148\n    Epoch 10/10 | Val CCC: 0.0797, MAE: 0.1164\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0442, MAE: 0.1149\n    Epoch 2/10 | Val CCC: 0.0725, MAE: 0.1146\n    Epoch 3/10 | Val CCC: 0.0543, MAE: 0.1144\n    Epoch 4/10 | Val CCC: 0.0635, MAE: 0.1142\n    Epoch 5/10 | Val CCC: 0.0699, MAE: 0.1162\n    Epoch 6/10 | Val CCC: 0.0709, MAE: 0.1152\n    Epoch 7/10 | Val CCC: 0.0719, MAE: 0.1145\n    Epoch 8/10 | Val CCC: 0.0875, MAE: 0.1150\n    Epoch 9/10 | Val CCC: 0.0674, MAE: 0.1160\n    Epoch 10/10 | Val CCC: 0.0783, MAE: 0.1141\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0285, MAE: 0.1184\n    Epoch 2/10 | Val CCC: 0.1180, MAE: 0.1167\n    Epoch 3/10 | Val CCC: 0.0985, MAE: 0.1173\n    Epoch 4/10 | Val CCC: 0.0853, MAE: 0.1178\n    Epoch 5/10 | Val CCC: 0.0845, MAE: 0.1149\n    Epoch 6/10 | Val CCC: 0.0731, MAE: 0.1150\n    Epoch 7/10 | Val CCC: 0.0467, MAE: 0.1153\n    Epoch 8/10 | Val CCC: 0.0795, MAE: 0.1148\n    Epoch 9/10 | Val CCC: 0.0407, MAE: 0.1155\n    Epoch 10/10 | Val CCC: 0.0790, MAE: 0.1152\n  Avg CCC: 0.0972, MAE: 0.1156\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0711, MAE: 0.1154\n    Epoch 2/10 | Val CCC: 0.0860, MAE: 0.1159\n    Epoch 3/10 | Val CCC: 0.0565, MAE: 0.1161\n    Epoch 4/10 | Val CCC: 0.0625, MAE: 0.1172\n    Epoch 5/10 | Val CCC: 0.0670, MAE: 0.1168\n    Epoch 6/10 | Val CCC: 0.0652, MAE: 0.1174\n    Epoch 7/10 | Val CCC: 0.0626, MAE: 0.1160\n    Epoch 8/10 | Val CCC: 0.0834, MAE: 0.1156\n    Epoch 9/10 | Val CCC: 0.0617, MAE: 0.1154\n    Epoch 10/10 | Val CCC: 0.0695, MAE: 0.1181\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0708, MAE: 0.1143\n    Epoch 2/10 | Val CCC: 0.0597, MAE: 0.1143\n    Epoch 3/10 | Val CCC: 0.0720, MAE: 0.1145\n    Epoch 4/10 | Val CCC: 0.0682, MAE: 0.1154\n    Epoch 5/10 | Val CCC: 0.0688, MAE: 0.1147\n    Epoch 6/10 | Val CCC: 0.0558, MAE: 0.1156\n    Epoch 7/10 | Val CCC: 0.0673, MAE: 0.1158\n    Epoch 8/10 | Val CCC: 0.0647, MAE: 0.1145\n    Epoch 9/10 | Val CCC: 0.0644, MAE: 0.1161\n    Epoch 10/10 | Val CCC: 0.0718, MAE: 0.1155\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0444, MAE: 0.1165\n    Epoch 2/10 | Val CCC: 0.0681, MAE: 0.1163\n    Epoch 3/10 | Val CCC: 0.0758, MAE: 0.1159\n    Epoch 4/10 | Val CCC: 0.0711, MAE: 0.1155\n    Epoch 5/10 | Val CCC: 0.0743, MAE: 0.1152\n    Epoch 6/10 | Val CCC: 0.0724, MAE: 0.1176\n    Epoch 7/10 | Val CCC: 0.0730, MAE: 0.1175\n    Epoch 8/10 | Val CCC: 0.0645, MAE: 0.1160\n    Epoch 9/10 | Val CCC: 0.0674, MAE: 0.1159\n    Epoch 10/10 | Val CCC: 0.0686, MAE: 0.1158\n  Avg CCC: 0.0779, MAE: 0.1154\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0801, MAE: 0.1193\n    Epoch 2/10 | Val CCC: 0.0613, MAE: 0.1162\n    Epoch 3/10 | Val CCC: 0.0622, MAE: 0.1155\n    Epoch 4/10 | Val CCC: 0.0492, MAE: 0.1163\n    Epoch 5/10 | Val CCC: 0.0708, MAE: 0.1181\n    Epoch 6/10 | Val CCC: 0.0798, MAE: 0.1161\n    Epoch 7/10 | Val CCC: 0.0661, MAE: 0.1169\n    Epoch 8/10 | Val CCC: 0.0598, MAE: 0.1158\n    Epoch 9/10 | Val CCC: 0.0609, MAE: 0.1151\n    Epoch 10/10 | Val CCC: 0.0678, MAE: 0.1166\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0571, MAE: 0.1179\n    Epoch 2/10 | Val CCC: 0.0404, MAE: 0.1228\n    Epoch 3/10 | Val CCC: 0.0672, MAE: 0.1143\n    Epoch 4/10 | Val CCC: 0.0494, MAE: 0.1201\n    Epoch 5/10 | Val CCC: 0.0532, MAE: 0.1144\n    Epoch 6/10 | Val CCC: 0.0629, MAE: 0.1194\n    Epoch 7/10 | Val CCC: 0.0619, MAE: 0.1141\n    Epoch 8/10 | Val CCC: 0.0491, MAE: 0.1141\n    Epoch 9/10 | Val CCC: 0.0612, MAE: 0.1142\n    Epoch 10/10 | Val CCC: 0.0496, MAE: 0.1142\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0813, MAE: 0.1172\n    Epoch 2/10 | Val CCC: 0.0600, MAE: 0.1164\n    Epoch 3/10 | Val CCC: 0.0535, MAE: 0.1199\n    Epoch 4/10 | Val CCC: 0.0849, MAE: 0.1194\n    Epoch 5/10 | Val CCC: 0.0486, MAE: 0.1171\n    Epoch 6/10 | Val CCC: 0.0488, MAE: 0.1157\n    Epoch 7/10 | Val CCC: 0.0629, MAE: 0.1169\n    Epoch 8/10 | Val CCC: 0.0505, MAE: 0.1168\n    Epoch 9/10 | Val CCC: 0.0737, MAE: 0.1151\n    Epoch 10/10 | Val CCC: 0.0633, MAE: 0.1161\n  Avg CCC: 0.0774, MAE: 0.1177\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0652, MAE: 0.1187\n    Epoch 2/10 | Val CCC: 0.0535, MAE: 0.1151\n    Epoch 3/10 | Val CCC: 0.0503, MAE: 0.1188\n    Epoch 4/10 | Val CCC: 0.0609, MAE: 0.1282\n    Epoch 5/10 | Val CCC: 0.0523, MAE: 0.1150\n    Epoch 6/10 | Val CCC: 0.0533, MAE: 0.1155\n    Epoch 7/10 | Val CCC: 0.0572, MAE: 0.1151\n    Epoch 8/10 | Val CCC: 0.0447, MAE: 0.1155\n    Epoch 9/10 | Val CCC: 0.0497, MAE: 0.1150\n    Epoch 10/10 | Val CCC: 0.0619, MAE: 0.1149\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0628, MAE: 0.1143\n    Epoch 2/10 | Val CCC: 0.0485, MAE: 0.1225\n    Epoch 3/10 | Val CCC: 0.0334, MAE: 0.1255\n    Epoch 4/10 | Val CCC: 0.0807, MAE: 0.1153\n    Epoch 5/10 | Val CCC: 0.0772, MAE: 0.1147\n    Epoch 6/10 | Val CCC: 0.0646, MAE: 0.1143\n    Epoch 7/10 | Val CCC: 0.0623, MAE: 0.1140\n    Epoch 8/10 | Val CCC: 0.0563, MAE: 0.1141\n    Epoch 9/10 | Val CCC: 0.0579, MAE: 0.1143\n    Epoch 10/10 | Val CCC: 0.0470, MAE: 0.1143\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0846, MAE: 0.1158\n    Epoch 2/10 | Val CCC: 0.0420, MAE: 0.1359\n    Epoch 3/10 | Val CCC: 0.0432, MAE: 0.1192\n    Epoch 4/10 | Val CCC: 0.0652, MAE: 0.1158\n    Epoch 5/10 | Val CCC: 0.0725, MAE: 0.1156\n    Epoch 6/10 | Val CCC: 0.0610, MAE: 0.1160\n    Epoch 7/10 | Val CCC: 0.0549, MAE: 0.1155\n    Epoch 8/10 | Val CCC: 0.0697, MAE: 0.1152\n    Epoch 9/10 | Val CCC: 0.0767, MAE: 0.1152\n    Epoch 10/10 | Val CCC: 0.0586, MAE: 0.1153\n  Avg CCC: 0.0768, MAE: 0.1166\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0664, MAE: 0.1150\n    Epoch 2/10 | Val CCC: 0.0606, MAE: 0.1150\n    Epoch 3/10 | Val CCC: 0.0503, MAE: 0.1150\n    Epoch 4/10 | Val CCC: 0.0507, MAE: 0.1185\n    Epoch 5/10 | Val CCC: 0.0856, MAE: 0.1175\n    Epoch 6/10 | Val CCC: 0.0741, MAE: 0.1154\n    Epoch 7/10 | Val CCC: 0.0728, MAE: 0.1215\n    Epoch 8/10 | Val CCC: 0.0734, MAE: 0.1163\n    Epoch 9/10 | Val CCC: 0.0673, MAE: 0.1162\n    Epoch 10/10 | Val CCC: 0.0819, MAE: 0.1166\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0863, MAE: 0.1157\n    Epoch 2/10 | Val CCC: 0.0498, MAE: 0.1141\n    Epoch 3/10 | Val CCC: 0.0951, MAE: 0.1155\n    Epoch 4/10 | Val CCC: 0.0784, MAE: 0.1142\n    Epoch 5/10 | Val CCC: 0.0575, MAE: 0.1152\n    Epoch 6/10 | Val CCC: 0.0593, MAE: 0.1141\n    Epoch 7/10 | Val CCC: 0.0754, MAE: 0.1167\n    Epoch 8/10 | Val CCC: 0.0830, MAE: 0.1164\n    Epoch 9/10 | Val CCC: 0.0639, MAE: 0.1180\n    Epoch 10/10 | Val CCC: 0.0656, MAE: 0.1163\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0313, MAE: 0.1165\n    Epoch 2/10 | Val CCC: 0.0863, MAE: 0.1154\n    Epoch 3/10 | Val CCC: 0.0846, MAE: 0.1162\n    Epoch 4/10 | Val CCC: 0.0778, MAE: 0.1150\n    Epoch 5/10 | Val CCC: 0.0545, MAE: 0.1151\n    Epoch 6/10 | Val CCC: 0.0715, MAE: 0.1158\n    Epoch 7/10 | Val CCC: 0.0660, MAE: 0.1158\n    Epoch 8/10 | Val CCC: 0.0755, MAE: 0.1165\n    Epoch 9/10 | Val CCC: 0.0637, MAE: 0.1151\n    Epoch 10/10 | Val CCC: 0.0520, MAE: 0.1153\n  Avg CCC: 0.0890, MAE: 0.1161\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0796, MAE: 0.1229\n    Epoch 2/10 | Val CCC: 0.0513, MAE: 0.1231\n    Epoch 3/10 | Val CCC: 0.0590, MAE: 0.1171\n    Epoch 4/10 | Val CCC: 0.0572, MAE: 0.1177\n    Epoch 5/10 | Val CCC: 0.0726, MAE: 0.1209\n    Epoch 6/10 | Val CCC: 0.0491, MAE: 0.1205\n    Epoch 7/10 | Val CCC: 0.0733, MAE: 0.1194\n    Epoch 8/10 | Val CCC: 0.0526, MAE: 0.1292\n    Epoch 9/10 | Val CCC: 0.0508, MAE: 0.1179\n    Epoch 10/10 | Val CCC: 0.0612, MAE: 0.1199\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0224, MAE: 0.1165\n    Epoch 2/10 | Val CCC: 0.0558, MAE: 0.1154\n    Epoch 3/10 | Val CCC: 0.0598, MAE: 0.1291\n    Epoch 4/10 | Val CCC: 0.0417, MAE: 0.1214\n    Epoch 5/10 | Val CCC: 0.0577, MAE: 0.1200\n    Epoch 6/10 | Val CCC: 0.0510, MAE: 0.1224\n    Epoch 7/10 | Val CCC: 0.0684, MAE: 0.1197\n    Epoch 8/10 | Val CCC: 0.0640, MAE: 0.1145\n    Epoch 9/10 | Val CCC: 0.0605, MAE: 0.1198\n    Epoch 10/10 | Val CCC: 0.0451, MAE: 0.1227\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0315, MAE: 0.1324\n    Epoch 2/10 | Val CCC: 0.0488, MAE: 0.1171\n    Epoch 3/10 | Val CCC: 0.0773, MAE: 0.1224\n    Epoch 4/10 | Val CCC: 0.0545, MAE: 0.1238\n    Epoch 5/10 | Val CCC: 0.0637, MAE: 0.1167\n    Epoch 6/10 | Val CCC: 0.0559, MAE: 0.1169\n    Epoch 7/10 | Val CCC: 0.0457, MAE: 0.1201\n    Epoch 8/10 | Val CCC: 0.0417, MAE: 0.1184\n    Epoch 9/10 | Val CCC: 0.0622, MAE: 0.1181\n    Epoch 10/10 | Val CCC: 0.0598, MAE: 0.1175\n  Avg CCC: 0.0751, MAE: 0.1217\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0660, MAE: 0.1592\n    Epoch 2/10 | Val CCC: 0.0350, MAE: 0.1725\n    Epoch 3/10 | Val CCC: 0.0495, MAE: 0.1597\n    Epoch 4/10 | Val CCC: 0.0391, MAE: 0.1467\n    Epoch 5/10 | Val CCC: 0.0590, MAE: 0.1424\n    Epoch 6/10 | Val CCC: 0.0603, MAE: 0.1337\n    Epoch 7/10 | Val CCC: 0.0708, MAE: 0.1264\n    Epoch 8/10 | Val CCC: 0.0744, MAE: 0.1269\n    Epoch 9/10 | Val CCC: 0.0617, MAE: 0.1174\n    Epoch 10/10 | Val CCC: 0.0780, MAE: 0.1177\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0649, MAE: 0.1483\n    Epoch 2/10 | Val CCC: 0.0749, MAE: 0.1312\n    Epoch 3/10 | Val CCC: 0.0680, MAE: 0.1299\n    Epoch 4/10 | Val CCC: 0.0739, MAE: 0.1182\n    Epoch 5/10 | Val CCC: 0.0679, MAE: 0.1373\n    Epoch 6/10 | Val CCC: 0.0678, MAE: 0.1203\n    Epoch 7/10 | Val CCC: 0.0640, MAE: 0.1171\n    Epoch 8/10 | Val CCC: 0.0664, MAE: 0.1164\n    Epoch 9/10 | Val CCC: 0.0772, MAE: 0.1148\n    Epoch 10/10 | Val CCC: 0.0861, MAE: 0.1152\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0623, MAE: 0.1414\n    Epoch 2/10 | Val CCC: 0.0440, MAE: 0.1512\n    Epoch 3/10 | Val CCC: 0.0511, MAE: 0.1336\n    Epoch 4/10 | Val CCC: 0.0517, MAE: 0.1341\n    Epoch 5/10 | Val CCC: 0.0712, MAE: 0.1182\n    Epoch 6/10 | Val CCC: 0.0651, MAE: 0.1173\n    Epoch 7/10 | Val CCC: 0.0578, MAE: 0.1200\n    Epoch 8/10 | Val CCC: 0.0579, MAE: 0.1174\n    Epoch 9/10 | Val CCC: 0.0913, MAE: 0.1164\n    Epoch 10/10 | Val CCC: 0.0949, MAE: 0.1196\n  Avg CCC: 0.0863, MAE: 0.1175\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0487, MAE: 0.1453\n    Epoch 2/10 | Val CCC: 0.0251, MAE: 0.1162\n    Epoch 3/10 | Val CCC: 0.0458, MAE: 0.1155\n    Epoch 4/10 | Val CCC: 0.0216, MAE: 0.1163\n    Epoch 5/10 | Val CCC: 0.0000, MAE: 0.1171\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1171\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1170\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1171\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1170\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1170\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0651, MAE: 0.1355\n    Epoch 2/10 | Val CCC: 0.0610, MAE: 0.1145\n    Epoch 3/10 | Val CCC: 0.0807, MAE: 0.1180\n    Epoch 4/10 | Val CCC: 0.0377, MAE: 0.1147\n    Epoch 5/10 | Val CCC: 0.0000, MAE: 0.1162\n    Epoch 6/10 | Val CCC: 0.0411, MAE: 0.1152\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1164\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1162\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1165\n    Epoch 10/10 | Val CCC: -0.0000, MAE: 0.1161\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0548, MAE: 0.1230\n    Epoch 2/10 | Val CCC: 0.0429, MAE: 0.1168\n    Epoch 3/10 | Val CCC: 0.0198, MAE: 0.1166\n    Epoch 4/10 | Val CCC: 0.0214, MAE: 0.1165\n    Epoch 5/10 | Val CCC: 0.0000, MAE: 0.1178\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1173\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1173\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1173\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1177\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1173\n  Avg CCC: 0.0614, MAE: 0.1288\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0507, MAE: 0.1240\n    Epoch 2/10 | Val CCC: 0.0558, MAE: 0.1370\n    Epoch 3/10 | Val CCC: 0.0416, MAE: 0.1316\n    Epoch 4/10 | Val CCC: 0.0453, MAE: 0.1359\n    Epoch 5/10 | Val CCC: 0.0366, MAE: 0.1358\n    Epoch 6/10 | Val CCC: 0.0564, MAE: 0.1269\n    Epoch 7/10 | Val CCC: 0.0455, MAE: 0.1285\n    Epoch 8/10 | Val CCC: 0.0450, MAE: 0.1309\n    Epoch 9/10 | Val CCC: 0.0458, MAE: 0.1284\n    Epoch 10/10 | Val CCC: 0.0560, MAE: 0.1254\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0578, MAE: 0.1304\n    Epoch 2/10 | Val CCC: 0.0601, MAE: 0.1533\n    Epoch 3/10 | Val CCC: 0.0341, MAE: 0.1449\n    Epoch 4/10 | Val CCC: 0.0452, MAE: 0.1371\n    Epoch 5/10 | Val CCC: 0.0452, MAE: 0.1417\n    Epoch 6/10 | Val CCC: 0.0649, MAE: 0.1252\n    Epoch 7/10 | Val CCC: 0.0458, MAE: 0.1447\n    Epoch 8/10 | Val CCC: 0.0461, MAE: 0.1409\n    Epoch 9/10 | Val CCC: 0.0527, MAE: 0.1272\n    Epoch 10/10 | Val CCC: 0.0570, MAE: 0.1347\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0671, MAE: 0.1284\n    Epoch 2/10 | Val CCC: 0.0545, MAE: 0.1381\n    Epoch 3/10 | Val CCC: 0.0488, MAE: 0.1370\n    Epoch 4/10 | Val CCC: 0.0392, MAE: 0.1440\n    Epoch 5/10 | Val CCC: 0.0461, MAE: 0.1236\n    Epoch 6/10 | Val CCC: 0.0521, MAE: 0.1252\n    Epoch 7/10 | Val CCC: 0.0544, MAE: 0.1219\n    Epoch 8/10 | Val CCC: 0.0760, MAE: 0.1226\n    Epoch 9/10 | Val CCC: 0.0672, MAE: 0.1246\n    Epoch 10/10 | Val CCC: 0.0685, MAE: 0.1189\n  Avg CCC: 0.0658, MAE: 0.1249\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0506, MAE: 0.1215\n    Epoch 2/10 | Val CCC: 0.0783, MAE: 0.1151\n    Epoch 3/10 | Val CCC: 0.0902, MAE: 0.1167\n    Epoch 4/10 | Val CCC: 0.1043, MAE: 0.1172\n    Epoch 5/10 | Val CCC: 0.1068, MAE: 0.1158\n    Epoch 6/10 | Val CCC: 0.0588, MAE: 0.1148\n    Epoch 7/10 | Val CCC: 0.0721, MAE: 0.1157\n    Epoch 8/10 | Val CCC: 0.0853, MAE: 0.1146\n    Epoch 9/10 | Val CCC: 0.0558, MAE: 0.1154\n    Epoch 10/10 | Val CCC: 0.0664, MAE: 0.1146\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0488, MAE: 0.1180\n    Epoch 2/10 | Val CCC: 0.0838, MAE: 0.1155\n    Epoch 3/10 | Val CCC: 0.0635, MAE: 0.1141\n    Epoch 4/10 | Val CCC: 0.0498, MAE: 0.1142\n    Epoch 5/10 | Val CCC: 0.0608, MAE: 0.1138\n    Epoch 6/10 | Val CCC: 0.0662, MAE: 0.1138\n    Epoch 7/10 | Val CCC: 0.0657, MAE: 0.1139\n    Epoch 8/10 | Val CCC: 0.0847, MAE: 0.1140\n    Epoch 9/10 | Val CCC: 0.0759, MAE: 0.1139\n    Epoch 10/10 | Val CCC: 0.0859, MAE: 0.1140\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0257, MAE: 0.1163\n    Epoch 2/10 | Val CCC: 0.0882, MAE: 0.1151\n    Epoch 3/10 | Val CCC: 0.0975, MAE: 0.1155\n    Epoch 4/10 | Val CCC: 0.0813, MAE: 0.1156\n    Epoch 5/10 | Val CCC: 0.0817, MAE: 0.1152\n    Epoch 6/10 | Val CCC: 0.0502, MAE: 0.1151\n    Epoch 7/10 | Val CCC: 0.0893, MAE: 0.1153\n    Epoch 8/10 | Val CCC: 0.0371, MAE: 0.1157\n    Epoch 9/10 | Val CCC: 0.0993, MAE: 0.1156\n    Epoch 10/10 | Val CCC: 0.0645, MAE: 0.1154\n  Avg CCC: 0.0973, MAE: 0.1152\n\n>>> Best Config Selected: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n\n>>> Final Training for OPENNESS (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0270\n  Epoch 2/10 - Train Loss: 0.0226\n  Epoch 3/10 - Train Loss: 0.0221\n  Epoch 4/10 - Train Loss: 0.0221\n  Epoch 5/10 - Train Loss: 0.0220\n  Epoch 6/10 - Train Loss: 0.0219\n  Epoch 7/10 - Train Loss: 0.0218\n  Epoch 8/10 - Train Loss: 0.0217\n  Epoch 9/10 - Train Loss: 0.0217\n  Epoch 10/10 - Train Loss: 0.0216\n\n==== OPENNESS Evaluation on Test Set ====\nTest CCC: 0.0840, Test MAE: 0.1144, Accuracy (±0.1): 51.23%\nSaving final model for openness to best_audio_transformer_model_openness.pth\n\n--- Training for Trait: conscientiousness ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0033, MAE: 0.1519\n    Epoch 2/10 | Val CCC: 0.0045, MAE: 0.1292\n    Epoch 3/10 | Val CCC: 0.0059, MAE: 0.1304\n    Epoch 4/10 | Val CCC: 0.0079, MAE: 0.1256\n    Epoch 5/10 | Val CCC: 0.0000, MAE: 0.1254\n    Epoch 6/10 | Val CCC: 0.0024, MAE: 0.1252\n    Epoch 7/10 | Val CCC: 0.0015, MAE: 0.1253\n    Epoch 8/10 | Val CCC: 0.0049, MAE: 0.1252\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1254\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1253\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0010, MAE: 0.1503\n    Epoch 2/10 | Val CCC: 0.0050, MAE: 0.1460\n    Epoch 3/10 | Val CCC: 0.0119, MAE: 0.1278\n    Epoch 4/10 | Val CCC: 0.0114, MAE: 0.1256\n    Epoch 5/10 | Val CCC: 0.0128, MAE: 0.1260\n    Epoch 6/10 | Val CCC: 0.0043, MAE: 0.1256\n    Epoch 7/10 | Val CCC: 0.0004, MAE: 0.1257\n    Epoch 8/10 | Val CCC: 0.0020, MAE: 0.1256\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1257\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1257\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0010, MAE: 0.1684\n    Epoch 2/10 | Val CCC: 0.0054, MAE: 0.1530\n    Epoch 3/10 | Val CCC: 0.0108, MAE: 0.1321\n    Epoch 4/10 | Val CCC: 0.0075, MAE: 0.1262\n    Epoch 5/10 | Val CCC: 0.0055, MAE: 0.1263\n    Epoch 6/10 | Val CCC: 0.0001, MAE: 0.1262\n    Epoch 7/10 | Val CCC: 0.0028, MAE: 0.1262\n    Epoch 8/10 | Val CCC: -0.0003, MAE: 0.1262\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1262\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1262\n  Avg CCC: 0.0105, MAE: 0.1279\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0064, MAE: 0.1500\n    Epoch 2/10 | Val CCC: 0.0061, MAE: 0.1452\n    Epoch 3/10 | Val CCC: 0.0083, MAE: 0.1412\n    Epoch 4/10 | Val CCC: 0.0110, MAE: 0.1326\n    Epoch 5/10 | Val CCC: 0.0110, MAE: 0.1382\n    Epoch 6/10 | Val CCC: 0.0124, MAE: 0.1255\n    Epoch 7/10 | Val CCC: 0.0148, MAE: 0.1284\n    Epoch 8/10 | Val CCC: 0.0149, MAE: 0.1270\n    Epoch 9/10 | Val CCC: 0.0186, MAE: 0.1263\n    Epoch 10/10 | Val CCC: 0.0210, MAE: 0.1263\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0074, MAE: 0.1365\n    Epoch 2/10 | Val CCC: 0.0131, MAE: 0.1361\n    Epoch 3/10 | Val CCC: 0.0062, MAE: 0.1330\n    Epoch 4/10 | Val CCC: 0.0109, MAE: 0.1291\n    Epoch 5/10 | Val CCC: 0.0127, MAE: 0.1273\n    Epoch 6/10 | Val CCC: 0.0144, MAE: 0.1270\n    Epoch 7/10 | Val CCC: 0.0192, MAE: 0.1264\n    Epoch 8/10 | Val CCC: 0.0173, MAE: 0.1251\n    Epoch 9/10 | Val CCC: 0.0158, MAE: 0.1256\n    Epoch 10/10 | Val CCC: 0.0161, MAE: 0.1252\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0110, MAE: 0.1582\n    Epoch 2/10 | Val CCC: 0.0046, MAE: 0.1508\n    Epoch 3/10 | Val CCC: 0.0042, MAE: 0.1447\n    Epoch 4/10 | Val CCC: 0.0074, MAE: 0.1382\n    Epoch 5/10 | Val CCC: 0.0067, MAE: 0.1285\n    Epoch 6/10 | Val CCC: 0.0116, MAE: 0.1381\n    Epoch 7/10 | Val CCC: 0.0115, MAE: 0.1267\n    Epoch 8/10 | Val CCC: 0.0122, MAE: 0.1286\n    Epoch 9/10 | Val CCC: 0.0107, MAE: 0.1262\n    Epoch 10/10 | Val CCC: 0.0141, MAE: 0.1260\n  Avg CCC: 0.0181, MAE: 0.1262\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0067, MAE: 0.1289\n    Epoch 2/10 | Val CCC: 0.0069, MAE: 0.1282\n    Epoch 3/10 | Val CCC: 0.0112, MAE: 0.1265\n    Epoch 4/10 | Val CCC: 0.0041, MAE: 0.1260\n    Epoch 5/10 | Val CCC: 0.0078, MAE: 0.1268\n    Epoch 6/10 | Val CCC: 0.0060, MAE: 0.1311\n    Epoch 7/10 | Val CCC: 0.0051, MAE: 0.1277\n    Epoch 8/10 | Val CCC: 0.0078, MAE: 0.1268\n    Epoch 9/10 | Val CCC: 0.0005, MAE: 0.1253\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1255\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0033, MAE: 0.1341\n    Epoch 2/10 | Val CCC: 0.0091, MAE: 0.1311\n    Epoch 3/10 | Val CCC: 0.0056, MAE: 0.1292\n    Epoch 4/10 | Val CCC: 0.0055, MAE: 0.1257\n    Epoch 5/10 | Val CCC: 0.0043, MAE: 0.1302\n    Epoch 6/10 | Val CCC: 0.0057, MAE: 0.1284\n    Epoch 7/10 | Val CCC: -0.0001, MAE: 0.1259\n    Epoch 8/10 | Val CCC: -0.0000, MAE: 0.1257\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1257\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1257\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0081, MAE: 0.1269\n    Epoch 2/10 | Val CCC: 0.0080, MAE: 0.1259\n    Epoch 3/10 | Val CCC: 0.0116, MAE: 0.1275\n    Epoch 4/10 | Val CCC: 0.0080, MAE: 0.1258\n    Epoch 5/10 | Val CCC: 0.0042, MAE: 0.1342\n    Epoch 6/10 | Val CCC: 0.0063, MAE: 0.1284\n    Epoch 7/10 | Val CCC: 0.0004, MAE: 0.1264\n    Epoch 8/10 | Val CCC: 0.0003, MAE: 0.1265\n    Epoch 9/10 | Val CCC: 0.0028, MAE: 0.1268\n    Epoch 10/10 | Val CCC: 0.0106, MAE: 0.1263\n  Avg CCC: 0.0106, MAE: 0.1284\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0309, MAE: 0.1262\n    Epoch 2/10 | Val CCC: 0.0119, MAE: 0.1255\n    Epoch 3/10 | Val CCC: 0.0290, MAE: 0.1262\n    Epoch 4/10 | Val CCC: 0.0141, MAE: 0.1249\n    Epoch 5/10 | Val CCC: 0.0148, MAE: 0.1260\n    Epoch 6/10 | Val CCC: 0.0136, MAE: 0.1255\n    Epoch 7/10 | Val CCC: 0.0161, MAE: 0.1251\n    Epoch 8/10 | Val CCC: 0.0206, MAE: 0.1247\n    Epoch 9/10 | Val CCC: 0.0234, MAE: 0.1247\n    Epoch 10/10 | Val CCC: 0.0187, MAE: 0.1248\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0182, MAE: 0.1251\n    Epoch 2/10 | Val CCC: 0.0137, MAE: 0.1252\n    Epoch 3/10 | Val CCC: 0.0112, MAE: 0.1259\n    Epoch 4/10 | Val CCC: 0.0114, MAE: 0.1254\n    Epoch 5/10 | Val CCC: 0.0093, MAE: 0.1271\n    Epoch 6/10 | Val CCC: 0.0190, MAE: 0.1259\n    Epoch 7/10 | Val CCC: 0.0196, MAE: 0.1251\n    Epoch 8/10 | Val CCC: 0.0133, MAE: 0.1267\n    Epoch 9/10 | Val CCC: 0.0176, MAE: 0.1251\n    Epoch 10/10 | Val CCC: 0.0127, MAE: 0.1255\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0061, MAE: 0.1261\n    Epoch 2/10 | Val CCC: 0.0158, MAE: 0.1256\n    Epoch 3/10 | Val CCC: 0.0100, MAE: 0.1257\n    Epoch 4/10 | Val CCC: 0.0185, MAE: 0.1256\n    Epoch 5/10 | Val CCC: 0.0133, MAE: 0.1281\n    Epoch 6/10 | Val CCC: 0.0155, MAE: 0.1256\n    Epoch 7/10 | Val CCC: 0.0178, MAE: 0.1273\n    Epoch 8/10 | Val CCC: 0.0174, MAE: 0.1256\n    Epoch 9/10 | Val CCC: 0.0161, MAE: 0.1260\n    Epoch 10/10 | Val CCC: 0.0186, MAE: 0.1255\n  Avg CCC: 0.0230, MAE: 0.1256\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0064, MAE: 0.1281\n    Epoch 2/10 | Val CCC: 0.0073, MAE: 0.1323\n    Epoch 3/10 | Val CCC: 0.0091, MAE: 0.1266\n    Epoch 4/10 | Val CCC: 0.0121, MAE: 0.1257\n    Epoch 5/10 | Val CCC: 0.0113, MAE: 0.1278\n    Epoch 6/10 | Val CCC: 0.0138, MAE: 0.1257\n    Epoch 7/10 | Val CCC: 0.0088, MAE: 0.1253\n    Epoch 8/10 | Val CCC: 0.0045, MAE: 0.1252\n    Epoch 9/10 | Val CCC: 0.0036, MAE: 0.1252\n    Epoch 10/10 | Val CCC: -0.0002, MAE: 0.1254\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0050, MAE: 0.1301\n    Epoch 2/10 | Val CCC: 0.0039, MAE: 0.1292\n    Epoch 3/10 | Val CCC: 0.0088, MAE: 0.1283\n    Epoch 4/10 | Val CCC: 0.0082, MAE: 0.1352\n    Epoch 5/10 | Val CCC: 0.0127, MAE: 0.1255\n    Epoch 6/10 | Val CCC: 0.0060, MAE: 0.1255\n    Epoch 7/10 | Val CCC: 0.0137, MAE: 0.1256\n    Epoch 8/10 | Val CCC: 0.0111, MAE: 0.1254\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1257\n    Epoch 10/10 | Val CCC: 0.0041, MAE: 0.1256\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0069, MAE: 0.1430\n    Epoch 2/10 | Val CCC: 0.0053, MAE: 0.1351\n    Epoch 3/10 | Val CCC: 0.0099, MAE: 0.1323\n    Epoch 4/10 | Val CCC: 0.0069, MAE: 0.1382\n    Epoch 5/10 | Val CCC: 0.0163, MAE: 0.1328\n    Epoch 6/10 | Val CCC: 0.0094, MAE: 0.1268\n    Epoch 7/10 | Val CCC: 0.0148, MAE: 0.1258\n    Epoch 8/10 | Val CCC: 0.0183, MAE: 0.1259\n    Epoch 9/10 | Val CCC: 0.0005, MAE: 0.1265\n    Epoch 10/10 | Val CCC: 0.0029, MAE: 0.1261\n  Avg CCC: 0.0153, MAE: 0.1257\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0107, MAE: 0.1295\n    Epoch 2/10 | Val CCC: 0.0070, MAE: 0.1383\n    Epoch 3/10 | Val CCC: 0.0080, MAE: 0.1269\n    Epoch 4/10 | Val CCC: 0.0141, MAE: 0.1342\n    Epoch 5/10 | Val CCC: 0.0154, MAE: 0.1274\n    Epoch 6/10 | Val CCC: 0.0112, MAE: 0.1376\n    Epoch 7/10 | Val CCC: 0.0081, MAE: 0.1270\n    Epoch 8/10 | Val CCC: 0.0146, MAE: 0.1258\n    Epoch 9/10 | Val CCC: 0.0151, MAE: 0.1285\n    Epoch 10/10 | Val CCC: 0.0187, MAE: 0.1249\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0102, MAE: 0.1265\n    Epoch 2/10 | Val CCC: 0.0087, MAE: 0.1373\n    Epoch 3/10 | Val CCC: 0.0111, MAE: 0.1298\n    Epoch 4/10 | Val CCC: 0.0108, MAE: 0.1285\n    Epoch 5/10 | Val CCC: 0.0070, MAE: 0.1442\n    Epoch 6/10 | Val CCC: 0.0141, MAE: 0.1275\n    Epoch 7/10 | Val CCC: 0.0149, MAE: 0.1291\n    Epoch 8/10 | Val CCC: 0.0067, MAE: 0.1295\n    Epoch 9/10 | Val CCC: 0.0113, MAE: 0.1312\n    Epoch 10/10 | Val CCC: 0.0177, MAE: 0.1251\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0072, MAE: 0.1346\n    Epoch 2/10 | Val CCC: 0.0119, MAE: 0.1367\n    Epoch 3/10 | Val CCC: 0.0164, MAE: 0.1268\n    Epoch 4/10 | Val CCC: 0.0133, MAE: 0.1264\n    Epoch 5/10 | Val CCC: 0.0111, MAE: 0.1300\n    Epoch 6/10 | Val CCC: 0.0137, MAE: 0.1289\n    Epoch 7/10 | Val CCC: 0.0198, MAE: 0.1276\n    Epoch 8/10 | Val CCC: 0.0269, MAE: 0.1274\n    Epoch 9/10 | Val CCC: 0.0192, MAE: 0.1285\n    Epoch 10/10 | Val CCC: 0.0142, MAE: 0.1259\n  Avg CCC: 0.0211, MAE: 0.1258\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0286, MAE: 0.1250\n    Epoch 2/10 | Val CCC: 0.0062, MAE: 0.1260\n    Epoch 3/10 | Val CCC: 0.0210, MAE: 0.1275\n    Epoch 4/10 | Val CCC: 0.0139, MAE: 0.1256\n    Epoch 5/10 | Val CCC: 0.0133, MAE: 0.1254\n    Epoch 6/10 | Val CCC: 0.0213, MAE: 0.1251\n    Epoch 7/10 | Val CCC: 0.0227, MAE: 0.1248\n    Epoch 8/10 | Val CCC: 0.0190, MAE: 0.1249\n    Epoch 9/10 | Val CCC: 0.0296, MAE: 0.1251\n    Epoch 10/10 | Val CCC: 0.0260, MAE: 0.1249\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0292, MAE: 0.1256\n    Epoch 2/10 | Val CCC: 0.0272, MAE: 0.1274\n    Epoch 3/10 | Val CCC: 0.0048, MAE: 0.1262\n    Epoch 4/10 | Val CCC: 0.0221, MAE: 0.1256\n    Epoch 5/10 | Val CCC: 0.0206, MAE: 0.1251\n    Epoch 6/10 | Val CCC: 0.0104, MAE: 0.1263\n    Epoch 7/10 | Val CCC: 0.0231, MAE: 0.1259\n    Epoch 8/10 | Val CCC: 0.0187, MAE: 0.1251\n    Epoch 9/10 | Val CCC: 0.0178, MAE: 0.1252\n    Epoch 10/10 | Val CCC: 0.0154, MAE: 0.1252\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0136, MAE: 0.1259\n    Epoch 2/10 | Val CCC: 0.0278, MAE: 0.1257\n    Epoch 3/10 | Val CCC: 0.0127, MAE: 0.1266\n    Epoch 4/10 | Val CCC: 0.0204, MAE: 0.1261\n    Epoch 5/10 | Val CCC: 0.0176, MAE: 0.1260\n    Epoch 6/10 | Val CCC: 0.0185, MAE: 0.1257\n    Epoch 7/10 | Val CCC: 0.0203, MAE: 0.1260\n    Epoch 8/10 | Val CCC: 0.0234, MAE: 0.1257\n    Epoch 9/10 | Val CCC: 0.0069, MAE: 0.1265\n    Epoch 10/10 | Val CCC: 0.0174, MAE: 0.1266\n  Avg CCC: 0.0288, MAE: 0.1254\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0050, MAE: 0.1285\n    Epoch 2/10 | Val CCC: 0.0051, MAE: 0.1276\n    Epoch 3/10 | Val CCC: 0.0055, MAE: 0.1287\n    Epoch 4/10 | Val CCC: 0.0210, MAE: 0.1263\n    Epoch 5/10 | Val CCC: 0.0000, MAE: 0.1288\n    Epoch 6/10 | Val CCC: 0.0048, MAE: 0.1256\n    Epoch 7/10 | Val CCC: 0.0048, MAE: 0.1251\n    Epoch 8/10 | Val CCC: 0.0001, MAE: 0.1255\n    Epoch 9/10 | Val CCC: 0.0011, MAE: 0.1253\n    Epoch 10/10 | Val CCC: 0.0036, MAE: 0.1252\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0052, MAE: 0.1284\n    Epoch 2/10 | Val CCC: 0.0103, MAE: 0.1339\n    Epoch 3/10 | Val CCC: 0.0161, MAE: 0.1263\n    Epoch 4/10 | Val CCC: 0.0044, MAE: 0.1263\n    Epoch 5/10 | Val CCC: 0.0016, MAE: 0.1273\n    Epoch 6/10 | Val CCC: 0.0074, MAE: 0.1254\n    Epoch 7/10 | Val CCC: 0.0034, MAE: 0.1256\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1257\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1257\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1257\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0036, MAE: 0.1260\n    Epoch 2/10 | Val CCC: 0.0076, MAE: 0.1264\n    Epoch 3/10 | Val CCC: 0.0028, MAE: 0.1260\n    Epoch 4/10 | Val CCC: 0.0089, MAE: 0.1258\n    Epoch 5/10 | Val CCC: 0.0026, MAE: 0.1262\n    Epoch 6/10 | Val CCC: 0.0045, MAE: 0.1275\n    Epoch 7/10 | Val CCC: 0.0023, MAE: 0.1261\n    Epoch 8/10 | Val CCC: 0.0021, MAE: 0.1261\n    Epoch 9/10 | Val CCC: 0.0020, MAE: 0.1261\n    Epoch 10/10 | Val CCC: 0.0079, MAE: 0.1259\n  Avg CCC: 0.0154, MAE: 0.1262\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0067, MAE: 0.1251\n    Epoch 2/10 | Val CCC: 0.0135, MAE: 0.1255\n    Epoch 3/10 | Val CCC: 0.0234, MAE: 0.1251\n    Epoch 4/10 | Val CCC: 0.0129, MAE: 0.1249\n    Epoch 5/10 | Val CCC: 0.0145, MAE: 0.1258\n    Epoch 6/10 | Val CCC: 0.0079, MAE: 0.1252\n    Epoch 7/10 | Val CCC: 0.0060, MAE: 0.1256\n    Epoch 8/10 | Val CCC: 0.0033, MAE: 0.1251\n    Epoch 9/10 | Val CCC: 0.0179, MAE: 0.1254\n    Epoch 10/10 | Val CCC: 0.0091, MAE: 0.1254\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0178, MAE: 0.1256\n    Epoch 2/10 | Val CCC: 0.0073, MAE: 0.1256\n    Epoch 3/10 | Val CCC: 0.0165, MAE: 0.1253\n    Epoch 4/10 | Val CCC: 0.0080, MAE: 0.1270\n    Epoch 5/10 | Val CCC: 0.0093, MAE: 0.1265\n    Epoch 6/10 | Val CCC: 0.0098, MAE: 0.1255\n    Epoch 7/10 | Val CCC: 0.0094, MAE: 0.1254\n    Epoch 8/10 | Val CCC: 0.0061, MAE: 0.1254\n    Epoch 9/10 | Val CCC: 0.0058, MAE: 0.1256\n    Epoch 10/10 | Val CCC: 0.0062, MAE: 0.1256\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0082, MAE: 0.1280\n    Epoch 2/10 | Val CCC: 0.0082, MAE: 0.1262\n    Epoch 3/10 | Val CCC: 0.0112, MAE: 0.1265\n    Epoch 4/10 | Val CCC: 0.0124, MAE: 0.1258\n    Epoch 5/10 | Val CCC: 0.0132, MAE: 0.1265\n    Epoch 6/10 | Val CCC: 0.0108, MAE: 0.1257\n    Epoch 7/10 | Val CCC: 0.0048, MAE: 0.1271\n    Epoch 8/10 | Val CCC: 0.0066, MAE: 0.1265\n    Epoch 9/10 | Val CCC: 0.0072, MAE: 0.1286\n    Epoch 10/10 | Val CCC: 0.0004, MAE: 0.1262\n  Avg CCC: 0.0181, MAE: 0.1258\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0053, MAE: 0.1313\n    Epoch 2/10 | Val CCC: 0.0081, MAE: 0.1256\n    Epoch 3/10 | Val CCC: 0.0077, MAE: 0.1259\n    Epoch 4/10 | Val CCC: 0.0090, MAE: 0.1261\n    Epoch 5/10 | Val CCC: 0.0069, MAE: 0.1251\n    Epoch 6/10 | Val CCC: 0.0132, MAE: 0.1251\n    Epoch 7/10 | Val CCC: 0.0087, MAE: 0.1250\n    Epoch 8/10 | Val CCC: 0.0013, MAE: 0.1253\n    Epoch 9/10 | Val CCC: 0.0171, MAE: 0.1251\n    Epoch 10/10 | Val CCC: 0.0005, MAE: 0.1253\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0083, MAE: 0.1344\n    Epoch 2/10 | Val CCC: 0.0067, MAE: 0.1299\n    Epoch 3/10 | Val CCC: 0.0040, MAE: 0.1259\n    Epoch 4/10 | Val CCC: 0.0056, MAE: 0.1262\n    Epoch 5/10 | Val CCC: 0.0093, MAE: 0.1254\n    Epoch 6/10 | Val CCC: 0.0119, MAE: 0.1255\n    Epoch 7/10 | Val CCC: 0.0120, MAE: 0.1253\n    Epoch 8/10 | Val CCC: 0.0029, MAE: 0.1256\n    Epoch 9/10 | Val CCC: 0.0014, MAE: 0.1256\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1257\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0075, MAE: 0.1275\n    Epoch 2/10 | Val CCC: 0.0055, MAE: 0.1288\n    Epoch 3/10 | Val CCC: 0.0063, MAE: 0.1362\n    Epoch 4/10 | Val CCC: 0.0090, MAE: 0.1281\n    Epoch 5/10 | Val CCC: 0.0094, MAE: 0.1268\n    Epoch 6/10 | Val CCC: 0.0109, MAE: 0.1261\n    Epoch 7/10 | Val CCC: 0.0044, MAE: 0.1261\n    Epoch 8/10 | Val CCC: 0.0036, MAE: 0.1263\n    Epoch 9/10 | Val CCC: 0.0131, MAE: 0.1261\n    Epoch 10/10 | Val CCC: 0.0072, MAE: 0.1260\n  Avg CCC: 0.0141, MAE: 0.1255\n\n>>> Best Config Selected: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n\n>>> Final Training for CONSCIENTIOUSNESS (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0267\n  Epoch 2/10 - Train Loss: 0.0251\n  Epoch 3/10 - Train Loss: 0.0249\n  Epoch 4/10 - Train Loss: 0.0249\n  Epoch 5/10 - Train Loss: 0.0248\n  Epoch 6/10 - Train Loss: 0.0246\n  Epoch 7/10 - Train Loss: 0.0247\n  Epoch 8/10 - Train Loss: 0.0245\n  Epoch 9/10 - Train Loss: 0.0245\n  Epoch 10/10 - Train Loss: 0.0244\n\n==== CONSCIENTIOUSNESS Evaluation on Test Set ====\nTest CCC: 0.0239, Test MAE: 0.1251, Accuracy (±0.1): 46.05%\nSaving final model for conscientiousness to best_audio_transformer_model_conscientiousness.pth\n\n--- Training for Trait: extraversion ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0514, MAE: 0.1225\n    Epoch 2/10 | Val CCC: 0.0430, MAE: 0.1243\n    Epoch 3/10 | Val CCC: 0.0384, MAE: 0.1224\n    Epoch 4/10 | Val CCC: 0.0422, MAE: 0.1233\n    Epoch 5/10 | Val CCC: 0.0404, MAE: 0.1242\n    Epoch 6/10 | Val CCC: 0.0462, MAE: 0.1246\n    Epoch 7/10 | Val CCC: 0.0456, MAE: 0.1214\n    Epoch 8/10 | Val CCC: 0.0491, MAE: 0.1215\n    Epoch 9/10 | Val CCC: 0.0529, MAE: 0.1234\n    Epoch 10/10 | Val CCC: 0.0512, MAE: 0.1214\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0570, MAE: 0.1247\n    Epoch 2/10 | Val CCC: 0.0396, MAE: 0.1278\n    Epoch 3/10 | Val CCC: 0.0442, MAE: 0.1226\n    Epoch 4/10 | Val CCC: 0.0426, MAE: 0.1264\n    Epoch 5/10 | Val CCC: 0.0408, MAE: 0.1211\n    Epoch 6/10 | Val CCC: 0.0392, MAE: 0.1221\n    Epoch 7/10 | Val CCC: 0.0390, MAE: 0.1218\n    Epoch 8/10 | Val CCC: 0.0442, MAE: 0.1209\n    Epoch 9/10 | Val CCC: 0.0460, MAE: 0.1207\n    Epoch 10/10 | Val CCC: 0.0485, MAE: 0.1205\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0285, MAE: 0.1276\n    Epoch 2/10 | Val CCC: 0.0386, MAE: 0.1276\n    Epoch 3/10 | Val CCC: 0.0325, MAE: 0.1321\n    Epoch 4/10 | Val CCC: 0.0334, MAE: 0.1260\n    Epoch 5/10 | Val CCC: 0.0363, MAE: 0.1305\n    Epoch 6/10 | Val CCC: 0.0453, MAE: 0.1219\n    Epoch 7/10 | Val CCC: 0.0411, MAE: 0.1213\n    Epoch 8/10 | Val CCC: 0.0523, MAE: 0.1232\n    Epoch 9/10 | Val CCC: 0.0499, MAE: 0.1243\n    Epoch 10/10 | Val CCC: 0.0514, MAE: 0.1213\n  Avg CCC: 0.0541, MAE: 0.1238\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0379, MAE: 0.1271\n    Epoch 2/10 | Val CCC: 0.0279, MAE: 0.1221\n    Epoch 3/10 | Val CCC: 0.0450, MAE: 0.1288\n    Epoch 4/10 | Val CCC: 0.0390, MAE: 0.1284\n    Epoch 5/10 | Val CCC: 0.0509, MAE: 0.1234\n    Epoch 6/10 | Val CCC: 0.0475, MAE: 0.1212\n    Epoch 7/10 | Val CCC: 0.0306, MAE: 0.1210\n    Epoch 8/10 | Val CCC: 0.0404, MAE: 0.1211\n    Epoch 9/10 | Val CCC: 0.0342, MAE: 0.1213\n    Epoch 10/10 | Val CCC: 0.0367, MAE: 0.1211\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0413, MAE: 0.1511\n    Epoch 2/10 | Val CCC: 0.0391, MAE: 0.1277\n    Epoch 3/10 | Val CCC: 0.0346, MAE: 0.1246\n    Epoch 4/10 | Val CCC: 0.0411, MAE: 0.1216\n    Epoch 5/10 | Val CCC: 0.0325, MAE: 0.1205\n    Epoch 6/10 | Val CCC: 0.0505, MAE: 0.1205\n    Epoch 7/10 | Val CCC: 0.0284, MAE: 0.1205\n    Epoch 8/10 | Val CCC: 0.0454, MAE: 0.1213\n    Epoch 9/10 | Val CCC: 0.0351, MAE: 0.1205\n    Epoch 10/10 | Val CCC: 0.0229, MAE: 0.1207\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0225, MAE: 0.1344\n    Epoch 2/10 | Val CCC: 0.0412, MAE: 0.1278\n    Epoch 3/10 | Val CCC: 0.0512, MAE: 0.1252\n    Epoch 4/10 | Val CCC: 0.0376, MAE: 0.1243\n    Epoch 5/10 | Val CCC: 0.0444, MAE: 0.1222\n    Epoch 6/10 | Val CCC: 0.0670, MAE: 0.1225\n    Epoch 7/10 | Val CCC: 0.0481, MAE: 0.1214\n    Epoch 8/10 | Val CCC: 0.0296, MAE: 0.1217\n    Epoch 9/10 | Val CCC: 0.0453, MAE: 0.1213\n    Epoch 10/10 | Val CCC: 0.0368, MAE: 0.1216\n  Avg CCC: 0.0561, MAE: 0.1221\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0267, MAE: 0.1260\n    Epoch 2/10 | Val CCC: 0.0422, MAE: 0.1227\n    Epoch 3/10 | Val CCC: 0.0376, MAE: 0.1213\n    Epoch 4/10 | Val CCC: 0.0422, MAE: 0.1212\n    Epoch 5/10 | Val CCC: 0.0490, MAE: 0.1214\n    Epoch 6/10 | Val CCC: 0.0220, MAE: 0.1221\n    Epoch 7/10 | Val CCC: 0.0391, MAE: 0.1216\n    Epoch 8/10 | Val CCC: 0.0405, MAE: 0.1245\n    Epoch 9/10 | Val CCC: 0.0274, MAE: 0.1211\n    Epoch 10/10 | Val CCC: 0.0534, MAE: 0.1232\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0352, MAE: 0.1210\n    Epoch 2/10 | Val CCC: 0.0485, MAE: 0.1211\n    Epoch 3/10 | Val CCC: 0.0506, MAE: 0.1212\n    Epoch 4/10 | Val CCC: 0.0340, MAE: 0.1229\n    Epoch 5/10 | Val CCC: 0.0439, MAE: 0.1206\n    Epoch 6/10 | Val CCC: 0.0327, MAE: 0.1207\n    Epoch 7/10 | Val CCC: 0.0316, MAE: 0.1215\n    Epoch 8/10 | Val CCC: 0.0386, MAE: 0.1212\n    Epoch 9/10 | Val CCC: 0.0281, MAE: 0.1206\n    Epoch 10/10 | Val CCC: 0.0244, MAE: 0.1207\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0392, MAE: 0.1216\n    Epoch 2/10 | Val CCC: 0.0391, MAE: 0.1216\n    Epoch 3/10 | Val CCC: 0.0427, MAE: 0.1231\n    Epoch 4/10 | Val CCC: 0.0440, MAE: 0.1235\n    Epoch 5/10 | Val CCC: 0.0304, MAE: 0.1221\n    Epoch 6/10 | Val CCC: 0.0476, MAE: 0.1252\n    Epoch 7/10 | Val CCC: 0.0378, MAE: 0.1220\n    Epoch 8/10 | Val CCC: 0.0239, MAE: 0.1227\n    Epoch 9/10 | Val CCC: -0.0000, MAE: 0.1231\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1249\n  Avg CCC: 0.0506, MAE: 0.1232\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0290, MAE: 0.1239\n    Epoch 2/10 | Val CCC: 0.0376, MAE: 0.1213\n    Epoch 3/10 | Val CCC: 0.0258, MAE: 0.1239\n    Epoch 4/10 | Val CCC: 0.0429, MAE: 0.1219\n    Epoch 5/10 | Val CCC: 0.0322, MAE: 0.1255\n    Epoch 6/10 | Val CCC: 0.0329, MAE: 0.1214\n    Epoch 7/10 | Val CCC: 0.0003, MAE: 0.1248\n    Epoch 8/10 | Val CCC: 0.0481, MAE: 0.1225\n    Epoch 9/10 | Val CCC: 0.0326, MAE: 0.1210\n    Epoch 10/10 | Val CCC: 0.0302, MAE: 0.1211\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0418, MAE: 0.1268\n    Epoch 2/10 | Val CCC: 0.0447, MAE: 0.1218\n    Epoch 3/10 | Val CCC: 0.0455, MAE: 0.1214\n    Epoch 4/10 | Val CCC: 0.0451, MAE: 0.1208\n    Epoch 5/10 | Val CCC: 0.0517, MAE: 0.1208\n    Epoch 6/10 | Val CCC: 0.0380, MAE: 0.1205\n    Epoch 7/10 | Val CCC: 0.0421, MAE: 0.1208\n    Epoch 8/10 | Val CCC: 0.0325, MAE: 0.1205\n    Epoch 9/10 | Val CCC: 0.0472, MAE: 0.1208\n    Epoch 10/10 | Val CCC: 0.0404, MAE: 0.1206\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0435, MAE: 0.1219\n    Epoch 2/10 | Val CCC: 0.0406, MAE: 0.1232\n    Epoch 3/10 | Val CCC: 0.0444, MAE: 0.1217\n    Epoch 4/10 | Val CCC: 0.0237, MAE: 0.1234\n    Epoch 5/10 | Val CCC: 0.0357, MAE: 0.1219\n    Epoch 6/10 | Val CCC: 0.0402, MAE: 0.1219\n    Epoch 7/10 | Val CCC: 0.0323, MAE: 0.1216\n    Epoch 8/10 | Val CCC: 0.0411, MAE: 0.1217\n    Epoch 9/10 | Val CCC: 0.0402, MAE: 0.1214\n    Epoch 10/10 | Val CCC: 0.0351, MAE: 0.1215\n  Avg CCC: 0.0481, MAE: 0.1217\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0509, MAE: 0.1207\n    Epoch 2/10 | Val CCC: 0.0426, MAE: 0.1208\n    Epoch 3/10 | Val CCC: 0.0542, MAE: 0.1207\n    Epoch 4/10 | Val CCC: 0.0804, MAE: 0.1215\n    Epoch 5/10 | Val CCC: 0.0468, MAE: 0.1204\n    Epoch 6/10 | Val CCC: 0.0465, MAE: 0.1219\n    Epoch 7/10 | Val CCC: 0.0459, MAE: 0.1207\n    Epoch 8/10 | Val CCC: 0.0547, MAE: 0.1207\n    Epoch 9/10 | Val CCC: 0.0633, MAE: 0.1206\n    Epoch 10/10 | Val CCC: 0.0417, MAE: 0.1208\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0353, MAE: 0.1211\n    Epoch 2/10 | Val CCC: 0.0557, MAE: 0.1208\n    Epoch 3/10 | Val CCC: 0.0765, MAE: 0.1222\n    Epoch 4/10 | Val CCC: 0.0853, MAE: 0.1216\n    Epoch 5/10 | Val CCC: 0.0708, MAE: 0.1204\n    Epoch 6/10 | Val CCC: 0.0697, MAE: 0.1220\n    Epoch 7/10 | Val CCC: 0.0390, MAE: 0.1222\n    Epoch 8/10 | Val CCC: 0.0451, MAE: 0.1202\n    Epoch 9/10 | Val CCC: 0.0175, MAE: 0.1224\n    Epoch 10/10 | Val CCC: 0.0375, MAE: 0.1202\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0831, MAE: 0.1224\n    Epoch 2/10 | Val CCC: 0.0624, MAE: 0.1213\n    Epoch 3/10 | Val CCC: 0.0639, MAE: 0.1212\n    Epoch 4/10 | Val CCC: 0.0331, MAE: 0.1223\n    Epoch 5/10 | Val CCC: 0.0431, MAE: 0.1218\n    Epoch 6/10 | Val CCC: 0.0420, MAE: 0.1214\n    Epoch 7/10 | Val CCC: 0.0548, MAE: 0.1209\n    Epoch 8/10 | Val CCC: 0.0520, MAE: 0.1208\n    Epoch 9/10 | Val CCC: 0.0489, MAE: 0.1210\n    Epoch 10/10 | Val CCC: 0.0476, MAE: 0.1214\n  Avg CCC: 0.0829, MAE: 0.1218\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0227, MAE: 0.1221\n    Epoch 2/10 | Val CCC: 0.0002, MAE: 0.1239\n    Epoch 3/10 | Val CCC: 0.0211, MAE: 0.1245\n    Epoch 4/10 | Val CCC: 0.0001, MAE: 0.1227\n    Epoch 5/10 | Val CCC: -0.0000, MAE: 0.1226\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1223\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1222\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1222\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1222\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1225\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0001, MAE: 0.1220\n    Epoch 2/10 | Val CCC: 0.0202, MAE: 0.1218\n    Epoch 3/10 | Val CCC: -0.0001, MAE: 0.1233\n    Epoch 4/10 | Val CCC: 0.0254, MAE: 0.1212\n    Epoch 5/10 | Val CCC: 0.0320, MAE: 0.1209\n    Epoch 6/10 | Val CCC: 0.0301, MAE: 0.1208\n    Epoch 7/10 | Val CCC: 0.0187, MAE: 0.1208\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1219\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1219\n    Epoch 10/10 | Val CCC: -0.0000, MAE: 0.1219\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0320, MAE: 0.1235\n    Epoch 2/10 | Val CCC: 0.0372, MAE: 0.1215\n    Epoch 3/10 | Val CCC: 0.0099, MAE: 0.1227\n    Epoch 4/10 | Val CCC: 0.0210, MAE: 0.1218\n    Epoch 5/10 | Val CCC: 0.0174, MAE: 0.1221\n    Epoch 6/10 | Val CCC: 0.0365, MAE: 0.1216\n    Epoch 7/10 | Val CCC: 0.0381, MAE: 0.1215\n    Epoch 8/10 | Val CCC: 0.0173, MAE: 0.1221\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1231\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1232\n  Avg CCC: 0.0309, MAE: 0.1215\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0390, MAE: 0.1222\n    Epoch 2/10 | Val CCC: 0.0478, MAE: 0.1215\n    Epoch 3/10 | Val CCC: 0.0328, MAE: 0.1212\n    Epoch 4/10 | Val CCC: 0.0343, MAE: 0.1215\n    Epoch 5/10 | Val CCC: 0.0415, MAE: 0.1229\n    Epoch 6/10 | Val CCC: 0.0429, MAE: 0.1236\n    Epoch 7/10 | Val CCC: 0.0255, MAE: 0.1243\n    Epoch 8/10 | Val CCC: 0.0436, MAE: 0.1215\n    Epoch 9/10 | Val CCC: 0.0344, MAE: 0.1235\n    Epoch 10/10 | Val CCC: 0.0443, MAE: 0.1247\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0488, MAE: 0.1219\n    Epoch 2/10 | Val CCC: 0.0523, MAE: 0.1244\n    Epoch 3/10 | Val CCC: 0.0447, MAE: 0.1222\n    Epoch 4/10 | Val CCC: 0.0408, MAE: 0.1260\n    Epoch 5/10 | Val CCC: 0.0398, MAE: 0.1241\n    Epoch 6/10 | Val CCC: 0.0451, MAE: 0.1253\n    Epoch 7/10 | Val CCC: 0.0382, MAE: 0.1234\n    Epoch 8/10 | Val CCC: 0.0429, MAE: 0.1240\n    Epoch 9/10 | Val CCC: 0.0554, MAE: 0.1236\n    Epoch 10/10 | Val CCC: 0.0407, MAE: 0.1233\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0310, MAE: 0.1218\n    Epoch 2/10 | Val CCC: 0.0539, MAE: 0.1214\n    Epoch 3/10 | Val CCC: 0.0345, MAE: 0.1226\n    Epoch 4/10 | Val CCC: 0.0278, MAE: 0.1219\n    Epoch 5/10 | Val CCC: 0.0409, MAE: 0.1251\n    Epoch 6/10 | Val CCC: 0.0571, MAE: 0.1225\n    Epoch 7/10 | Val CCC: 0.0310, MAE: 0.1220\n    Epoch 8/10 | Val CCC: 0.0337, MAE: 0.1230\n    Epoch 9/10 | Val CCC: 0.0480, MAE: 0.1216\n    Epoch 10/10 | Val CCC: 0.0344, MAE: 0.1223\n  Avg CCC: 0.0534, MAE: 0.1225\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0262, MAE: 0.1250\n    Epoch 2/10 | Val CCC: 0.0458, MAE: 0.1255\n    Epoch 3/10 | Val CCC: 0.0231, MAE: 0.1213\n    Epoch 4/10 | Val CCC: 0.0314, MAE: 0.1211\n    Epoch 5/10 | Val CCC: 0.0468, MAE: 0.1211\n    Epoch 6/10 | Val CCC: 0.0167, MAE: 0.1214\n    Epoch 7/10 | Val CCC: 0.0243, MAE: 0.1211\n    Epoch 8/10 | Val CCC: 0.0230, MAE: 0.1212\n    Epoch 9/10 | Val CCC: 0.0399, MAE: 0.1210\n    Epoch 10/10 | Val CCC: 0.0331, MAE: 0.1210\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0277, MAE: 0.1207\n    Epoch 2/10 | Val CCC: 0.0290, MAE: 0.1224\n    Epoch 3/10 | Val CCC: 0.0380, MAE: 0.1206\n    Epoch 4/10 | Val CCC: 0.0104, MAE: 0.1215\n    Epoch 5/10 | Val CCC: 0.0427, MAE: 0.1206\n    Epoch 6/10 | Val CCC: -0.0000, MAE: 0.1219\n    Epoch 7/10 | Val CCC: -0.0000, MAE: 0.1219\n    Epoch 8/10 | Val CCC: -0.0000, MAE: 0.1219\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1219\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1219\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0220, MAE: 0.1228\n    Epoch 2/10 | Val CCC: 0.0319, MAE: 0.1216\n    Epoch 3/10 | Val CCC: 0.0125, MAE: 0.1222\n    Epoch 4/10 | Val CCC: 0.0435, MAE: 0.1215\n    Epoch 5/10 | Val CCC: 0.0296, MAE: 0.1217\n    Epoch 6/10 | Val CCC: 0.0178, MAE: 0.1220\n    Epoch 7/10 | Val CCC: -0.0000, MAE: 0.1231\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1230\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1230\n    Epoch 10/10 | Val CCC: -0.0000, MAE: 0.1232\n  Avg CCC: 0.0444, MAE: 0.1211\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0322, MAE: 0.1243\n    Epoch 2/10 | Val CCC: 0.0347, MAE: 0.1353\n    Epoch 3/10 | Val CCC: 0.0431, MAE: 0.1241\n    Epoch 4/10 | Val CCC: 0.0452, MAE: 0.1210\n    Epoch 5/10 | Val CCC: 0.0418, MAE: 0.1237\n    Epoch 6/10 | Val CCC: 0.0322, MAE: 0.1210\n    Epoch 7/10 | Val CCC: 0.0192, MAE: 0.1214\n    Epoch 8/10 | Val CCC: 0.0515, MAE: 0.1212\n    Epoch 9/10 | Val CCC: 0.0297, MAE: 0.1210\n    Epoch 10/10 | Val CCC: 0.0141, MAE: 0.1217\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0507, MAE: 0.1231\n    Epoch 2/10 | Val CCC: 0.0512, MAE: 0.1244\n    Epoch 3/10 | Val CCC: 0.0413, MAE: 0.1243\n    Epoch 4/10 | Val CCC: 0.0409, MAE: 0.1213\n    Epoch 5/10 | Val CCC: 0.0530, MAE: 0.1208\n    Epoch 6/10 | Val CCC: 0.0301, MAE: 0.1205\n    Epoch 7/10 | Val CCC: 0.0609, MAE: 0.1227\n    Epoch 8/10 | Val CCC: 0.0329, MAE: 0.1205\n    Epoch 9/10 | Val CCC: 0.0418, MAE: 0.1212\n    Epoch 10/10 | Val CCC: 0.0348, MAE: 0.1207\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0318, MAE: 0.1244\n    Epoch 2/10 | Val CCC: 0.0419, MAE: 0.1330\n    Epoch 3/10 | Val CCC: 0.0369, MAE: 0.1231\n    Epoch 4/10 | Val CCC: 0.0339, MAE: 0.1230\n    Epoch 5/10 | Val CCC: 0.0489, MAE: 0.1224\n    Epoch 6/10 | Val CCC: 0.0360, MAE: 0.1214\n    Epoch 7/10 | Val CCC: 0.0405, MAE: 0.1213\n    Epoch 8/10 | Val CCC: 0.0298, MAE: 0.1217\n    Epoch 9/10 | Val CCC: 0.0281, MAE: 0.1216\n    Epoch 10/10 | Val CCC: 0.0207, MAE: 0.1220\n  Avg CCC: 0.0538, MAE: 0.1221\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0244, MAE: 0.1216\n    Epoch 2/10 | Val CCC: 0.0332, MAE: 0.1241\n    Epoch 3/10 | Val CCC: 0.0297, MAE: 0.1243\n    Epoch 4/10 | Val CCC: 0.0382, MAE: 0.1211\n    Epoch 5/10 | Val CCC: 0.0480, MAE: 0.1224\n    Epoch 6/10 | Val CCC: 0.0297, MAE: 0.1212\n    Epoch 7/10 | Val CCC: 0.0292, MAE: 0.1211\n    Epoch 8/10 | Val CCC: 0.0414, MAE: 0.1207\n    Epoch 9/10 | Val CCC: 0.0367, MAE: 0.1232\n    Epoch 10/10 | Val CCC: 0.0370, MAE: 0.1207\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0332, MAE: 0.1291\n    Epoch 2/10 | Val CCC: 0.0528, MAE: 0.1209\n    Epoch 3/10 | Val CCC: 0.0253, MAE: 0.1266\n    Epoch 4/10 | Val CCC: 0.0542, MAE: 0.1217\n    Epoch 5/10 | Val CCC: 0.0450, MAE: 0.1216\n    Epoch 6/10 | Val CCC: 0.0353, MAE: 0.1211\n    Epoch 7/10 | Val CCC: 0.0287, MAE: 0.1205\n    Epoch 8/10 | Val CCC: 0.0220, MAE: 0.1233\n    Epoch 9/10 | Val CCC: 0.0261, MAE: 0.1207\n    Epoch 10/10 | Val CCC: 0.0555, MAE: 0.1204\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0298, MAE: 0.1243\n    Epoch 2/10 | Val CCC: 0.0391, MAE: 0.1224\n    Epoch 3/10 | Val CCC: 0.0480, MAE: 0.1211\n    Epoch 4/10 | Val CCC: 0.0363, MAE: 0.1227\n    Epoch 5/10 | Val CCC: 0.0437, MAE: 0.1240\n    Epoch 6/10 | Val CCC: 0.0439, MAE: 0.1218\n    Epoch 7/10 | Val CCC: 0.0285, MAE: 0.1219\n    Epoch 8/10 | Val CCC: 0.0376, MAE: 0.1213\n    Epoch 9/10 | Val CCC: 0.0296, MAE: 0.1219\n    Epoch 10/10 | Val CCC: 0.0329, MAE: 0.1216\n  Avg CCC: 0.0505, MAE: 0.1213\n\n>>> Best Config Selected: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n\n>>> Final Training for EXTRAVERSION (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0269\n  Epoch 2/10 - Train Loss: 0.0241\n  Epoch 3/10 - Train Loss: 0.0237\n  Epoch 4/10 - Train Loss: 0.0236\n  Epoch 5/10 - Train Loss: 0.0235\n  Epoch 6/10 - Train Loss: 0.0234\n  Epoch 7/10 - Train Loss: 0.0233\n  Epoch 8/10 - Train Loss: 0.0232\n  Epoch 9/10 - Train Loss: 0.0231\n  Epoch 10/10 - Train Loss: 0.0231\n\n==== EXTRAVERSION Evaluation on Test Set ====\nTest CCC: 0.0813, Test MAE: 0.1209, Accuracy (±0.1): 47.36%\nSaving final model for extraversion to best_audio_transformer_model_extraversion.pth\n\n--- Training for Trait: agreeableness ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0089, MAE: 0.1127\n    Epoch 2/10 | Val CCC: 0.0076, MAE: 0.1058\n    Epoch 3/10 | Val CCC: 0.0228, MAE: 0.1075\n    Epoch 4/10 | Val CCC: 0.0221, MAE: 0.1051\n    Epoch 5/10 | Val CCC: 0.0193, MAE: 0.1091\n    Epoch 6/10 | Val CCC: 0.0194, MAE: 0.1052\n    Epoch 7/10 | Val CCC: 0.0259, MAE: 0.1053\n    Epoch 8/10 | Val CCC: 0.0160, MAE: 0.1069\n    Epoch 9/10 | Val CCC: 0.0174, MAE: 0.1051\n    Epoch 10/10 | Val CCC: 0.0329, MAE: 0.1053\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0164, MAE: 0.1055\n    Epoch 2/10 | Val CCC: 0.0142, MAE: 0.1054\n    Epoch 3/10 | Val CCC: 0.0212, MAE: 0.1060\n    Epoch 4/10 | Val CCC: 0.0264, MAE: 0.1062\n    Epoch 5/10 | Val CCC: 0.0218, MAE: 0.1056\n    Epoch 6/10 | Val CCC: 0.0245, MAE: 0.1052\n    Epoch 7/10 | Val CCC: 0.0165, MAE: 0.1075\n    Epoch 8/10 | Val CCC: 0.0123, MAE: 0.1060\n    Epoch 9/10 | Val CCC: 0.0229, MAE: 0.1054\n    Epoch 10/10 | Val CCC: 0.0246, MAE: 0.1052\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0105, MAE: 0.1161\n    Epoch 2/10 | Val CCC: 0.0234, MAE: 0.1070\n    Epoch 3/10 | Val CCC: 0.0117, MAE: 0.1081\n    Epoch 4/10 | Val CCC: 0.0235, MAE: 0.1070\n    Epoch 5/10 | Val CCC: 0.0193, MAE: 0.1072\n    Epoch 6/10 | Val CCC: 0.0297, MAE: 0.1089\n    Epoch 7/10 | Val CCC: 0.0132, MAE: 0.1082\n    Epoch 8/10 | Val CCC: 0.0130, MAE: 0.1076\n    Epoch 9/10 | Val CCC: 0.0252, MAE: 0.1067\n    Epoch 10/10 | Val CCC: 0.0178, MAE: 0.1068\n  Avg CCC: 0.0296, MAE: 0.1068\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0117, MAE: 0.1074\n    Epoch 2/10 | Val CCC: 0.0146, MAE: 0.1158\n    Epoch 3/10 | Val CCC: 0.0185, MAE: 0.1060\n    Epoch 4/10 | Val CCC: 0.0279, MAE: 0.1064\n    Epoch 5/10 | Val CCC: 0.0141, MAE: 0.1052\n    Epoch 6/10 | Val CCC: 0.0182, MAE: 0.1052\n    Epoch 7/10 | Val CCC: 0.0026, MAE: 0.1055\n    Epoch 8/10 | Val CCC: 0.0114, MAE: 0.1055\n    Epoch 9/10 | Val CCC: 0.0033, MAE: 0.1053\n    Epoch 10/10 | Val CCC: 0.0064, MAE: 0.1053\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0104, MAE: 0.1148\n    Epoch 2/10 | Val CCC: 0.0187, MAE: 0.1145\n    Epoch 3/10 | Val CCC: 0.0221, MAE: 0.1086\n    Epoch 4/10 | Val CCC: 0.0212, MAE: 0.1057\n    Epoch 5/10 | Val CCC: 0.0076, MAE: 0.1057\n    Epoch 6/10 | Val CCC: 0.0082, MAE: 0.1057\n    Epoch 7/10 | Val CCC: 0.0147, MAE: 0.1054\n    Epoch 8/10 | Val CCC: 0.0221, MAE: 0.1055\n    Epoch 9/10 | Val CCC: -0.0005, MAE: 0.1061\n    Epoch 10/10 | Val CCC: 0.0069, MAE: 0.1057\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0131, MAE: 0.1174\n    Epoch 2/10 | Val CCC: 0.0081, MAE: 0.1149\n    Epoch 3/10 | Val CCC: 0.0186, MAE: 0.1098\n    Epoch 4/10 | Val CCC: 0.0140, MAE: 0.1068\n    Epoch 5/10 | Val CCC: 0.0135, MAE: 0.1068\n    Epoch 6/10 | Val CCC: 0.0103, MAE: 0.1068\n    Epoch 7/10 | Val CCC: 0.0183, MAE: 0.1068\n    Epoch 8/10 | Val CCC: 0.0110, MAE: 0.1070\n    Epoch 9/10 | Val CCC: 0.0080, MAE: 0.1070\n    Epoch 10/10 | Val CCC: 0.0049, MAE: 0.1071\n  Avg CCC: 0.0229, MAE: 0.1082\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0144, MAE: 0.1142\n    Epoch 2/10 | Val CCC: 0.0157, MAE: 0.1121\n    Epoch 3/10 | Val CCC: 0.0118, MAE: 0.1152\n    Epoch 4/10 | Val CCC: 0.0119, MAE: 0.1171\n    Epoch 5/10 | Val CCC: 0.0181, MAE: 0.1101\n    Epoch 6/10 | Val CCC: 0.0174, MAE: 0.1066\n    Epoch 7/10 | Val CCC: 0.0185, MAE: 0.1074\n    Epoch 8/10 | Val CCC: 0.0187, MAE: 0.1060\n    Epoch 9/10 | Val CCC: 0.0185, MAE: 0.1064\n    Epoch 10/10 | Val CCC: 0.0241, MAE: 0.1062\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0086, MAE: 0.1176\n    Epoch 2/10 | Val CCC: 0.0129, MAE: 0.1173\n    Epoch 3/10 | Val CCC: 0.0128, MAE: 0.1120\n    Epoch 4/10 | Val CCC: 0.0170, MAE: 0.1120\n    Epoch 5/10 | Val CCC: 0.0131, MAE: 0.1167\n    Epoch 6/10 | Val CCC: 0.0165, MAE: 0.1088\n    Epoch 7/10 | Val CCC: 0.0206, MAE: 0.1090\n    Epoch 8/10 | Val CCC: 0.0197, MAE: 0.1078\n    Epoch 9/10 | Val CCC: 0.0268, MAE: 0.1067\n    Epoch 10/10 | Val CCC: 0.0209, MAE: 0.1062\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0103, MAE: 0.1176\n    Epoch 2/10 | Val CCC: 0.0197, MAE: 0.1069\n    Epoch 3/10 | Val CCC: 0.0160, MAE: 0.1093\n    Epoch 4/10 | Val CCC: 0.0173, MAE: 0.1080\n    Epoch 5/10 | Val CCC: 0.0194, MAE: 0.1139\n    Epoch 6/10 | Val CCC: 0.0201, MAE: 0.1077\n    Epoch 7/10 | Val CCC: 0.0236, MAE: 0.1068\n    Epoch 8/10 | Val CCC: 0.0125, MAE: 0.1071\n    Epoch 9/10 | Val CCC: 0.0275, MAE: 0.1074\n    Epoch 10/10 | Val CCC: 0.0160, MAE: 0.1100\n  Avg CCC: 0.0262, MAE: 0.1068\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0125, MAE: 0.1305\n    Epoch 2/10 | Val CCC: 0.0177, MAE: 0.1180\n    Epoch 3/10 | Val CCC: 0.0223, MAE: 0.1052\n    Epoch 4/10 | Val CCC: 0.0101, MAE: 0.1134\n    Epoch 5/10 | Val CCC: 0.0197, MAE: 0.1117\n    Epoch 6/10 | Val CCC: 0.0271, MAE: 0.1054\n    Epoch 7/10 | Val CCC: 0.0129, MAE: 0.1063\n    Epoch 8/10 | Val CCC: 0.0394, MAE: 0.1072\n    Epoch 9/10 | Val CCC: 0.0227, MAE: 0.1052\n    Epoch 10/10 | Val CCC: 0.0254, MAE: 0.1071\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0144, MAE: 0.1079\n    Epoch 2/10 | Val CCC: 0.0164, MAE: 0.1102\n    Epoch 3/10 | Val CCC: 0.0160, MAE: 0.1108\n    Epoch 4/10 | Val CCC: 0.0222, MAE: 0.1056\n    Epoch 5/10 | Val CCC: 0.0182, MAE: 0.1061\n    Epoch 6/10 | Val CCC: 0.0307, MAE: 0.1064\n    Epoch 7/10 | Val CCC: 0.0255, MAE: 0.1061\n    Epoch 8/10 | Val CCC: 0.0110, MAE: 0.1059\n    Epoch 9/10 | Val CCC: 0.0151, MAE: 0.1056\n    Epoch 10/10 | Val CCC: 0.0139, MAE: 0.1056\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0132, MAE: 0.1114\n    Epoch 2/10 | Val CCC: 0.0194, MAE: 0.1224\n    Epoch 3/10 | Val CCC: 0.0107, MAE: 0.1067\n    Epoch 4/10 | Val CCC: 0.0114, MAE: 0.1226\n    Epoch 5/10 | Val CCC: 0.0141, MAE: 0.1189\n    Epoch 6/10 | Val CCC: 0.0122, MAE: 0.1134\n    Epoch 7/10 | Val CCC: 0.0171, MAE: 0.1098\n    Epoch 8/10 | Val CCC: 0.0089, MAE: 0.1083\n    Epoch 9/10 | Val CCC: 0.0231, MAE: 0.1068\n    Epoch 10/10 | Val CCC: 0.0193, MAE: 0.1066\n  Avg CCC: 0.0311, MAE: 0.1068\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0268, MAE: 0.1052\n    Epoch 2/10 | Val CCC: 0.0148, MAE: 0.1049\n    Epoch 3/10 | Val CCC: 0.0055, MAE: 0.1056\n    Epoch 4/10 | Val CCC: 0.0353, MAE: 0.1070\n    Epoch 5/10 | Val CCC: 0.0336, MAE: 0.1052\n    Epoch 6/10 | Val CCC: 0.0317, MAE: 0.1058\n    Epoch 7/10 | Val CCC: 0.0097, MAE: 0.1054\n    Epoch 8/10 | Val CCC: 0.0075, MAE: 0.1052\n    Epoch 9/10 | Val CCC: 0.0371, MAE: 0.1055\n    Epoch 10/10 | Val CCC: 0.0228, MAE: 0.1051\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0431, MAE: 0.1102\n    Epoch 2/10 | Val CCC: -0.0035, MAE: 0.1076\n    Epoch 3/10 | Val CCC: 0.0316, MAE: 0.1055\n    Epoch 4/10 | Val CCC: 0.0048, MAE: 0.1066\n    Epoch 5/10 | Val CCC: 0.0366, MAE: 0.1059\n    Epoch 6/10 | Val CCC: 0.0343, MAE: 0.1061\n    Epoch 7/10 | Val CCC: 0.0370, MAE: 0.1076\n    Epoch 8/10 | Val CCC: 0.0196, MAE: 0.1056\n    Epoch 9/10 | Val CCC: 0.0236, MAE: 0.1060\n    Epoch 10/10 | Val CCC: 0.0269, MAE: 0.1053\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0136, MAE: 0.1099\n    Epoch 2/10 | Val CCC: -0.0073, MAE: 0.1080\n    Epoch 3/10 | Val CCC: 0.0185, MAE: 0.1082\n    Epoch 4/10 | Val CCC: 0.0156, MAE: 0.1069\n    Epoch 5/10 | Val CCC: 0.0119, MAE: 0.1067\n    Epoch 6/10 | Val CCC: 0.0051, MAE: 0.1085\n    Epoch 7/10 | Val CCC: 0.0206, MAE: 0.1071\n    Epoch 8/10 | Val CCC: 0.0432, MAE: 0.1093\n    Epoch 9/10 | Val CCC: 0.0033, MAE: 0.1080\n    Epoch 10/10 | Val CCC: 0.0159, MAE: 0.1073\n  Avg CCC: 0.0411, MAE: 0.1083\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0169, MAE: 0.1057\n    Epoch 2/10 | Val CCC: 0.0193, MAE: 0.1058\n    Epoch 3/10 | Val CCC: 0.0206, MAE: 0.1052\n    Epoch 4/10 | Val CCC: 0.0103, MAE: 0.1054\n    Epoch 5/10 | Val CCC: 0.0010, MAE: 0.1057\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1056\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1055\n    Epoch 8/10 | Val CCC: 0.0037, MAE: 0.1053\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1056\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1056\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0064, MAE: 0.1057\n    Epoch 2/10 | Val CCC: 0.0269, MAE: 0.1058\n    Epoch 3/10 | Val CCC: 0.0103, MAE: 0.1055\n    Epoch 4/10 | Val CCC: 0.0045, MAE: 0.1061\n    Epoch 5/10 | Val CCC: 0.0026, MAE: 0.1058\n    Epoch 6/10 | Val CCC: 0.0097, MAE: 0.1061\n    Epoch 7/10 | Val CCC: 0.0046, MAE: 0.1058\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1070\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1058\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1058\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0113, MAE: 0.1080\n    Epoch 2/10 | Val CCC: 0.0106, MAE: 0.1069\n    Epoch 3/10 | Val CCC: 0.0169, MAE: 0.1103\n    Epoch 4/10 | Val CCC: 0.0000, MAE: 0.1074\n    Epoch 5/10 | Val CCC: 0.0000, MAE: 0.1072\n    Epoch 6/10 | Val CCC: 0.0002, MAE: 0.1076\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1072\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1072\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1077\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1077\n  Avg CCC: 0.0215, MAE: 0.1071\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0184, MAE: 0.1073\n    Epoch 2/10 | Val CCC: 0.0118, MAE: 0.1061\n    Epoch 3/10 | Val CCC: 0.0153, MAE: 0.1083\n    Epoch 4/10 | Val CCC: 0.0220, MAE: 0.1066\n    Epoch 5/10 | Val CCC: 0.0201, MAE: 0.1079\n    Epoch 6/10 | Val CCC: 0.0118, MAE: 0.1053\n    Epoch 7/10 | Val CCC: 0.0131, MAE: 0.1052\n    Epoch 8/10 | Val CCC: 0.0209, MAE: 0.1058\n    Epoch 9/10 | Val CCC: 0.0175, MAE: 0.1060\n    Epoch 10/10 | Val CCC: 0.0240, MAE: 0.1064\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0086, MAE: 0.1058\n    Epoch 2/10 | Val CCC: 0.0113, MAE: 0.1055\n    Epoch 3/10 | Val CCC: 0.0205, MAE: 0.1056\n    Epoch 4/10 | Val CCC: 0.0145, MAE: 0.1056\n    Epoch 5/10 | Val CCC: 0.0121, MAE: 0.1091\n    Epoch 6/10 | Val CCC: 0.0228, MAE: 0.1097\n    Epoch 7/10 | Val CCC: 0.0192, MAE: 0.1053\n    Epoch 8/10 | Val CCC: 0.0173, MAE: 0.1062\n    Epoch 9/10 | Val CCC: 0.0292, MAE: 0.1054\n    Epoch 10/10 | Val CCC: 0.0134, MAE: 0.1063\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0064, MAE: 0.1079\n    Epoch 2/10 | Val CCC: 0.0172, MAE: 0.1073\n    Epoch 3/10 | Val CCC: 0.0238, MAE: 0.1074\n    Epoch 4/10 | Val CCC: 0.0175, MAE: 0.1080\n    Epoch 5/10 | Val CCC: 0.0181, MAE: 0.1074\n    Epoch 6/10 | Val CCC: 0.0142, MAE: 0.1091\n    Epoch 7/10 | Val CCC: 0.0207, MAE: 0.1111\n    Epoch 8/10 | Val CCC: 0.0207, MAE: 0.1067\n    Epoch 9/10 | Val CCC: 0.0203, MAE: 0.1084\n    Epoch 10/10 | Val CCC: 0.0137, MAE: 0.1069\n  Avg CCC: 0.0257, MAE: 0.1064\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0233, MAE: 0.1053\n    Epoch 2/10 | Val CCC: 0.0309, MAE: 0.1052\n    Epoch 3/10 | Val CCC: 0.0345, MAE: 0.1053\n    Epoch 4/10 | Val CCC: 0.0022, MAE: 0.1061\n    Epoch 5/10 | Val CCC: 0.0255, MAE: 0.1048\n    Epoch 6/10 | Val CCC: 0.0279, MAE: 0.1053\n    Epoch 7/10 | Val CCC: 0.0220, MAE: 0.1052\n    Epoch 8/10 | Val CCC: 0.0273, MAE: 0.1056\n    Epoch 9/10 | Val CCC: 0.0199, MAE: 0.1050\n    Epoch 10/10 | Val CCC: 0.0302, MAE: 0.1049\n  Fold 2/3\n    Epoch 1/10 | Val CCC: -0.0082, MAE: 0.1097\n    Epoch 2/10 | Val CCC: 0.0145, MAE: 0.1053\n    Epoch 3/10 | Val CCC: 0.0084, MAE: 0.1072\n    Epoch 4/10 | Val CCC: 0.0245, MAE: 0.1055\n    Epoch 5/10 | Val CCC: 0.0195, MAE: 0.1052\n    Epoch 6/10 | Val CCC: 0.0116, MAE: 0.1055\n    Epoch 7/10 | Val CCC: 0.0221, MAE: 0.1051\n    Epoch 8/10 | Val CCC: 0.0215, MAE: 0.1052\n    Epoch 9/10 | Val CCC: 0.0275, MAE: 0.1050\n    Epoch 10/10 | Val CCC: 0.0113, MAE: 0.1056\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0290, MAE: 0.1066\n    Epoch 2/10 | Val CCC: 0.0065, MAE: 0.1074\n    Epoch 3/10 | Val CCC: 0.0353, MAE: 0.1072\n    Epoch 4/10 | Val CCC: 0.0271, MAE: 0.1065\n    Epoch 5/10 | Val CCC: 0.0196, MAE: 0.1065\n    Epoch 6/10 | Val CCC: 0.0195, MAE: 0.1067\n    Epoch 7/10 | Val CCC: 0.0222, MAE: 0.1070\n    Epoch 8/10 | Val CCC: 0.0259, MAE: 0.1071\n    Epoch 9/10 | Val CCC: 0.0328, MAE: 0.1073\n    Epoch 10/10 | Val CCC: 0.0284, MAE: 0.1065\n  Avg CCC: 0.0324, MAE: 0.1059\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0065, MAE: 0.1268\n    Epoch 2/10 | Val CCC: 0.0113, MAE: 0.1191\n    Epoch 3/10 | Val CCC: 0.0150, MAE: 0.1213\n    Epoch 4/10 | Val CCC: 0.0229, MAE: 0.1083\n    Epoch 5/10 | Val CCC: 0.0154, MAE: 0.1068\n    Epoch 6/10 | Val CCC: 0.0127, MAE: 0.1056\n    Epoch 7/10 | Val CCC: 0.0132, MAE: 0.1064\n    Epoch 8/10 | Val CCC: 0.0205, MAE: 0.1152\n    Epoch 9/10 | Val CCC: 0.0133, MAE: 0.1068\n    Epoch 10/10 | Val CCC: 0.0170, MAE: 0.1067\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0072, MAE: 0.1116\n    Epoch 2/10 | Val CCC: 0.0100, MAE: 0.1078\n    Epoch 3/10 | Val CCC: 0.0164, MAE: 0.1176\n    Epoch 4/10 | Val CCC: 0.0187, MAE: 0.1097\n    Epoch 5/10 | Val CCC: 0.0132, MAE: 0.1056\n    Epoch 6/10 | Val CCC: 0.0227, MAE: 0.1074\n    Epoch 7/10 | Val CCC: 0.0169, MAE: 0.1065\n    Epoch 8/10 | Val CCC: 0.0214, MAE: 0.1077\n    Epoch 9/10 | Val CCC: 0.0252, MAE: 0.1054\n    Epoch 10/10 | Val CCC: 0.0224, MAE: 0.1052\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0156, MAE: 0.1102\n    Epoch 2/10 | Val CCC: 0.0056, MAE: 0.1195\n    Epoch 3/10 | Val CCC: 0.0079, MAE: 0.1159\n    Epoch 4/10 | Val CCC: 0.0180, MAE: 0.1100\n    Epoch 5/10 | Val CCC: 0.0171, MAE: 0.1123\n    Epoch 6/10 | Val CCC: 0.0093, MAE: 0.1069\n    Epoch 7/10 | Val CCC: 0.0145, MAE: 0.1079\n    Epoch 8/10 | Val CCC: 0.0161, MAE: 0.1068\n    Epoch 9/10 | Val CCC: 0.0168, MAE: 0.1091\n    Epoch 10/10 | Val CCC: 0.0333, MAE: 0.1077\n  Avg CCC: 0.0271, MAE: 0.1071\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0129, MAE: 0.1161\n    Epoch 2/10 | Val CCC: 0.0002, MAE: 0.1055\n    Epoch 3/10 | Val CCC: 0.0007, MAE: 0.1085\n    Epoch 4/10 | Val CCC: 0.0019, MAE: 0.1062\n    Epoch 5/10 | Val CCC: 0.0020, MAE: 0.1055\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1057\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1055\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1055\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1055\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1055\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0037, MAE: 0.1211\n    Epoch 2/10 | Val CCC: 0.0091, MAE: 0.1056\n    Epoch 3/10 | Val CCC: 0.0091, MAE: 0.1063\n    Epoch 4/10 | Val CCC: 0.0147, MAE: 0.1058\n    Epoch 5/10 | Val CCC: 0.0117, MAE: 0.1059\n    Epoch 6/10 | Val CCC: 0.0056, MAE: 0.1061\n    Epoch 7/10 | Val CCC: 0.0121, MAE: 0.1078\n    Epoch 3/10 | Val CCC: 0.0003, MAE: 0.1072\n    Epoch 4/10 | Val CCC: -0.0000, MAE: 0.1072\n    Epoch 5/10 | Val CCC: 0.0000, MAE: 0.1072\n    Epoch 6/10 | Val CCC: 0.0000, MAE: 0.1072\n    Epoch 7/10 | Val CCC: 0.0000, MAE: 0.1072\n    Epoch 8/10 | Val CCC: 0.0000, MAE: 0.1075\n    Epoch 9/10 | Val CCC: 0.0000, MAE: 0.1074\n    Epoch 10/10 | Val CCC: 0.0000, MAE: 0.1075\n  Avg CCC: 0.0145, MAE: 0.1100\n\n>>> Best Config Selected: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n\n>>> Final Training for AGREEABLENESS (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0214\n  Epoch 2/10 - Train Loss: 0.0192\n  Epoch 3/10 - Train Loss: 0.0189\n  Epoch 4/10 - Train Loss: 0.0187\n  Epoch 5/10 - Train Loss: 0.0185\n  Epoch 6/10 - Train Loss: 0.0183\n  Epoch 7/10 - Train Loss: 0.0181\n  Epoch 8/10 - Train Loss: 0.0180\n  Epoch 9/10 - Train Loss: 0.0180\n  Epoch 10/10 - Train Loss: 0.0179\n\n==== AGREEABLENESS Evaluation on Test Set ====\nTest CCC: 0.0080, Test MAE: 0.1057, Accuracy (±0.1): 54.65%\nSaving final model for agreeableness to best_audio_transformer_model_agreeableness.pth\n\n--- Training for Trait: neuroticism ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0355, MAE: 0.1291\n    Epoch 2/10 | Val CCC: 0.0361, MAE: 0.1239\n    Epoch 3/10 | Val CCC: 0.0269, MAE: 0.1361\n    Epoch 4/10 | Val CCC: 0.0387, MAE: 0.1282\n    Epoch 5/10 | Val CCC: 0.0263, MAE: 0.1337\n    Epoch 6/10 | Val CCC: 0.0253, MAE: 0.1232\n    Epoch 7/10 | Val CCC: 0.0381, MAE: 0.1225\n    Epoch 8/10 | Val CCC: 0.0322, MAE: 0.1243\n    Epoch 9/10 | Val CCC: 0.0331, MAE: 0.1255\n    Epoch 10/10 | Val CCC: 0.0348, MAE: 0.1266\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0325, MAE: 0.1241\n    Epoch 2/10 | Val CCC: 0.0338, MAE: 0.1282\n    Epoch 3/10 | Val CCC: 0.0299, MAE: 0.1272\n    Epoch 4/10 | Val CCC: 0.0360, MAE: 0.1229\n    Epoch 5/10 | Val CCC: 0.0374, MAE: 0.1292\n    Epoch 6/10 | Val CCC: 0.0312, MAE: 0.1261\n    Epoch 7/10 | Val CCC: 0.0297, MAE: 0.1236\n    Epoch 8/10 | Val CCC: 0.0473, MAE: 0.1253\n    Epoch 9/10 | Val CCC: 0.0301, MAE: 0.1232\n    Epoch 10/10 | Val CCC: 0.0242, MAE: 0.1240\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0301, MAE: 0.1235\n    Epoch 2/10 | Val CCC: 0.0464, MAE: 0.1240\n    Epoch 3/10 | Val CCC: 0.0395, MAE: 0.1275\n    Epoch 4/10 | Val CCC: 0.0340, MAE: 0.1226\n    Epoch 5/10 | Val CCC: 0.0462, MAE: 0.1263\n    Epoch 6/10 | Val CCC: 0.0365, MAE: 0.1232\n    Epoch 7/10 | Val CCC: 0.0349, MAE: 0.1264\n    Epoch 8/10 | Val CCC: 0.0223, MAE: 0.1257\n    Epoch 9/10 | Val CCC: 0.0200, MAE: 0.1265\n    Epoch 10/10 | Val CCC: 0.0401, MAE: 0.1285\n  Avg CCC: 0.0441, MAE: 0.1259\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0284, MAE: 0.1618\n    Epoch 2/10 | Val CCC: 0.0199, MAE: 0.1478\n    Epoch 3/10 | Val CCC: 0.0216, MAE: 0.1456\n    Epoch 4/10 | Val CCC: 0.0186, MAE: 0.1573\n    Epoch 5/10 | Val CCC: 0.0431, MAE: 0.1394\n    Epoch 6/10 | Val CCC: 0.0395, MAE: 0.1354\n    Epoch 7/10 | Val CCC: 0.0366, MAE: 0.1295\n    Epoch 8/10 | Val CCC: 0.0380, MAE: 0.1238\n    Epoch 9/10 | Val CCC: 0.0393, MAE: 0.1223\n    Epoch 10/10 | Val CCC: 0.0453, MAE: 0.1215\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0269, MAE: 0.1536\n    Epoch 2/10 | Val CCC: 0.0217, MAE: 0.1425\n    Epoch 3/10 | Val CCC: 0.0271, MAE: 0.1552\n    Epoch 4/10 | Val CCC: 0.0338, MAE: 0.1517\n    Epoch 5/10 | Val CCC: 0.0414, MAE: 0.1296\n    Epoch 6/10 | Val CCC: 0.0326, MAE: 0.1374\n    Epoch 7/10 | Val CCC: 0.0455, MAE: 0.1332\n    Epoch 8/10 | Val CCC: 0.0398, MAE: 0.1257\n    Epoch 9/10 | Val CCC: 0.0375, MAE: 0.1247\n    Epoch 10/10 | Val CCC: 0.0474, MAE: 0.1230\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0300, MAE: 0.1407\n    Epoch 2/10 | Val CCC: 0.0367, MAE: 0.1409\n    Epoch 3/10 | Val CCC: 0.0316, MAE: 0.1262\n    Epoch 4/10 | Val CCC: 0.0287, MAE: 0.1268\n    Epoch 5/10 | Val CCC: 0.0366, MAE: 0.1252\n    Epoch 6/10 | Val CCC: 0.0355, MAE: 0.1223\n    Epoch 7/10 | Val CCC: 0.0361, MAE: 0.1229\n    Epoch 8/10 | Val CCC: 0.0511, MAE: 0.1243\n    Epoch 9/10 | Val CCC: 0.0557, MAE: 0.1223\n    Epoch 10/10 | Val CCC: 0.0662, MAE: 0.1227\n  Avg CCC: 0.0529, MAE: 0.1224\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0331, MAE: 0.1238\n    Epoch 2/10 | Val CCC: 0.0290, MAE: 0.1250\n    Epoch 3/10 | Val CCC: 0.0243, MAE: 0.1364\n    Epoch 4/10 | Val CCC: 0.0242, MAE: 0.1398\n    Epoch 5/10 | Val CCC: 0.0321, MAE: 0.1336\n    Epoch 6/10 | Val CCC: 0.0285, MAE: 0.1281\n    Epoch 7/10 | Val CCC: 0.0331, MAE: 0.1374\n    Epoch 8/10 | Val CCC: 0.0431, MAE: 0.1254\n    Epoch 9/10 | Val CCC: 0.0434, MAE: 0.1251\n    Epoch 10/10 | Val CCC: 0.0341, MAE: 0.1262\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0414, MAE: 0.1291\n    Epoch 2/10 | Val CCC: 0.0286, MAE: 0.1294\n    Epoch 3/10 | Val CCC: 0.0312, MAE: 0.1369\n    Epoch 4/10 | Val CCC: 0.0376, MAE: 0.1296\n    Epoch 5/10 | Val CCC: 0.0436, MAE: 0.1304\n    Epoch 6/10 | Val CCC: 0.0389, MAE: 0.1324\n    Epoch 7/10 | Val CCC: 0.0381, MAE: 0.1252\n    Epoch 8/10 | Val CCC: 0.0356, MAE: 0.1321\n    Epoch 9/10 | Val CCC: 0.0349, MAE: 0.1305\n    Epoch 10/10 | Val CCC: 0.0405, MAE: 0.1243\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0317, MAE: 0.1240\n    Epoch 2/10 | Val CCC: 0.0330, MAE: 0.1312\n    Epoch 3/10 | Val CCC: 0.0290, MAE: 0.1320\n    Epoch 4/10 | Val CCC: 0.0334, MAE: 0.1314\n    Epoch 5/10 | Val CCC: 0.0265, MAE: 0.1423\n    Epoch 6/10 | Val CCC: 0.0370, MAE: 0.1305\n    Epoch 7/10 | Val CCC: 0.0368, MAE: 0.1340\n    Epoch 8/10 | Val CCC: 0.0363, MAE: 0.1316\n    Epoch 9/10 | Val CCC: 0.0374, MAE: 0.1271\n    Epoch 10/10 | Val CCC: 0.0424, MAE: 0.1244\n  Avg CCC: 0.0431, MAE: 0.1266\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0379, MAE: 0.1223\n    Epoch 2/10 | Val CCC: 0.0614, MAE: 0.1224\n    Epoch 3/10 | Val CCC: 0.0149, MAE: 0.1228\n    Epoch 4/10 | Val CCC: 0.0487, MAE: 0.1217\n    Epoch 5/10 | Val CCC: 0.0453, MAE: 0.1212\n    Epoch 6/10 | Val CCC: 0.0483, MAE: 0.1211\n    Epoch 7/10 | Val CCC: 0.0516, MAE: 0.1233\n    Epoch 8/10 | Val CCC: 0.0540, MAE: 0.1212\n    Epoch 9/10 | Val CCC: 0.0488, MAE: 0.1210\n    Epoch 10/10 | Val CCC: 0.0470, MAE: 0.1211\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0417, MAE: 0.1216\n    Epoch 2/10 | Val CCC: 0.0267, MAE: 0.1221\n    Epoch 3/10 | Val CCC: 0.0184, MAE: 0.1232\n    Epoch 4/10 | Val CCC: 0.0169, MAE: 0.1225\n    Epoch 5/10 | Val CCC: 0.0430, MAE: 0.1218\n    Epoch 6/10 | Val CCC: 0.0593, MAE: 0.1225\n    Epoch 7/10 | Val CCC: 0.0574, MAE: 0.1218\n    Epoch 8/10 | Val CCC: 0.0398, MAE: 0.1216\n    Epoch 9/10 | Val CCC: 0.0433, MAE: 0.1224\n    Epoch 10/10 | Val CCC: 0.0370, MAE: 0.1230\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0519, MAE: 0.1219\n    Epoch 2/10 | Val CCC: 0.0328, MAE: 0.1224\n    Epoch 3/10 | Val CCC: 0.0216, MAE: 0.1225\n    Epoch 4/10 | Val CCC: 0.0202, MAE: 0.1232\n    Epoch 5/10 | Val CCC: 0.0483, MAE: 0.1217\n    Epoch 6/10 | Val CCC: 0.0366, MAE: 0.1219\n    Epoch 7/10 | Val CCC: 0.0274, MAE: 0.1226\n    Epoch 8/10 | Val CCC: 0.0293, MAE: 0.1220\n    Epoch 9/10 | Val CCC: 0.0415, MAE: 0.1216\n    Epoch 10/10 | Val CCC: 0.0606, MAE: 0.1216\n  Avg CCC: 0.0604, MAE: 0.1222\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0221, MAE: 0.1339\n    Epoch 2/10 | Val CCC: 0.0435, MAE: 0.1288\n    Epoch 3/10 | Val CCC: 0.0371, MAE: 0.1263\n    Epoch 4/10 | Val CCC: 0.0490, MAE: 0.1270\n    Epoch 5/10 | Val CCC: 0.0361, MAE: 0.1220\n    Epoch 6/10 | Val CCC: 0.0413, MAE: 0.1219\n    Epoch 7/10 | Val CCC: 0.0277, MAE: 0.1216\n    Epoch 8/10 | Val CCC: 0.0403, MAE: 0.1218\n    Epoch 9/10 | Val CCC: 0.0242, MAE: 0.1217\n    Epoch 10/10 | Val CCC: 0.0134, MAE: 0.1223\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0173, MAE: 0.1555\n    Epoch 2/10 | Val CCC: 0.0261, MAE: 0.1242\n    Epoch 3/10 | Val CCC: 0.0419, MAE: 0.1273\n    Epoch 4/10 | Val CCC: 0.0458, MAE: 0.1287\n    Epoch 5/10 | Val CCC: 0.0392, MAE: 0.1237\n    Epoch 6/10 | Val CCC: 0.0440, MAE: 0.1232\n    Epoch 7/10 | Val CCC: 0.0379, MAE: 0.1220\n    Epoch 8/10 | Val CCC: 0.0328, MAE: 0.1221\n    Epoch 9/10 | Val CCC: 0.0294, MAE: 0.1221\n    Epoch 10/10 | Val CCC: 0.0499, MAE: 0.1230\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0154, MAE: 0.1829\n    Epoch 2/10 | Val CCC: 0.0201, MAE: 0.1423\n    Epoch 3/10 | Val CCC: 0.0346, MAE: 0.1255\n    Epoch 4/10 | Val CCC: 0.0508, MAE: 0.1253\n    Epoch 5/10 | Val CCC: 0.0492, MAE: 0.1268\n    Epoch 6/10 | Val CCC: 0.0438, MAE: 0.1246\n    Epoch 7/10 | Val CCC: 0.0336, MAE: 0.1225\n    Epoch 8/10 | Val CCC: 0.0290, MAE: 0.1225\n    Epoch 9/10 | Val CCC: 0.0274, MAE: 0.1226\n    Epoch 10/10 | Val CCC: 0.0295, MAE: 0.1220\n  Avg CCC: 0.0499, MAE: 0.1251\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0167, MAE: 0.1219\n    Epoch 2/10 | Val CCC: 0.0527, MAE: 0.1216\n    Epoch 3/10 | Val CCC: 0.0432, MAE: 0.1230\n    Epoch 4/10 | Val CCC: 0.0454, MAE: 0.1213\n    Epoch 5/10 | Val CCC: 0.0407, MAE: 0.1214\n    Epoch 6/10 | Val CCC: 0.0419, MAE: 0.1212\n    Epoch 7/10 | Val CCC: 0.0340, MAE: 0.1213\n    Epoch 8/10 | Val CCC: 0.0268, MAE: 0.1241\n    Epoch 9/10 | Val CCC: 0.0416, MAE: 0.1215\n    Epoch 10/10 | Val CCC: 0.0210, MAE: 0.1216\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0229, MAE: 0.1243\n    Epoch 2/10 | Val CCC: 0.0522, MAE: 0.1222\n    Epoch 3/10 | Val CCC: 0.0448, MAE: 0.1224\n    Epoch 4/10 | Val CCC: 0.0338, MAE: 0.1219\n    Epoch 5/10 | Val CCC: 0.0391, MAE: 0.1218\n    Epoch 6/10 | Val CCC: 0.0437, MAE: 0.1218\n    Epoch 7/10 | Val CCC: 0.0412, MAE: 0.1217\n    Epoch 8/10 | Val CCC: 0.0475, MAE: 0.1217\n    Epoch 9/10 | Val CCC: 0.0400, MAE: 0.1248\n    Epoch 10/10 | Val CCC: 0.0310, MAE: 0.1219\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0122, MAE: 0.1232\n    Epoch 2/10 | Val CCC: 0.0660, MAE: 0.1246\n    Epoch 3/10 | Val CCC: 0.0432, MAE: 0.1231\n    Epoch 4/10 | Val CCC: 0.0217, MAE: 0.1229\n    Epoch 5/10 | Val CCC: 0.0373, MAE: 0.1220\n    Epoch 6/10 | Val CCC: 0.0259, MAE: 0.1222\n    Epoch 7/10 | Val CCC: 0.0410, MAE: 0.1218\n    Epoch 8/10 | Val CCC: 0.0417, MAE: 0.1217\n    Epoch 9/10 | Val CCC: 0.0370, MAE: 0.1216\n    Epoch 10/10 | Val CCC: 0.0460, MAE: 0.1217\n  Avg CCC: 0.0569, MAE: 0.1228\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0313, MAE: 0.1213\n    Epoch 2/10 | Val CCC: 0.0105, MAE: 0.1283\n    Epoch 3/10 | Val CCC: 0.0521, MAE: 0.1253\n    Epoch 4/10 | Val CCC: 0.0482, MAE: 0.1215\n    Epoch 5/10 | Val CCC: 0.0314, MAE: 0.1256\n    Epoch 6/10 | Val CCC: 0.0404, MAE: 0.1223\n    Epoch 7/10 | Val CCC: 0.0394, MAE: 0.1245\n    Epoch 8/10 | Val CCC: 0.0324, MAE: 0.1234\n    Epoch 9/10 | Val CCC: 0.0411, MAE: 0.1239\n    Epoch 10/10 | Val CCC: 0.0359, MAE: 0.1254\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0553, MAE: 0.1241\n    Epoch 2/10 | Val CCC: 0.0351, MAE: 0.1220\n    Epoch 3/10 | Val CCC: 0.0375, MAE: 0.1274\n    Epoch 4/10 | Val CCC: 0.0306, MAE: 0.1226\n    Epoch 5/10 | Val CCC: 0.0380, MAE: 0.1283\n    Epoch 6/10 | Val CCC: 0.0185, MAE: 0.1263\n    Epoch 7/10 | Val CCC: 0.0408, MAE: 0.1257\n    Epoch 8/10 | Val CCC: 0.0381, MAE: 0.1257\n    Epoch 9/10 | Val CCC: 0.0414, MAE: 0.1263\n    Epoch 10/10 | Val CCC: 0.0470, MAE: 0.1225\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0682, MAE: 0.1229\n    Epoch 2/10 | Val CCC: 0.0500, MAE: 0.1252\n    Epoch 3/10 | Val CCC: 0.0323, MAE: 0.1240\n    Epoch 4/10 | Val CCC: 0.0376, MAE: 0.1234\n    Epoch 5/10 | Val CCC: 0.0362, MAE: 0.1242\n    Epoch 6/10 | Val CCC: 0.0368, MAE: 0.1250\n    Epoch 7/10 | Val CCC: 0.0401, MAE: 0.1230\n    Epoch 8/10 | Val CCC: 0.0245, MAE: 0.1261\n    Epoch 9/10 | Val CCC: 0.0342, MAE: 0.1228\n    Epoch 10/10 | Val CCC: 0.0349, MAE: 0.1274\n  Avg CCC: 0.0585, MAE: 0.1241\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0459, MAE: 0.1353\n    Epoch 2/10 | Val CCC: 0.0382, MAE: 0.1440\n    Epoch 3/10 | Val CCC: 0.0308, MAE: 0.1405\n    Epoch 4/10 | Val CCC: 0.0338, MAE: 0.1477\n    Epoch 5/10 | Val CCC: 0.0312, MAE: 0.1417\n    Epoch 6/10 | Val CCC: 0.0320, MAE: 0.1365\n    Epoch 7/10 | Val CCC: 0.0371, MAE: 0.1349\n    Epoch 8/10 | Val CCC: 0.0440, MAE: 0.1313\n    Epoch 9/10 | Val CCC: 0.0486, MAE: 0.1252\n    Epoch 10/10 | Val CCC: 0.0361, MAE: 0.1324\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0366, MAE: 0.1403\n    Epoch 2/10 | Val CCC: 0.0306, MAE: 0.1337\n    Epoch 3/10 | Val CCC: 0.0269, MAE: 0.1555\n    Epoch 4/10 | Val CCC: 0.0285, MAE: 0.1522\n    Epoch 5/10 | Val CCC: 0.0243, MAE: 0.1571\n    Epoch 6/10 | Val CCC: 0.0329, MAE: 0.1335\n    Epoch 7/10 | Val CCC: 0.0352, MAE: 0.1410\n    Epoch 8/10 | Val CCC: 0.0357, MAE: 0.1429\n    Epoch 9/10 | Val CCC: 0.0356, MAE: 0.1413\n    Epoch 10/10 | Val CCC: 0.0368, MAE: 0.1297\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0565, MAE: 0.1480\n    Epoch 2/10 | Val CCC: 0.0505, MAE: 0.1261\n    Epoch 3/10 | Val CCC: 0.0308, MAE: 0.1391\n    Epoch 4/10 | Val CCC: 0.0279, MAE: 0.1428\n    Epoch 5/10 | Val CCC: 0.0446, MAE: 0.1343\n    Epoch 6/10 | Val CCC: 0.0322, MAE: 0.1320\n    Epoch 7/10 | Val CCC: 0.0392, MAE: 0.1340\n    Epoch 8/10 | Val CCC: 0.0342, MAE: 0.1355\n    Epoch 9/10 | Val CCC: 0.0355, MAE: 0.1358\n    Epoch 10/10 | Val CCC: 0.0372, MAE: 0.1293\n  Avg CCC: 0.0473, MAE: 0.1343\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0352, MAE: 0.1220\n    Epoch 2/10 | Val CCC: 0.0245, MAE: 0.1256\n    Epoch 3/10 | Val CCC: 0.0332, MAE: 0.1245\n    Epoch 4/10 | Val CCC: 0.0357, MAE: 0.1229\n    Epoch 5/10 | Val CCC: 0.0322, MAE: 0.1247\n    Epoch 6/10 | Val CCC: 0.0485, MAE: 0.1238\n    Epoch 7/10 | Val CCC: 0.0425, MAE: 0.1220\n    Epoch 8/10 | Val CCC: 0.0416, MAE: 0.1227\n    Epoch 9/10 | Val CCC: 0.0476, MAE: 0.1218\n    Epoch 10/10 | Val CCC: 0.0524, MAE: 0.1222\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0278, MAE: 0.1322\n    Epoch 2/10 | Val CCC: 0.0277, MAE: 0.1287\n    Epoch 3/10 | Val CCC: 0.0293, MAE: 0.1318\n    Epoch 4/10 | Val CCC: 0.0364, MAE: 0.1351\n    Epoch 5/10 | Val CCC: 0.0323, MAE: 0.1226\n    Epoch 6/10 | Val CCC: 0.0411, MAE: 0.1231\n    Epoch 7/10 | Val CCC: 0.0340, MAE: 0.1240\n    Epoch 8/10 | Val CCC: 0.0474, MAE: 0.1227\n    Epoch 9/10 | Val CCC: 0.0378, MAE: 0.1252\n    Epoch 10/10 | Val CCC: 0.0454, MAE: 0.1224\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0336, MAE: 0.1223\n    Epoch 2/10 | Val CCC: 0.0376, MAE: 0.1303\n    Epoch 3/10 | Val CCC: 0.0455, MAE: 0.1235\n    Epoch 4/10 | Val CCC: 0.0390, MAE: 0.1222\n    Epoch 5/10 | Val CCC: 0.0517, MAE: 0.1223\n    Epoch 6/10 | Val CCC: 0.0345, MAE: 0.1224\n    Epoch 7/10 | Val CCC: 0.0470, MAE: 0.1222\n    Epoch 8/10 | Val CCC: 0.0472, MAE: 0.1224\n    Epoch 9/10 | Val CCC: 0.0510, MAE: 0.1224\n    Epoch 10/10 | Val CCC: 0.0392, MAE: 0.1220\n  Avg CCC: 0.0505, MAE: 0.1224\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0269, MAE: 0.1553\n    Epoch 2/10 | Val CCC: 0.0374, MAE: 0.1409\n    Epoch 3/10 | Val CCC: 0.0278, MAE: 0.1347\n    Epoch 4/10 | Val CCC: 0.0338, MAE: 0.1260\n    Epoch 5/10 | Val CCC: 0.0295, MAE: 0.1218\n    Epoch 6/10 | Val CCC: 0.0468, MAE: 0.1215\n    Epoch 7/10 | Val CCC: 0.0543, MAE: 0.1218\n    Epoch 8/10 | Val CCC: 0.0502, MAE: 0.1216\n    Epoch 9/10 | Val CCC: 0.0413, MAE: 0.1214\n    Epoch 10/10 | Val CCC: 0.0464, MAE: 0.1217\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0220, MAE: 0.1262\n    Epoch 2/10 | Val CCC: 0.0300, MAE: 0.1226\n    Epoch 3/10 | Val CCC: 0.0355, MAE: 0.1274\n    Epoch 4/10 | Val CCC: 0.0351, MAE: 0.1222\n    Epoch 5/10 | Val CCC: 0.0341, MAE: 0.1221\n    Epoch 6/10 | Val CCC: 0.0275, MAE: 0.1221\n    Epoch 7/10 | Val CCC: 0.0309, MAE: 0.1223\n    Epoch 8/10 | Val CCC: 0.0402, MAE: 0.1221\n    Epoch 9/10 | Val CCC: 0.0277, MAE: 0.1221\n    Epoch 10/10 | Val CCC: 0.0374, MAE: 0.1220\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0266, MAE: 0.1251\n    Epoch 2/10 | Val CCC: 0.0161, MAE: 0.1337\n    Epoch 3/10 | Val CCC: 0.0249, MAE: 0.1271\n    Epoch 4/10 | Val CCC: 0.0252, MAE: 0.1257\n    Epoch 5/10 | Val CCC: 0.0386, MAE: 0.1301\n    Epoch 6/10 | Val CCC: 0.0394, MAE: 0.1223\n    Epoch 7/10 | Val CCC: 0.0315, MAE: 0.1223\n    Epoch 8/10 | Val CCC: 0.0292, MAE: 0.1221\n    Epoch 9/10 | Val CCC: 0.0411, MAE: 0.1219\n    Epoch 10/10 | Val CCC: 0.0203, MAE: 0.1225\n  Avg CCC: 0.0452, MAE: 0.1219\n\n>>> Best Config Selected: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001}\n\n>>> Final Training for NEUROTICISM (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0271\n  Epoch 2/10 - Train Loss: 0.0251\n  Epoch 3/10 - Train Loss: 0.0247\n  Epoch 4/10 - Train Loss: 0.0245\n  Epoch 5/10 - Train Loss: 0.0243\n  Epoch 6/10 - Train Loss: 0.0241\n  Epoch 7/10 - Train Loss: 0.0240\n  Epoch 8/10 - Train Loss: 0.0239\n  Epoch 9/10 - Train Loss: 0.0238\n  Epoch 10/10 - Train Loss: 0.0237\n\n==== NEUROTICISM Evaluation on Test Set ====\nTest CCC: 0.0550, Test MAE: 0.1220, Accuracy (±0.1): 47.64%\nSaving final model for neuroticism to best_audio_transformer_model_neuroticism.pth\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# **Text HC Traits**","metadata":{}},{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split, KFold\nimport torch.optim as optim\nfrom sklearn.preprocessing import StandardScaler\n\n# Load dataset\ndf = pd.read_csv('/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/text_hc_features.csv')\n\n# Drop unnecessary columns\ndrop_cols = [\"Filename\", \"Segment_ID\", \"interview\", \"Gender\", \"Ethnicity\", \"AgeGroup\"]\ndf.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True, errors='ignore')\n\n# Define label columns\nlabel_columns = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n\n# Separate features and labels\nX = df.drop(columns=label_columns)\ny = df[label_columns]\n\n# Fill missing values\nX = X.fillna(X.mean())\ny = y.fillna(y.mean())\n\n# Normalize features\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n# Convert to tensors\nX_tensor = torch.tensor(X.values, dtype=torch.float32)\ny_tensors = {trait: torch.tensor(y[trait].values, dtype=torch.float32) for trait in label_columns}\n\n# Dataset class\nclass TextDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\nimport torch\nimport torch.nn as nn\n\nclass SimpleTransformerRegressor(nn.Module):\n    \"\"\"\n    Simple Transformer Regressor using batch_first=True convention.\n    Takes tabular features, projects them, passes through a Transformer Encoder,\n    and predicts a single regression value.\n    \"\"\"\n    def __init__(self, input_dim, embed_dim=256, num_heads=4, num_layers=2, dropout=0.3, ff_dim_multiplier=4):\n        \"\"\"\n        Args:\n            input_dim (int): Number of input features.\n            embed_dim (int): Dimension for projecting features and for the Transformer. Must be divisible by num_heads.\n            num_heads (int): Number of attention heads in the Transformer.\n            num_layers (int): Number of layers in the Transformer Encoder.\n            dropout (float): Dropout rate.\n            ff_dim_multiplier (int): Multiplier for the feed-forward layer dimension within the Transformer.\n        \"\"\"\n        super(SimpleTransformerRegressor, self).__init__()\n\n        # Ensure embed_dim is divisible by num_heads\n        if embed_dim % num_heads != 0:\n            # Adjust embed_dim up to the nearest multiple of num_heads\n            original_embed_dim = embed_dim\n            embed_dim = (embed_dim // num_heads + 1) * num_heads\n            print(f\"Warning: embed_dim ({original_embed_dim}) not divisible by num_heads ({num_heads}).\")\n            print(f\"Adjusted embed_dim to {embed_dim}.\")\n\n        self.input_dim = input_dim\n        self.embed_dim = embed_dim\n\n        # Project input features to embedding dimension\n        self.project = nn.Linear(input_dim, embed_dim)\n\n        # Define the Transformer Encoder Layer with batch_first=True\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim,\n            nhead=num_heads,\n            dim_feedforward=embed_dim * ff_dim_multiplier, # Standard practice\n            dropout=dropout,\n            batch_first=True  # <<< Input tensor shape: (batch, seq_len, features)\n        )\n\n        # Stack the encoder layers\n        self.encoder = nn.TransformerEncoder(\n            encoder_layer=encoder_layer,\n            num_layers=num_layers\n        )\n\n        # Classifier head\n        self.classifier = nn.Sequential(\n            nn.LayerNorm(embed_dim),      # Add LayerNorm for stability before classifier\n            nn.Linear(embed_dim, 128),    # Linear layer 1\n            nn.ReLU(),                    # Activation\n            nn.Dropout(dropout),          # Dropout\n            nn.Linear(128, 1)             # Final output layer (regression target)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass.\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_dim).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size).\n        \"\"\"\n        # 1. Project features\n        # x shape: (batch_size, input_dim)\n        x = self.project(x)\n        # x shape: (batch_size, embed_dim)\n\n        # 2. Add sequence dimension for Transformer\n        # TransformerEncoderLayer with batch_first=True expects (batch, seq_len, features)\n        x = x.unsqueeze(1)\n        # x shape: (batch_size, seq_len=1, embed_dim)\n\n        # 3. Pass through Transformer Encoder\n        x = self.encoder(x)\n        # x shape: (batch_size, seq_len=1, embed_dim)\n\n        # 4. Remove sequence dimension\n        x = x.squeeze(1)\n        # x shape: (batch_size, embed_dim)\n\n        # 5. Pass through classifier\n        output = self.classifier(x)\n        # output shape: (batch_size, 1)\n\n        # 6. Squeeze final dimension for regression output\n        return output.squeeze(-1)\n        # final shape: (batch_size)\n\n# Metrics\n\ndef mean_absolute_error(preds, labels):\n    return torch.mean(torch.abs(preds - labels)).item()\n\ndef concordance_correlation_coefficient(preds, labels):\n    preds_mean = torch.mean(preds)\n    labels_mean = torch.mean(labels)\n    preds_var = torch.var(preds)\n    labels_var = torch.var(labels)\n    covariance = torch.mean((preds - preds_mean) * (labels - labels_mean))\n    ccc = (2 * covariance) / (preds_var + labels_var + (preds_mean - labels_mean) ** 2)\n    return ccc.item()\n\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    total_loss, total_mae, total_ccc = 0, 0, 0\n    with torch.no_grad():\n        for X_batch, y_batch in loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            preds = model(X_batch)\n            loss = criterion(preds, y_batch)\n            total_loss += loss.item()\n            total_mae += mean_absolute_error(preds, y_batch)\n            total_ccc += concordance_correlation_coefficient(preds, y_batch)\n    n_batches = len(loader)\n    return total_loss/n_batches, total_mae/n_batches, total_ccc/n_batches\n\ndef train_one_epoch(model, loader, optimizer, scheduler, criterion, device):\n    model.train()\n    total_loss = 0\n    for i, (X_batch, y_batch) in enumerate(loader):\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        preds = model(X_batch)\n        loss = criterion(preds, y_batch)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    scheduler.step()\n    return total_loss / len(loader)\n\n\ndef generate_random_configs(search_space, num_configs=10):\n    configs = []\n    for _ in range(num_configs):\n        config = {\n            \"embed_dim\": np.random.choice(search_space[\"embed_dim\"]),\n            \"num_heads\": np.random.choice(search_space[\"num_heads\"]),\n            \"num_layers\": np.random.choice(search_space[\"num_layers\"]),\n            \"dropout\": np.random.choice(search_space[\"dropout\"]),\n            \"lr\": np.random.choice(search_space[\"lr\"]),\n            \"batch_size\": np.random.choice(search_space[\"batch_size\"]),\n            \"weight_decay\": np.random.choice(search_space[\"weight_decay\"])\n        }\n        configs.append(config)\n    return configs\n\ndef cross_validate(config, X_tensor, y_tensor, num_folds=3, epochs=10):\n    print(f\"Evaluating Config: {config}\")\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n    fold_metrics = {\"val_ccc\": [], \"val_mae\": [], \"val_loss\": []}\n\n    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_tensor)):\n        print(f\"  Fold {fold+1}/{num_folds}\")\n        X_train_fold, y_train_fold = X_tensor[train_idx], y_tensor[train_idx]\n        X_val_fold, y_val_fold = X_tensor[val_idx], y_tensor[val_idx]\n\n        train_loader = DataLoader(TextDataset(X_train_fold, y_train_fold), batch_size=int(config[\"batch_size\"]), shuffle=True)\n        val_loader = DataLoader(TextDataset(X_val_fold, y_val_fold), batch_size=int(config[\"batch_size\"]), shuffle=False)\n\n        model = SimpleTransformerRegressor(\n            input_dim=X_tensor.shape[1],\n            embed_dim=config[\"embed_dim\"],\n            num_heads=config[\"num_heads\"],\n            num_layers=config[\"num_layers\"],\n            dropout=config[\"dropout\"]\n        ).to(device)\n\n        optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n        criterion = nn.MSELoss()\n\n        best_ccc = -1\n        for epoch in range(epochs):\n            print(f\"    Epoch {epoch+1}/{epochs}\", end=' | ')\n            train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, device)\n            val_loss, val_mae, val_ccc = evaluate(model, val_loader, criterion, device)\n            print(f\"Val CCC: {val_ccc:.4f}, MAE: {val_mae:.4f}\")\n            if val_ccc > best_ccc:\n                best_ccc = val_ccc\n                best_metrics = (val_loss, val_mae, val_ccc)\n\n        fold_metrics[\"val_loss\"].append(best_metrics[0])\n        fold_metrics[\"val_mae\"].append(best_metrics[1])\n        fold_metrics[\"val_ccc\"].append(best_metrics[2])\n\n    return {\n        \"ccc\": np.mean(fold_metrics[\"val_ccc\"]),\n        \"mae\": np.mean(fold_metrics[\"val_mae\"]),\n        \"loss\": np.mean(fold_metrics[\"val_loss\"])\n    }\n\n\ndef hyperparameter_tuning(X_tensor, y_tensor, num_configs=10):\n    search_space = {\n        \"embed_dim\": [128, 256, 512],\n        \"num_heads\": [2, 4, 8],\n        \"num_layers\": [2, 4],\n        \"dropout\": [0.1, 0.3, 0.5],\n        \"lr\": [1e-4, 3e-4, 1e-3],\n        \"batch_size\": [32, 64],\n        \"weight_decay\": [1e-5, 1e-4]\n    }\n    configs = generate_random_configs(search_space, num_configs)\n    best_config = None\n    best_ccc = -1\n\n    for i, config in enumerate(configs):\n        print(f\"\\n>>> Config {i+1}/{num_configs}\")\n        metrics = cross_validate(config, X_tensor, y_tensor)\n        print(f\"  Avg CCC: {metrics['ccc']:.4f}, MAE: {metrics['mae']:.4f}\")\n        if metrics[\"ccc\"] > best_ccc:\n            best_ccc = metrics[\"ccc\"]\n            best_config = config\n\n    print(f\"\\n>>> Best Config Selected: {best_config}\")\n    return best_config\n\n\ndef final_train_and_evaluate(best_config, X_train, y_train, X_val, y_val, X_test, y_test, trait_name, epochs=10):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    X_final_train = torch.cat([X_train, X_val], dim=0)\n    y_final_train = torch.cat([y_train, y_val], dim=0)\n\n    final_train_loader = DataLoader(TextDataset(X_final_train, y_final_train), batch_size=int(best_config[\"batch_size\"]), shuffle=True)\n    test_loader = DataLoader(TextDataset(X_test, y_test), batch_size=int(best_config[\"batch_size\"]), shuffle=False)\n\n    model = SimpleTransformerRegressor(\n        input_dim=X_train.shape[1],\n        embed_dim=best_config[\"embed_dim\"],\n        num_heads=best_config[\"num_heads\"],\n        num_layers=best_config[\"num_layers\"],\n        dropout=best_config[\"dropout\"]\n    ).to(device)\n\n    optimizer = optim.AdamW(model.parameters(), lr=best_config[\"lr\"], weight_decay=best_config[\"weight_decay\"])\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n    criterion = nn.MSELoss()\n\n    print(f\"\\n>>> Final Training for {trait_name.upper()} ({epochs} epochs)\")\n    for epoch in range(epochs):\n        train_loss = train_one_epoch(model, final_train_loader, optimizer, scheduler, criterion, device)\n        print(f\"  Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}\")\n\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for X_batch, y_batch in test_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            preds = model(X_batch)\n            all_preds.append(preds)\n            all_labels.append(y_batch)\n\n    all_preds = torch.cat(all_preds, dim=0)\n    all_labels = torch.cat(all_labels, dim=0)\n\n    final_mae = mean_absolute_error(all_preds, all_labels)\n    final_ccc = concordance_correlation_coefficient(all_preds, all_labels)\n    tolerance = 0.1\n    correct = torch.abs(all_preds - all_labels) < tolerance\n    final_accuracy = correct.float().mean().item()\n\n    print(f\"\\n==== {trait_name.upper()} Evaluation on Test Set ====\")\n    print(f\"Test CCC: {final_ccc:.4f}, Test MAE: {final_mae:.4f}, Accuracy (±{tolerance}): {final_accuracy*100:.2f}%\")\n    torch.save(model.state_dict(), f\"best_text_transformer_model_{trait_name}.pth\")\n    model_save_path = f\"best_text_transformer_model_{trait_name}.pth\"\n    print(f\"Saving final model for {trait_name} to {model_save_path}\")\n    torch.save({\n        'epoch': epochs,\n        'model_state_dict': model.state_dict(), # <<< Weights nested here\n        'optimizer_state_dict': optimizer.state_dict(),\n        'best_config': best_config,           # <<< Config needed\n        'scaler_mean': scaler.mean_,         # <<< Scaler mean needed\n        'scaler_scale': scaler.scale_,         # <<< Scaler scale needed\n        'test_metrics': {'ccc': final_ccc, 'mae': final_mae, f'acc_{tolerance}': final_accuracy}\n    }, model_save_path)\n\n# Train model per trait\nfor trait in label_columns:\n    print(f\"\\n--- Training for Trait: {trait} ---\")\n    y_trait = y_tensors[trait]\n    train_idx, temp_idx = train_test_split(range(len(X)), test_size=0.3, random_state=42)\n    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n\n    X_train, y_train = X_tensor[train_idx], y_trait[train_idx]\n    X_val, y_val = X_tensor[val_idx], y_trait[val_idx]\n    X_test, y_test = X_tensor[test_idx], y_trait[test_idx]\n\n    best_config = hyperparameter_tuning(X_tensor, y_trait, num_configs=10)\n    final_train_and_evaluate(best_config, X_train, y_train, X_val, y_val, X_test, y_test, trait_name=trait)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T14:19:16.402472Z","iopub.execute_input":"2025-05-05T14:19:16.402864Z","iopub.status.idle":"2025-05-05T14:56:34.868328Z","shell.execute_reply.started":"2025-05-05T14:19:16.402841Z","shell.execute_reply":"2025-05-05T14:56:34.867300Z"}},"outputs":[{"name":"stdout","text":"\n--- Training for Trait: openness ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0602, MAE: 0.1159\n    Epoch 2/10 | Val CCC: 0.1260, MAE: 0.1161\n    Epoch 3/10 | Val CCC: 0.1145, MAE: 0.1165\n    Epoch 4/10 | Val CCC: 0.0791, MAE: 0.1437\n    Epoch 5/10 | Val CCC: 0.0848, MAE: 0.1444\n    Epoch 6/10 | Val CCC: 0.0980, MAE: 0.1349\n    Epoch 7/10 | Val CCC: 0.0958, MAE: 0.1364\n    Epoch 8/10 | Val CCC: 0.1027, MAE: 0.1413\n    Epoch 9/10 | Val CCC: 0.1190, MAE: 0.1294\n    Epoch 10/10 | Val CCC: 0.1190, MAE: 0.1321\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1257, MAE: 0.1246\n    Epoch 2/10 | Val CCC: 0.1305, MAE: 0.1153\n    Epoch 3/10 | Val CCC: 0.0945, MAE: 0.1275\n    Epoch 4/10 | Val CCC: 0.0793, MAE: 0.1460\n    Epoch 5/10 | Val CCC: 0.0942, MAE: 0.1401\n    Epoch 6/10 | Val CCC: 0.0881, MAE: 0.1370\n    Epoch 7/10 | Val CCC: 0.0788, MAE: 0.1555\n    Epoch 8/10 | Val CCC: 0.0952, MAE: 0.1419\n    Epoch 9/10 | Val CCC: 0.0990, MAE: 0.1368\n    Epoch 10/10 | Val CCC: 0.0949, MAE: 0.1442\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0995, MAE: 0.1203\n    Epoch 2/10 | Val CCC: 0.0981, MAE: 0.1196\n    Epoch 3/10 | Val CCC: 0.0982, MAE: 0.1304\n    Epoch 4/10 | Val CCC: 0.0995, MAE: 0.1233\n    Epoch 5/10 | Val CCC: 0.0824, MAE: 0.1374\n    Epoch 6/10 | Val CCC: 0.0868, MAE: 0.1372\n    Epoch 7/10 | Val CCC: 0.1122, MAE: 0.1231\n    Epoch 8/10 | Val CCC: 0.1197, MAE: 0.1305\n    Epoch 9/10 | Val CCC: 0.1018, MAE: 0.1387\n    Epoch 10/10 | Val CCC: 0.0881, MAE: 0.1415\n  Avg CCC: 0.1254, MAE: 0.1206\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0429, MAE: 0.1193\n    Epoch 2/10 | Val CCC: 0.0886, MAE: 0.1139\n    Epoch 3/10 | Val CCC: 0.0957, MAE: 0.1138\n    Epoch 4/10 | Val CCC: 0.1404, MAE: 0.1158\n    Epoch 5/10 | Val CCC: 0.1055, MAE: 0.1184\n    Epoch 6/10 | Val CCC: 0.0910, MAE: 0.1149\n    Epoch 7/10 | Val CCC: 0.1194, MAE: 0.1159\n    Epoch 8/10 | Val CCC: 0.1227, MAE: 0.1230\n    Epoch 9/10 | Val CCC: 0.1231, MAE: 0.1165\n    Epoch 10/10 | Val CCC: 0.0769, MAE: 0.1208\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0839, MAE: 0.1160\n    Epoch 2/10 | Val CCC: 0.0632, MAE: 0.1137\n    Epoch 3/10 | Val CCC: 0.1310, MAE: 0.1178\n    Epoch 4/10 | Val CCC: 0.1005, MAE: 0.1179\n    Epoch 5/10 | Val CCC: 0.0942, MAE: 0.1147\n    Epoch 6/10 | Val CCC: 0.0843, MAE: 0.1142\n    Epoch 7/10 | Val CCC: 0.0699, MAE: 0.1142\n    Epoch 8/10 | Val CCC: 0.0862, MAE: 0.1174\n    Epoch 9/10 | Val CCC: 0.0778, MAE: 0.1141\n    Epoch 10/10 | Val CCC: 0.0417, MAE: 0.1190\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0843, MAE: 0.1145\n    Epoch 2/10 | Val CCC: 0.0523, MAE: 0.1144\n    Epoch 3/10 | Val CCC: 0.0632, MAE: 0.1476\n    Epoch 4/10 | Val CCC: 0.0875, MAE: 0.1166\n    Epoch 5/10 | Val CCC: 0.0621, MAE: 0.1231\n    Epoch 6/10 | Val CCC: 0.0911, MAE: 0.1159\n    Epoch 7/10 | Val CCC: 0.0848, MAE: 0.1140\n    Epoch 8/10 | Val CCC: 0.1093, MAE: 0.1180\n    Epoch 9/10 | Val CCC: 0.0952, MAE: 0.1186\n    Epoch 10/10 | Val CCC: 0.0881, MAE: 0.1146\n  Avg CCC: 0.1269, MAE: 0.1172\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0858, MAE: 0.1188\n    Epoch 2/10 | Val CCC: 0.1315, MAE: 0.1160\n    Epoch 3/10 | Val CCC: 0.1015, MAE: 0.1199\n    Epoch 4/10 | Val CCC: 0.0822, MAE: 0.1421\n    Epoch 5/10 | Val CCC: 0.0899, MAE: 0.1303\n    Epoch 6/10 | Val CCC: 0.1102, MAE: 0.1312\n    Epoch 7/10 | Val CCC: 0.1059, MAE: 0.1251\n    Epoch 8/10 | Val CCC: 0.0829, MAE: 0.1416\n    Epoch 9/10 | Val CCC: 0.0990, MAE: 0.1305\n    Epoch 10/10 | Val CCC: 0.0767, MAE: 0.1503\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1210, MAE: 0.1200\n    Epoch 2/10 | Val CCC: 0.0826, MAE: 0.1158\n    Epoch 3/10 | Val CCC: 0.0980, MAE: 0.1136\n    Epoch 4/10 | Val CCC: 0.1020, MAE: 0.1204\n    Epoch 5/10 | Val CCC: 0.0974, MAE: 0.1162\n    Epoch 6/10 | Val CCC: 0.1010, MAE: 0.1236\n    Epoch 7/10 | Val CCC: 0.0842, MAE: 0.1299\n    Epoch 8/10 | Val CCC: 0.0946, MAE: 0.1307\n    Epoch 9/10 | Val CCC: 0.0809, MAE: 0.1294\n    Epoch 10/10 | Val CCC: 0.0983, MAE: 0.1191\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1305, MAE: 0.1188\n    Epoch 2/10 | Val CCC: 0.1241, MAE: 0.1255\n    Epoch 3/10 | Val CCC: 0.0845, MAE: 0.1309\n    Epoch 4/10 | Val CCC: 0.0927, MAE: 0.1305\n    Epoch 5/10 | Val CCC: 0.0902, MAE: 0.1300\n    Epoch 6/10 | Val CCC: 0.0870, MAE: 0.1543\n    Epoch 7/10 | Val CCC: 0.0922, MAE: 0.1273\n    Epoch 8/10 | Val CCC: 0.0867, MAE: 0.1379\n    Epoch 9/10 | Val CCC: 0.0620, MAE: 0.1628\n    Epoch 10/10 | Val CCC: 0.0739, MAE: 0.1482\n  Avg CCC: 0.1276, MAE: 0.1183\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1011, MAE: 0.1145\n    Epoch 2/10 | Val CCC: 0.0876, MAE: 0.1164\n    Epoch 3/10 | Val CCC: 0.0700, MAE: 0.1224\n    Epoch 4/10 | Val CCC: 0.0853, MAE: 0.1165\n    Epoch 5/10 | Val CCC: 0.0778, MAE: 0.1357\n    Epoch 6/10 | Val CCC: 0.1136, MAE: 0.1146\n    Epoch 7/10 | Val CCC: 0.1107, MAE: 0.1158\n    Epoch 8/10 | Val CCC: 0.1017, MAE: 0.1149\n    Epoch 9/10 | Val CCC: 0.1176, MAE: 0.1158\n    Epoch 10/10 | Val CCC: 0.1024, MAE: 0.1148\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0736, MAE: 0.1162\n    Epoch 2/10 | Val CCC: 0.0625, MAE: 0.1281\n    Epoch 3/10 | Val CCC: 0.0712, MAE: 0.1135\n    Epoch 4/10 | Val CCC: 0.0974, MAE: 0.1135\n    Epoch 5/10 | Val CCC: 0.0898, MAE: 0.1140\n    Epoch 6/10 | Val CCC: 0.0742, MAE: 0.1140\n    Epoch 7/10 | Val CCC: 0.0842, MAE: 0.1138\n    Epoch 8/10 | Val CCC: 0.0987, MAE: 0.1138\n    Epoch 9/10 | Val CCC: 0.0741, MAE: 0.1138\n    Epoch 10/10 | Val CCC: 0.0816, MAE: 0.1156\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0747, MAE: 0.1228\n    Epoch 2/10 | Val CCC: 0.0711, MAE: 0.1248\n    Epoch 3/10 | Val CCC: 0.0782, MAE: 0.1183\n    Epoch 4/10 | Val CCC: 0.0931, MAE: 0.1167\n    Epoch 5/10 | Val CCC: 0.0706, MAE: 0.1167\n    Epoch 6/10 | Val CCC: 0.0949, MAE: 0.1212\n    Epoch 7/10 | Val CCC: 0.1113, MAE: 0.1147\n    Epoch 8/10 | Val CCC: 0.0839, MAE: 0.1165\n    Epoch 9/10 | Val CCC: 0.1158, MAE: 0.1150\n    Epoch 10/10 | Val CCC: 0.1007, MAE: 0.1146\n  Avg CCC: 0.1107, MAE: 0.1149\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0880, MAE: 0.1175\n    Epoch 2/10 | Val CCC: 0.1139, MAE: 0.1173\n    Epoch 3/10 | Val CCC: 0.0697, MAE: 0.1151\n    Epoch 4/10 | Val CCC: 0.1206, MAE: 0.1165\n    Epoch 5/10 | Val CCC: 0.1400, MAE: 0.1152\n    Epoch 6/10 | Val CCC: 0.1006, MAE: 0.1157\n    Epoch 7/10 | Val CCC: 0.1220, MAE: 0.1156\n    Epoch 8/10 | Val CCC: 0.0959, MAE: 0.1169\n    Epoch 9/10 | Val CCC: 0.1031, MAE: 0.1204\n    Epoch 10/10 | Val CCC: 0.0971, MAE: 0.1150\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0743, MAE: 0.1160\n    Epoch 2/10 | Val CCC: 0.0835, MAE: 0.1159\n    Epoch 3/10 | Val CCC: 0.0777, MAE: 0.1143\n    Epoch 4/10 | Val CCC: 0.0644, MAE: 0.1146\n    Epoch 5/10 | Val CCC: 0.0893, MAE: 0.1156\n    Epoch 6/10 | Val CCC: 0.0862, MAE: 0.1139\n    Epoch 7/10 | Val CCC: 0.0954, MAE: 0.1137\n    Epoch 8/10 | Val CCC: 0.0883, MAE: 0.1145\n    Epoch 9/10 | Val CCC: 0.1055, MAE: 0.1136\n    Epoch 10/10 | Val CCC: 0.0885, MAE: 0.1139\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0779, MAE: 0.1161\n    Epoch 2/10 | Val CCC: 0.1008, MAE: 0.1154\n    Epoch 3/10 | Val CCC: 0.0950, MAE: 0.1162\n    Epoch 4/10 | Val CCC: 0.0924, MAE: 0.1161\n    Epoch 5/10 | Val CCC: 0.1031, MAE: 0.1144\n    Epoch 6/10 | Val CCC: 0.0959, MAE: 0.1190\n    Epoch 7/10 | Val CCC: 0.0968, MAE: 0.1149\n    Epoch 8/10 | Val CCC: 0.1024, MAE: 0.1149\n    Epoch 9/10 | Val CCC: 0.0831, MAE: 0.1169\n    Epoch 10/10 | Val CCC: 0.1199, MAE: 0.1160\n  Avg CCC: 0.1218, MAE: 0.1149\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0729, MAE: 0.1145\n    Epoch 2/10 | Val CCC: 0.0940, MAE: 0.1162\n    Epoch 3/10 | Val CCC: 0.0900, MAE: 0.1271\n    Epoch 4/10 | Val CCC: 0.0920, MAE: 0.1148\n    Epoch 5/10 | Val CCC: 0.1187, MAE: 0.1144\n    Epoch 6/10 | Val CCC: 0.1057, MAE: 0.1141\n    Epoch 7/10 | Val CCC: 0.0438, MAE: 0.1162\n    Epoch 8/10 | Val CCC: 0.0672, MAE: 0.1216\n    Epoch 9/10 | Val CCC: 0.0748, MAE: 0.1149\n    Epoch 10/10 | Val CCC: 0.0953, MAE: 0.1264\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0002, MAE: 0.1167\n    Epoch 2/10 | Val CCC: 0.0006, MAE: 0.1177\n    Epoch 3/10 | Val CCC: 0.0022, MAE: 0.1171\n    Epoch 4/10 | Val CCC: 0.0237, MAE: 0.1157\n    Epoch 5/10 | Val CCC: 0.0447, MAE: 0.1148\n    Epoch 6/10 | Val CCC: 0.0415, MAE: 0.1146\n    Epoch 7/10 | Val CCC: 0.0101, MAE: 0.1173\n    Epoch 8/10 | Val CCC: 0.0595, MAE: 0.1197\n    Epoch 9/10 | Val CCC: 0.0747, MAE: 0.1146\n    Epoch 10/10 | Val CCC: 0.0453, MAE: 0.1200\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0523, MAE: 0.1511\n    Epoch 2/10 | Val CCC: 0.0677, MAE: 0.1191\n    Epoch 3/10 | Val CCC: 0.0484, MAE: 0.1283\n    Epoch 4/10 | Val CCC: 0.0721, MAE: 0.1153\n    Epoch 5/10 | Val CCC: 0.0643, MAE: 0.1162\n    Epoch 6/10 | Val CCC: 0.0629, MAE: 0.1146\n    Epoch 7/10 | Val CCC: 0.0917, MAE: 0.1150\n    Epoch 8/10 | Val CCC: 0.0534, MAE: 0.1177\n    Epoch 9/10 | Val CCC: 0.0512, MAE: 0.1158\n    Epoch 10/10 | Val CCC: 0.0953, MAE: 0.1154\n  Avg CCC: 0.0962, MAE: 0.1148\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0773, MAE: 0.1186\n    Epoch 2/10 | Val CCC: 0.1130, MAE: 0.1162\n    Epoch 3/10 | Val CCC: 0.0883, MAE: 0.1164\n    Epoch 4/10 | Val CCC: 0.1058, MAE: 0.1174\n    Epoch 5/10 | Val CCC: 0.1073, MAE: 0.1150\n    Epoch 6/10 | Val CCC: 0.1039, MAE: 0.1164\n    Epoch 7/10 | Val CCC: 0.1176, MAE: 0.1149\n    Epoch 8/10 | Val CCC: 0.1131, MAE: 0.1180\n    Epoch 9/10 | Val CCC: 0.1146, MAE: 0.1171\n    Epoch 10/10 | Val CCC: 0.1047, MAE: 0.1174\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0686, MAE: 0.1188\n    Epoch 2/10 | Val CCC: 0.0967, MAE: 0.1224\n    Epoch 3/10 | Val CCC: 0.1050, MAE: 0.1144\n    Epoch 4/10 | Val CCC: 0.0733, MAE: 0.1151\n    Epoch 5/10 | Val CCC: 0.0684, MAE: 0.1148\n    Epoch 6/10 | Val CCC: 0.1017, MAE: 0.1150\n    Epoch 7/10 | Val CCC: 0.0760, MAE: 0.1155\n    Epoch 8/10 | Val CCC: 0.0957, MAE: 0.1161\n    Epoch 9/10 | Val CCC: 0.0688, MAE: 0.1155\n    Epoch 10/10 | Val CCC: 0.0932, MAE: 0.1151\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1418, MAE: 0.1223\n    Epoch 2/10 | Val CCC: 0.1175, MAE: 0.1202\n    Epoch 3/10 | Val CCC: 0.0923, MAE: 0.1154\n    Epoch 4/10 | Val CCC: 0.0892, MAE: 0.1155\n    Epoch 5/10 | Val CCC: 0.0835, MAE: 0.1166\n    Epoch 6/10 | Val CCC: 0.0786, MAE: 0.1146\n    Epoch 7/10 | Val CCC: 0.0989, MAE: 0.1156\n    Epoch 8/10 | Val CCC: 0.1043, MAE: 0.1156\n    Epoch 9/10 | Val CCC: 0.0947, MAE: 0.1166\n    Epoch 10/10 | Val CCC: 0.1241, MAE: 0.1163\n  Avg CCC: 0.1215, MAE: 0.1172\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1088, MAE: 0.1194\n    Epoch 2/10 | Val CCC: 0.0976, MAE: 0.1154\n    Epoch 3/10 | Val CCC: 0.1025, MAE: 0.1158\n    Epoch 4/10 | Val CCC: 0.1129, MAE: 0.1157\n    Epoch 5/10 | Val CCC: 0.1198, MAE: 0.1141\n    Epoch 6/10 | Val CCC: 0.1276, MAE: 0.1152\n    Epoch 7/10 | Val CCC: 0.1027, MAE: 0.1295\n    Epoch 8/10 | Val CCC: 0.1183, MAE: 0.1200\n    Epoch 9/10 | Val CCC: 0.0987, MAE: 0.1369\n    Epoch 10/10 | Val CCC: 0.1159, MAE: 0.1231\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0817, MAE: 0.1188\n    Epoch 2/10 | Val CCC: 0.0785, MAE: 0.1158\n    Epoch 3/10 | Val CCC: 0.0898, MAE: 0.1166\n    Epoch 4/10 | Val CCC: 0.1114, MAE: 0.1162\n    Epoch 5/10 | Val CCC: 0.0997, MAE: 0.1199\n    Epoch 6/10 | Val CCC: 0.1131, MAE: 0.1190\n    Epoch 7/10 | Val CCC: 0.1169, MAE: 0.1225\n    Epoch 8/10 | Val CCC: 0.1026, MAE: 0.1212\n    Epoch 9/10 | Val CCC: 0.1071, MAE: 0.1311\n    Epoch 10/10 | Val CCC: 0.0980, MAE: 0.1339\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1395, MAE: 0.1196\n    Epoch 2/10 | Val CCC: 0.1099, MAE: 0.1156\n    Epoch 3/10 | Val CCC: 0.1149, MAE: 0.1168\n    Epoch 4/10 | Val CCC: 0.1045, MAE: 0.1196\n    Epoch 5/10 | Val CCC: 0.1094, MAE: 0.1196\n    Epoch 6/10 | Val CCC: 0.1189, MAE: 0.1284\n    Epoch 7/10 | Val CCC: 0.1188, MAE: 0.1201\n    Epoch 8/10 | Val CCC: 0.1008, MAE: 0.1290\n    Epoch 9/10 | Val CCC: 0.1172, MAE: 0.1199\n    Epoch 10/10 | Val CCC: 0.1112, MAE: 0.1246\n  Avg CCC: 0.1280, MAE: 0.1191\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0029, MAE: 0.1254\n    Epoch 2/10 | Val CCC: 0.0029, MAE: 0.1588\n    Epoch 3/10 | Val CCC: 0.0039, MAE: 0.1994\n    Epoch 4/10 | Val CCC: 0.0947, MAE: 0.1243\n    Epoch 5/10 | Val CCC: 0.0629, MAE: 0.1575\n    Epoch 6/10 | Val CCC: 0.0770, MAE: 0.1320\n    Epoch 7/10 | Val CCC: 0.0981, MAE: 0.1212\n    Epoch 8/10 | Val CCC: 0.1065, MAE: 0.1157\n    Epoch 9/10 | Val CCC: 0.1261, MAE: 0.1226\n    Epoch 10/10 | Val CCC: 0.0936, MAE: 0.1241\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0013, MAE: 0.1441\n    Epoch 2/10 | Val CCC: 0.0018, MAE: 0.1589\n    Epoch 3/10 | Val CCC: 0.0039, MAE: 0.1908\n    Epoch 4/10 | Val CCC: 0.0853, MAE: 0.1312\n    Epoch 5/10 | Val CCC: 0.0609, MAE: 0.1249\n    Epoch 6/10 | Val CCC: 0.0654, MAE: 0.1444\n    Epoch 7/10 | Val CCC: 0.0784, MAE: 0.1145\n    Epoch 8/10 | Val CCC: 0.0538, MAE: 0.1250\n    Epoch 9/10 | Val CCC: 0.0953, MAE: 0.1288\n    Epoch 10/10 | Val CCC: 0.0913, MAE: 0.1159\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0042, MAE: 0.1387\n    Epoch 2/10 | Val CCC: 0.0044, MAE: 0.1433\n    Epoch 3/10 | Val CCC: 0.0400, MAE: 0.2013\n    Epoch 4/10 | Val CCC: 0.0679, MAE: 0.1556\n    Epoch 5/10 | Val CCC: 0.0820, MAE: 0.1188\n    Epoch 6/10 | Val CCC: 0.0691, MAE: 0.1472\n    Epoch 7/10 | Val CCC: 0.0671, MAE: 0.1260\n    Epoch 8/10 | Val CCC: 0.0828, MAE: 0.1368\n    Epoch 9/10 | Val CCC: 0.0989, MAE: 0.1342\n    Epoch 10/10 | Val CCC: 0.0867, MAE: 0.1192\n  Avg CCC: 0.1068, MAE: 0.1285\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0696, MAE: 0.1157\n    Epoch 2/10 | Val CCC: 0.0802, MAE: 0.1142\n    Epoch 3/10 | Val CCC: 0.0908, MAE: 0.1158\n    Epoch 4/10 | Val CCC: 0.0958, MAE: 0.1143\n    Epoch 5/10 | Val CCC: 0.1023, MAE: 0.1140\n    Epoch 6/10 | Val CCC: 0.0754, MAE: 0.1189\n    Epoch 7/10 | Val CCC: 0.0761, MAE: 0.1142\n    Epoch 8/10 | Val CCC: 0.1048, MAE: 0.1135\n    Epoch 9/10 | Val CCC: 0.1206, MAE: 0.1151\n    Epoch 10/10 | Val CCC: 0.0964, MAE: 0.1180\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0866, MAE: 0.1151\n    Epoch 2/10 | Val CCC: 0.0810, MAE: 0.1171\n    Epoch 3/10 | Val CCC: 0.0847, MAE: 0.1156\n    Epoch 4/10 | Val CCC: 0.1080, MAE: 0.1144\n    Epoch 5/10 | Val CCC: 0.0889, MAE: 0.1136\n    Epoch 6/10 | Val CCC: 0.0794, MAE: 0.1168\n    Epoch 7/10 | Val CCC: 0.0869, MAE: 0.1142\n    Epoch 8/10 | Val CCC: 0.0864, MAE: 0.1142\n    Epoch 9/10 | Val CCC: 0.0880, MAE: 0.1137\n    Epoch 10/10 | Val CCC: 0.0837, MAE: 0.1171\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0963, MAE: 0.1152\n    Epoch 2/10 | Val CCC: 0.0762, MAE: 0.1165\n    Epoch 3/10 | Val CCC: 0.0819, MAE: 0.1256\n    Epoch 4/10 | Val CCC: 0.0960, MAE: 0.1144\n    Epoch 5/10 | Val CCC: 0.0896, MAE: 0.1140\n    Epoch 6/10 | Val CCC: 0.0975, MAE: 0.1194\n    Epoch 7/10 | Val CCC: 0.1116, MAE: 0.1159\n    Epoch 8/10 | Val CCC: 0.0788, MAE: 0.1175\n    Epoch 9/10 | Val CCC: 0.1121, MAE: 0.1159\n    Epoch 10/10 | Val CCC: 0.1051, MAE: 0.1173\n  Avg CCC: 0.1136, MAE: 0.1151\n\n>>> Best Config Selected: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n\n>>> Final Training for OPENNESS (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0563\n  Epoch 2/10 - Train Loss: 0.0341\n  Epoch 3/10 - Train Loss: 0.0318\n  Epoch 4/10 - Train Loss: 0.0300\n  Epoch 5/10 - Train Loss: 0.0290\n  Epoch 6/10 - Train Loss: 0.0288\n  Epoch 7/10 - Train Loss: 0.0281\n  Epoch 8/10 - Train Loss: 0.0277\n  Epoch 9/10 - Train Loss: 0.0272\n  Epoch 10/10 - Train Loss: 0.0264\n\n==== OPENNESS Evaluation on Test Set ====\nTest CCC: 0.1066, Test MAE: 0.1474, Accuracy (±0.1): 41.53%\nSaving final model for openness to best_text_transformer_model_openness.pth\n\n--- Training for Trait: conscientiousness ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0728, MAE: 0.1312\n    Epoch 2/10 | Val CCC: 0.0638, MAE: 0.1317\n    Epoch 3/10 | Val CCC: 0.0501, MAE: 0.1384\n    Epoch 4/10 | Val CCC: 0.0582, MAE: 0.1303\n    Epoch 5/10 | Val CCC: 0.0489, MAE: 0.1343\n    Epoch 6/10 | Val CCC: 0.0554, MAE: 0.1243\n    Epoch 7/10 | Val CCC: 0.0501, MAE: 0.1276\n    Epoch 8/10 | Val CCC: 0.0616, MAE: 0.1235\n    Epoch 9/10 | Val CCC: 0.0605, MAE: 0.1232\n    Epoch 10/10 | Val CCC: 0.0790, MAE: 0.1210\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0608, MAE: 0.1356\n    Epoch 2/10 | Val CCC: 0.0832, MAE: 0.1272\n    Epoch 3/10 | Val CCC: 0.0850, MAE: 0.1266\n    Epoch 4/10 | Val CCC: 0.0896, MAE: 0.1265\n    Epoch 5/10 | Val CCC: 0.0920, MAE: 0.1248\n    Epoch 6/10 | Val CCC: 0.0849, MAE: 0.1244\n    Epoch 7/10 | Val CCC: 0.0927, MAE: 0.1251\n    Epoch 8/10 | Val CCC: 0.1033, MAE: 0.1237\n    Epoch 9/10 | Val CCC: 0.1110, MAE: 0.1232\n    Epoch 10/10 | Val CCC: 0.1128, MAE: 0.1229\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0539, MAE: 0.1339\n    Epoch 2/10 | Val CCC: 0.0521, MAE: 0.1285\n    Epoch 3/10 | Val CCC: 0.0468, MAE: 0.1282\n    Epoch 4/10 | Val CCC: 0.0401, MAE: 0.1278\n    Epoch 5/10 | Val CCC: 0.0548, MAE: 0.1262\n    Epoch 6/10 | Val CCC: 0.0522, MAE: 0.1251\n    Epoch 7/10 | Val CCC: 0.0637, MAE: 0.1233\n    Epoch 8/10 | Val CCC: 0.0723, MAE: 0.1228\n    Epoch 9/10 | Val CCC: 0.0745, MAE: 0.1232\n    Epoch 10/10 | Val CCC: 0.0878, MAE: 0.1217\n  Avg CCC: 0.0932, MAE: 0.1219\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1723, MAE: 0.1218\n    Epoch 2/10 | Val CCC: 0.1501, MAE: 0.1205\n    Epoch 3/10 | Val CCC: 0.1515, MAE: 0.1198\n    Epoch 4/10 | Val CCC: 0.1460, MAE: 0.1256\n    Epoch 5/10 | Val CCC: 0.1483, MAE: 0.1206\n    Epoch 6/10 | Val CCC: 0.1699, MAE: 0.1225\n    Epoch 7/10 | Val CCC: 0.1473, MAE: 0.1212\n    Epoch 8/10 | Val CCC: 0.1618, MAE: 0.1213\n    Epoch 9/10 | Val CCC: 0.1400, MAE: 0.1258\n    Epoch 10/10 | Val CCC: 0.1851, MAE: 0.1218\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1102, MAE: 0.1259\n    Epoch 2/10 | Val CCC: 0.0910, MAE: 0.1260\n    Epoch 3/10 | Val CCC: 0.1328, MAE: 0.1236\n    Epoch 4/10 | Val CCC: 0.1230, MAE: 0.1255\n    Epoch 5/10 | Val CCC: 0.1357, MAE: 0.1233\n    Epoch 6/10 | Val CCC: 0.1242, MAE: 0.1234\n    Epoch 7/10 | Val CCC: 0.1301, MAE: 0.1230\n    Epoch 8/10 | Val CCC: 0.1284, MAE: 0.1239\n    Epoch 9/10 | Val CCC: 0.1298, MAE: 0.1233\n    Epoch 10/10 | Val CCC: 0.1403, MAE: 0.1238\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1384, MAE: 0.1280\n    Epoch 2/10 | Val CCC: 0.1460, MAE: 0.1231\n    Epoch 3/10 | Val CCC: 0.1341, MAE: 0.1226\n    Epoch 4/10 | Val CCC: 0.1352, MAE: 0.1216\n    Epoch 5/10 | Val CCC: 0.1509, MAE: 0.1218\n    Epoch 6/10 | Val CCC: 0.1405, MAE: 0.1222\n    Epoch 7/10 | Val CCC: 0.1447, MAE: 0.1226\n    Epoch 8/10 | Val CCC: 0.1265, MAE: 0.1250\n    Epoch 9/10 | Val CCC: 0.1387, MAE: 0.1216\n    Epoch 10/10 | Val CCC: 0.1232, MAE: 0.1261\n  Avg CCC: 0.1588, MAE: 0.1225\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1419, MAE: 0.1293\n    Epoch 2/10 | Val CCC: 0.1391, MAE: 0.1198\n    Epoch 3/10 | Val CCC: 0.1374, MAE: 0.1251\n    Epoch 4/10 | Val CCC: 0.1500, MAE: 0.1241\n    Epoch 5/10 | Val CCC: 0.1254, MAE: 0.1300\n    Epoch 6/10 | Val CCC: 0.1545, MAE: 0.1245\n    Epoch 7/10 | Val CCC: 0.1746, MAE: 0.1222\n    Epoch 8/10 | Val CCC: 0.1450, MAE: 0.1274\n    Epoch 9/10 | Val CCC: 0.1564, MAE: 0.1207\n    Epoch 10/10 | Val CCC: 0.1816, MAE: 0.1213\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1282, MAE: 0.1238\n    Epoch 2/10 | Val CCC: 0.1253, MAE: 0.1240\n    Epoch 3/10 | Val CCC: 0.1149, MAE: 0.1385\n    Epoch 4/10 | Val CCC: 0.1079, MAE: 0.1278\n    Epoch 5/10 | Val CCC: 0.1207, MAE: 0.1289\n    Epoch 6/10 | Val CCC: 0.1266, MAE: 0.1277\n    Epoch 7/10 | Val CCC: 0.1688, MAE: 0.1276\n    Epoch 8/10 | Val CCC: 0.1516, MAE: 0.1239\n    Epoch 9/10 | Val CCC: 0.1288, MAE: 0.1310\n    Epoch 10/10 | Val CCC: 0.1598, MAE: 0.1245\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1154, MAE: 0.1256\n    Epoch 2/10 | Val CCC: 0.1513, MAE: 0.1248\n    Epoch 3/10 | Val CCC: 0.1391, MAE: 0.1353\n    Epoch 4/10 | Val CCC: 0.1110, MAE: 0.1349\n    Epoch 5/10 | Val CCC: 0.1382, MAE: 0.1225\n    Epoch 6/10 | Val CCC: 0.1234, MAE: 0.1277\n    Epoch 7/10 | Val CCC: 0.1245, MAE: 0.1312\n    Epoch 8/10 | Val CCC: 0.1563, MAE: 0.1257\n    Epoch 9/10 | Val CCC: 0.1454, MAE: 0.1281\n    Epoch 10/10 | Val CCC: 0.1462, MAE: 0.1204\n  Avg CCC: 0.1689, MAE: 0.1249\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1635, MAE: 0.1261\n    Epoch 2/10 | Val CCC: 0.1033, MAE: 0.1236\n    Epoch 3/10 | Val CCC: 0.1278, MAE: 0.1192\n    Epoch 4/10 | Val CCC: 0.1362, MAE: 0.1216\n    Epoch 5/10 | Val CCC: 0.1525, MAE: 0.1185\n    Epoch 6/10 | Val CCC: 0.1230, MAE: 0.1203\n    Epoch 7/10 | Val CCC: 0.0962, MAE: 0.1331\n    Epoch 8/10 | Val CCC: 0.1787, MAE: 0.1190\n    Epoch 9/10 | Val CCC: 0.1351, MAE: 0.1197\n    Epoch 10/10 | Val CCC: 0.1775, MAE: 0.1193\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1214, MAE: 0.1254\n    Epoch 2/10 | Val CCC: 0.1234, MAE: 0.1262\n    Epoch 3/10 | Val CCC: 0.1049, MAE: 0.1230\n    Epoch 4/10 | Val CCC: 0.1365, MAE: 0.1233\n    Epoch 5/10 | Val CCC: 0.1159, MAE: 0.1239\n    Epoch 6/10 | Val CCC: 0.1237, MAE: 0.1276\n    Epoch 7/10 | Val CCC: 0.0961, MAE: 0.1254\n    Epoch 8/10 | Val CCC: 0.0999, MAE: 0.1251\n    Epoch 9/10 | Val CCC: 0.1364, MAE: 0.1230\n    Epoch 10/10 | Val CCC: 0.1317, MAE: 0.1231\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1108, MAE: 0.1222\n    Epoch 2/10 | Val CCC: 0.1336, MAE: 0.1214\n    Epoch 3/10 | Val CCC: 0.1137, MAE: 0.1219\n    Epoch 4/10 | Val CCC: 0.1093, MAE: 0.1214\n    Epoch 5/10 | Val CCC: 0.1320, MAE: 0.1218\n    Epoch 6/10 | Val CCC: 0.1591, MAE: 0.1205\n    Epoch 7/10 | Val CCC: 0.1569, MAE: 0.1240\n    Epoch 8/10 | Val CCC: 0.1423, MAE: 0.1250\n    Epoch 9/10 | Val CCC: 0.1378, MAE: 0.1217\n    Epoch 10/10 | Val CCC: 0.1063, MAE: 0.1250\n  Avg CCC: 0.1581, MAE: 0.1209\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0115, MAE: 0.1318\n    Epoch 2/10 | Val CCC: 0.0160, MAE: 0.1538\n    Epoch 3/10 | Val CCC: 0.0499, MAE: 0.1470\n    Epoch 4/10 | Val CCC: 0.1043, MAE: 0.1977\n    Epoch 5/10 | Val CCC: 0.1263, MAE: 0.1602\n    Epoch 6/10 | Val CCC: 0.0862, MAE: 0.2243\n    Epoch 7/10 | Val CCC: 0.1275, MAE: 0.1551\n    Epoch 8/10 | Val CCC: 0.1066, MAE: 0.1374\n    Epoch 9/10 | Val CCC: 0.0953, MAE: 0.1407\n    Epoch 10/10 | Val CCC: 0.1131, MAE: 0.1333\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0022, MAE: 0.1419\n    Epoch 2/10 | Val CCC: 0.0013, MAE: 0.1931\n    Epoch 3/10 | Val CCC: 0.0013, MAE: 0.2050\n    Epoch 4/10 | Val CCC: 0.0014, MAE: 0.1726\n    Epoch 5/10 | Val CCC: 0.0019, MAE: 0.1886\n    Epoch 6/10 | Val CCC: 0.0057, MAE: 0.1394\n    Epoch 7/10 | Val CCC: 0.0294, MAE: 0.1470\n    Epoch 8/10 | Val CCC: 0.0848, MAE: 0.1740\n    Epoch 9/10 | Val CCC: 0.1001, MAE: 0.1608\n    Epoch 10/10 | Val CCC: 0.1052, MAE: 0.1392\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0041, MAE: 0.1412\n    Epoch 2/10 | Val CCC: 0.0022, MAE: 0.1857\n    Epoch 3/10 | Val CCC: 0.0044, MAE: 0.1741\n    Epoch 4/10 | Val CCC: 0.0135, MAE: 0.1495\n    Epoch 5/10 | Val CCC: 0.0946, MAE: 0.1758\n    Epoch 6/10 | Val CCC: 0.1030, MAE: 0.1569\n    Epoch 7/10 | Val CCC: 0.0505, MAE: 0.2268\n    Epoch 8/10 | Val CCC: 0.0700, MAE: 0.1778\n    Epoch 9/10 | Val CCC: 0.0910, MAE: 0.1682\n    Epoch 10/10 | Val CCC: 0.0950, MAE: 0.1522\n  Avg CCC: 0.1119, MAE: 0.1504\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1320, MAE: 0.1224\n    Epoch 2/10 | Val CCC: 0.1381, MAE: 0.1238\n    Epoch 3/10 | Val CCC: 0.1429, MAE: 0.1382\n    Epoch 4/10 | Val CCC: 0.1573, MAE: 0.1197\n    Epoch 5/10 | Val CCC: 0.1113, MAE: 0.1223\n    Epoch 6/10 | Val CCC: 0.1470, MAE: 0.1246\n    Epoch 7/10 | Val CCC: 0.1520, MAE: 0.1278\n    Epoch 8/10 | Val CCC: 0.1459, MAE: 0.1190\n    Epoch 9/10 | Val CCC: 0.1330, MAE: 0.1215\n    Epoch 10/10 | Val CCC: 0.1467, MAE: 0.1203\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1503, MAE: 0.1248\n    Epoch 2/10 | Val CCC: 0.1343, MAE: 0.1276\n    Epoch 3/10 | Val CCC: 0.0720, MAE: 0.1251\n    Epoch 4/10 | Val CCC: 0.0812, MAE: 0.1238\n    Epoch 5/10 | Val CCC: 0.1077, MAE: 0.1245\n    Epoch 6/10 | Val CCC: 0.1265, MAE: 0.1402\n    Epoch 7/10 | Val CCC: 0.1281, MAE: 0.1258\n    Epoch 8/10 | Val CCC: 0.1591, MAE: 0.1288\n    Epoch 9/10 | Val CCC: 0.1567, MAE: 0.1241\n    Epoch 10/10 | Val CCC: 0.1081, MAE: 0.1242\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1363, MAE: 0.1250\n    Epoch 2/10 | Val CCC: 0.1523, MAE: 0.1319\n    Epoch 3/10 | Val CCC: 0.1063, MAE: 0.1317\n    Epoch 4/10 | Val CCC: 0.1334, MAE: 0.1225\n    Epoch 5/10 | Val CCC: 0.1239, MAE: 0.1228\n    Epoch 6/10 | Val CCC: 0.1251, MAE: 0.1228\n    Epoch 7/10 | Val CCC: 0.1197, MAE: 0.1269\n    Epoch 8/10 | Val CCC: 0.1159, MAE: 0.1222\n    Epoch 9/10 | Val CCC: 0.1377, MAE: 0.1216\n    Epoch 10/10 | Val CCC: 0.1381, MAE: 0.1211\n  Avg CCC: 0.1562, MAE: 0.1268\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1459, MAE: 0.1237\n    Epoch 2/10 | Val CCC: 0.1457, MAE: 0.1216\n    Epoch 3/10 | Val CCC: 0.1575, MAE: 0.1199\n    Epoch 4/10 | Val CCC: 0.1577, MAE: 0.1196\n    Epoch 5/10 | Val CCC: 0.1457, MAE: 0.1196\n    Epoch 6/10 | Val CCC: 0.1420, MAE: 0.1199\n    Epoch 7/10 | Val CCC: 0.1491, MAE: 0.1200\n    Epoch 8/10 | Val CCC: 0.1441, MAE: 0.1190\n    Epoch 9/10 | Val CCC: 0.1313, MAE: 0.1204\n    Epoch 10/10 | Val CCC: 0.1311, MAE: 0.1194\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1354, MAE: 0.1268\n    Epoch 2/10 | Val CCC: 0.1490, MAE: 0.1265\n    Epoch 3/10 | Val CCC: 0.1392, MAE: 0.1258\n    Epoch 4/10 | Val CCC: 0.1246, MAE: 0.1245\n    Epoch 5/10 | Val CCC: 0.1335, MAE: 0.1228\n    Epoch 6/10 | Val CCC: 0.1402, MAE: 0.1258\n    Epoch 7/10 | Val CCC: 0.1399, MAE: 0.1225\n    Epoch 8/10 | Val CCC: 0.1366, MAE: 0.1239\n    Epoch 9/10 | Val CCC: 0.1173, MAE: 0.1228\n    Epoch 10/10 | Val CCC: 0.1252, MAE: 0.1234\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1036, MAE: 0.1268\n    Epoch 2/10 | Val CCC: 0.1424, MAE: 0.1239\n    Epoch 3/10 | Val CCC: 0.1227, MAE: 0.1251\n    Epoch 4/10 | Val CCC: 0.1221, MAE: 0.1219\n    Epoch 5/10 | Val CCC: 0.1252, MAE: 0.1228\n    Epoch 6/10 | Val CCC: 0.1300, MAE: 0.1220\n    Epoch 7/10 | Val CCC: 0.1458, MAE: 0.1213\n    Epoch 8/10 | Val CCC: 0.1202, MAE: 0.1218\n    Epoch 9/10 | Val CCC: 0.1448, MAE: 0.1222\n    Epoch 10/10 | Val CCC: 0.1285, MAE: 0.1216\n  Avg CCC: 0.1508, MAE: 0.1224\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1224, MAE: 0.1575\n    Epoch 2/10 | Val CCC: 0.1031, MAE: 0.1498\n    Epoch 3/10 | Val CCC: 0.1063, MAE: 0.1521\n    Epoch 4/10 | Val CCC: 0.0827, MAE: 0.1346\n    Epoch 5/10 | Val CCC: 0.1625, MAE: 0.1239\n    Epoch 6/10 | Val CCC: 0.1080, MAE: 0.1411\n    Epoch 7/10 | Val CCC: 0.1020, MAE: 0.1248\n    Epoch 8/10 | Val CCC: 0.1793, MAE: 0.1247\n    Epoch 9/10 | Val CCC: 0.1465, MAE: 0.1200\n    Epoch 10/10 | Val CCC: 0.1174, MAE: 0.1235\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0906, MAE: 0.1314\n    Epoch 2/10 | Val CCC: 0.1541, MAE: 0.1238\n    Epoch 3/10 | Val CCC: 0.1199, MAE: 0.1244\n    Epoch 4/10 | Val CCC: 0.1082, MAE: 0.1476\n    Epoch 5/10 | Val CCC: 0.0514, MAE: 0.1381\n    Epoch 6/10 | Val CCC: 0.0826, MAE: 0.1660\n    Epoch 7/10 | Val CCC: 0.0989, MAE: 0.1395\n    Epoch 8/10 | Val CCC: 0.1254, MAE: 0.1250\n    Epoch 9/10 | Val CCC: 0.1398, MAE: 0.1249\n    Epoch 10/10 | Val CCC: 0.1316, MAE: 0.1247\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1063, MAE: 0.1213\n    Epoch 2/10 | Val CCC: 0.1040, MAE: 0.1386\n    Epoch 3/10 | Val CCC: 0.0747, MAE: 0.1588\n    Epoch 4/10 | Val CCC: 0.0934, MAE: 0.1439\n    Epoch 5/10 | Val CCC: 0.1088, MAE: 0.1276\n    Epoch 6/10 | Val CCC: 0.0951, MAE: 0.1366\n    Epoch 7/10 | Val CCC: 0.0793, MAE: 0.1308\n    Epoch 8/10 | Val CCC: 0.0968, MAE: 0.1278\n    Epoch 9/10 | Val CCC: 0.1321, MAE: 0.1234\n    Epoch 10/10 | Val CCC: 0.1231, MAE: 0.1236\n  Avg CCC: 0.1552, MAE: 0.1239\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1244, MAE: 0.1238\n    Epoch 2/10 | Val CCC: 0.1154, MAE: 0.1222\n    Epoch 3/10 | Val CCC: 0.1406, MAE: 0.1206\n    Epoch 4/10 | Val CCC: 0.1622, MAE: 0.1189\n    Epoch 5/10 | Val CCC: 0.1590, MAE: 0.1196\n    Epoch 6/10 | Val CCC: 0.1651, MAE: 0.1193\n    Epoch 7/10 | Val CCC: 0.1408, MAE: 0.1228\n    Epoch 8/10 | Val CCC: 0.1522, MAE: 0.1206\n    Epoch 9/10 | Val CCC: 0.1483, MAE: 0.1197\n    Epoch 10/10 | Val CCC: 0.1594, MAE: 0.1199\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1194, MAE: 0.1263\n    Epoch 2/10 | Val CCC: 0.1093, MAE: 0.1245\n    Epoch 3/10 | Val CCC: 0.1152, MAE: 0.1253\n    Epoch 4/10 | Val CCC: 0.1206, MAE: 0.1234\n    Epoch 5/10 | Val CCC: 0.1339, MAE: 0.1237\n    Epoch 6/10 | Val CCC: 0.1459, MAE: 0.1236\n    Epoch 7/10 | Val CCC: 0.1206, MAE: 0.1234\n    Epoch 8/10 | Val CCC: 0.1334, MAE: 0.1230\n    Epoch 9/10 | Val CCC: 0.1377, MAE: 0.1231\n    Epoch 10/10 | Val CCC: 0.1493, MAE: 0.1236\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1394, MAE: 0.1241\n    Epoch 2/10 | Val CCC: 0.1235, MAE: 0.1221\n    Epoch 3/10 | Val CCC: 0.1244, MAE: 0.1213\n    Epoch 4/10 | Val CCC: 0.1232, MAE: 0.1216\n    Epoch 5/10 | Val CCC: 0.1231, MAE: 0.1213\n    Epoch 6/10 | Val CCC: 0.1182, MAE: 0.1212\n    Epoch 7/10 | Val CCC: 0.1431, MAE: 0.1205\n    Epoch 8/10 | Val CCC: 0.1459, MAE: 0.1204\n    Epoch 9/10 | Val CCC: 0.1594, MAE: 0.1203\n    Epoch 10/10 | Val CCC: 0.1307, MAE: 0.1206\n  Avg CCC: 0.1580, MAE: 0.1211\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0020, MAE: 0.1458\n    Epoch 2/10 | Val CCC: 0.0004, MAE: 0.1803\n    Epoch 3/10 | Val CCC: 0.0002, MAE: 0.1254\n    Epoch 4/10 | Val CCC: 0.0006, MAE: 0.1377\n    Epoch 5/10 | Val CCC: 0.0006, MAE: 0.1443\n    Epoch 6/10 | Val CCC: 0.0010, MAE: 0.1392\n    Epoch 7/10 | Val CCC: 0.0014, MAE: 0.1347\n    Epoch 8/10 | Val CCC: 0.0024, MAE: 0.1256\n    Epoch 9/10 | Val CCC: 0.0046, MAE: 0.1324\n    Epoch 10/10 | Val CCC: 0.0234, MAE: 0.1370\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0044, MAE: 0.1804\n    Epoch 2/10 | Val CCC: 0.0054, MAE: 0.1325\n    Epoch 3/10 | Val CCC: 0.0123, MAE: 0.1393\n    Epoch 4/10 | Val CCC: 0.1197, MAE: 0.1456\n    Epoch 5/10 | Val CCC: 0.1130, MAE: 0.1480\n    Epoch 6/10 | Val CCC: 0.1061, MAE: 0.1347\n    Epoch 7/10 | Val CCC: 0.1080, MAE: 0.1416\n    Epoch 8/10 | Val CCC: 0.0872, MAE: 0.1581\n    Epoch 9/10 | Val CCC: 0.1401, MAE: 0.1354\n    Epoch 10/10 | Val CCC: 0.1250, MAE: 0.1417\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0009, MAE: 0.1720\n    Epoch 2/10 | Val CCC: 0.0010, MAE: 0.1505\n    Epoch 3/10 | Val CCC: 0.0031, MAE: 0.1496\n    Epoch 4/10 | Val CCC: 0.0039, MAE: 0.1474\n    Epoch 5/10 | Val CCC: 0.0109, MAE: 0.1557\n    Epoch 6/10 | Val CCC: 0.1116, MAE: 0.1495\n    Epoch 7/10 | Val CCC: 0.1397, MAE: 0.1452\n    Epoch 8/10 | Val CCC: 0.1062, MAE: 0.1352\n    Epoch 9/10 | Val CCC: 0.0953, MAE: 0.1432\n    Epoch 10/10 | Val CCC: 0.1532, MAE: 0.1319\n  Avg CCC: 0.1056, MAE: 0.1348\n\n>>> Best Config Selected: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 0.0001}\n\n>>> Final Training for CONSCIENTIOUSNESS (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0398\n  Epoch 2/10 - Train Loss: 0.0290\n  Epoch 3/10 - Train Loss: 0.0288\n  Epoch 4/10 - Train Loss: 0.0279\n  Epoch 5/10 - Train Loss: 0.0277\n  Epoch 6/10 - Train Loss: 0.0275\n  Epoch 7/10 - Train Loss: 0.0272\n  Epoch 8/10 - Train Loss: 0.0268\n  Epoch 9/10 - Train Loss: 0.0262\n  Epoch 10/10 - Train Loss: 0.0264\n\n==== CONSCIENTIOUSNESS Evaluation on Test Set ====\nTest CCC: 0.1262, Test MAE: 0.1376, Accuracy (±0.1): 42.13%\nSaving final model for conscientiousness to best_text_transformer_model_conscientiousness.pth\n\n--- Training for Trait: extraversion ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0946, MAE: 0.1243\n    Epoch 2/10 | Val CCC: 0.1118, MAE: 0.1197\n    Epoch 3/10 | Val CCC: 0.1330, MAE: 0.1216\n    Epoch 4/10 | Val CCC: 0.1018, MAE: 0.1216\n    Epoch 5/10 | Val CCC: 0.1276, MAE: 0.1299\n    Epoch 6/10 | Val CCC: 0.1688, MAE: 0.1198\n    Epoch 7/10 | Val CCC: 0.1428, MAE: 0.1187\n    Epoch 8/10 | Val CCC: 0.1303, MAE: 0.1203\n    Epoch 9/10 | Val CCC: 0.1244, MAE: 0.1226\n    Epoch 10/10 | Val CCC: 0.1250, MAE: 0.1257\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0269, MAE: 0.1280\n    Epoch 2/10 | Val CCC: 0.0914, MAE: 0.1282\n    Epoch 3/10 | Val CCC: 0.1098, MAE: 0.1212\n    Epoch 4/10 | Val CCC: 0.1091, MAE: 0.1290\n    Epoch 5/10 | Val CCC: 0.0899, MAE: 0.1217\n    Epoch 6/10 | Val CCC: 0.0984, MAE: 0.1279\n    Epoch 7/10 | Val CCC: 0.1291, MAE: 0.1214\n    Epoch 8/10 | Val CCC: 0.1173, MAE: 0.1212\n    Epoch 9/10 | Val CCC: 0.1272, MAE: 0.1248\n    Epoch 10/10 | Val CCC: 0.0965, MAE: 0.1300\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0674, MAE: 0.1258\n    Epoch 2/10 | Val CCC: 0.0926, MAE: 0.1286\n    Epoch 3/10 | Val CCC: 0.0786, MAE: 0.1291\n    Epoch 4/10 | Val CCC: 0.1217, MAE: 0.1226\n    Epoch 5/10 | Val CCC: 0.1241, MAE: 0.1244\n    Epoch 6/10 | Val CCC: 0.1176, MAE: 0.1254\n    Epoch 7/10 | Val CCC: 0.1235, MAE: 0.1190\n    Epoch 8/10 | Val CCC: 0.0985, MAE: 0.1226\n    Epoch 9/10 | Val CCC: 0.1053, MAE: 0.1204\n    Epoch 10/10 | Val CCC: 0.1208, MAE: 0.1203\n  Avg CCC: 0.1407, MAE: 0.1219\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0847, MAE: 0.1201\n    Epoch 2/10 | Val CCC: 0.0958, MAE: 0.1196\n    Epoch 3/10 | Val CCC: 0.0916, MAE: 0.1200\n    Epoch 4/10 | Val CCC: 0.0940, MAE: 0.1207\n    Epoch 5/10 | Val CCC: 0.1158, MAE: 0.1324\n    Epoch 6/10 | Val CCC: 0.0624, MAE: 0.1208\n    Epoch 7/10 | Val CCC: 0.1047, MAE: 0.1246\n    Epoch 8/10 | Val CCC: 0.1302, MAE: 0.1292\n    Epoch 9/10 | Val CCC: 0.1197, MAE: 0.1203\n    Epoch 10/10 | Val CCC: 0.1404, MAE: 0.1240\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1171, MAE: 0.1287\n    Epoch 2/10 | Val CCC: 0.1060, MAE: 0.1201\n    Epoch 3/10 | Val CCC: 0.0779, MAE: 0.1209\n    Epoch 4/10 | Val CCC: 0.0654, MAE: 0.1199\n    Epoch 5/10 | Val CCC: 0.0708, MAE: 0.1220\n    Epoch 6/10 | Val CCC: 0.0923, MAE: 0.1207\n    Epoch 7/10 | Val CCC: 0.0632, MAE: 0.1304\n    Epoch 8/10 | Val CCC: 0.0896, MAE: 0.1211\n    Epoch 9/10 | Val CCC: 0.1073, MAE: 0.1241\n    Epoch 10/10 | Val CCC: 0.1302, MAE: 0.1267\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0523, MAE: 0.1915\n    Epoch 2/10 | Val CCC: 0.0404, MAE: 0.1301\n    Epoch 3/10 | Val CCC: 0.0722, MAE: 0.1268\n    Epoch 4/10 | Val CCC: 0.0883, MAE: 0.1269\n    Epoch 5/10 | Val CCC: 0.0834, MAE: 0.1211\n    Epoch 6/10 | Val CCC: 0.0858, MAE: 0.1220\n    Epoch 7/10 | Val CCC: 0.0368, MAE: 0.1225\n    Epoch 8/10 | Val CCC: 0.0734, MAE: 0.1191\n    Epoch 9/10 | Val CCC: 0.0515, MAE: 0.1221\n    Epoch 10/10 | Val CCC: 0.1299, MAE: 0.1272\n  Avg CCC: 0.1335, MAE: 0.1260\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0886, MAE: 0.1253\n    Epoch 2/10 | Val CCC: 0.1015, MAE: 0.1205\n    Epoch 3/10 | Val CCC: 0.1149, MAE: 0.1238\n    Epoch 4/10 | Val CCC: 0.1056, MAE: 0.1194\n    Epoch 5/10 | Val CCC: 0.1157, MAE: 0.1219\n    Epoch 6/10 | Val CCC: 0.1123, MAE: 0.1186\n    Epoch 7/10 | Val CCC: 0.1119, MAE: 0.1189\n    Epoch 8/10 | Val CCC: 0.1203, MAE: 0.1195\n    Epoch 9/10 | Val CCC: 0.0913, MAE: 0.1249\n    Epoch 10/10 | Val CCC: 0.1016, MAE: 0.1195\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0765, MAE: 0.1245\n    Epoch 2/10 | Val CCC: 0.1058, MAE: 0.1214\n    Epoch 3/10 | Val CCC: 0.0743, MAE: 0.1205\n    Epoch 4/10 | Val CCC: 0.1332, MAE: 0.1214\n    Epoch 5/10 | Val CCC: 0.1020, MAE: 0.1198\n    Epoch 6/10 | Val CCC: 0.1099, MAE: 0.1207\n    Epoch 7/10 | Val CCC: 0.0978, MAE: 0.1199\n    Epoch 8/10 | Val CCC: 0.1203, MAE: 0.1203\n    Epoch 9/10 | Val CCC: 0.0885, MAE: 0.1195\n    Epoch 10/10 | Val CCC: 0.1173, MAE: 0.1203\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1056, MAE: 0.1262\n    Epoch 2/10 | Val CCC: 0.0744, MAE: 0.1228\n    Epoch 3/10 | Val CCC: 0.0971, MAE: 0.1195\n    Epoch 4/10 | Val CCC: 0.1163, MAE: 0.1198\n    Epoch 5/10 | Val CCC: 0.1013, MAE: 0.1192\n    Epoch 6/10 | Val CCC: 0.1192, MAE: 0.1187\n    Epoch 7/10 | Val CCC: 0.1231, MAE: 0.1193\n    Epoch 8/10 | Val CCC: 0.1023, MAE: 0.1239\n    Epoch 9/10 | Val CCC: 0.1317, MAE: 0.1204\n    Epoch 10/10 | Val CCC: 0.1191, MAE: 0.1211\n  Avg CCC: 0.1284, MAE: 0.1204\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0983, MAE: 0.1276\n    Epoch 2/10 | Val CCC: 0.1036, MAE: 0.1247\n    Epoch 3/10 | Val CCC: 0.1072, MAE: 0.1237\n    Epoch 4/10 | Val CCC: 0.0961, MAE: 0.1233\n    Epoch 5/10 | Val CCC: 0.1188, MAE: 0.1219\n    Epoch 6/10 | Val CCC: 0.1074, MAE: 0.1220\n    Epoch 7/10 | Val CCC: 0.1133, MAE: 0.1209\n    Epoch 8/10 | Val CCC: 0.1175, MAE: 0.1208\n    Epoch 9/10 | Val CCC: 0.1141, MAE: 0.1207\n    Epoch 10/10 | Val CCC: 0.0889, MAE: 0.1215\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0984, MAE: 0.1261\n    Epoch 2/10 | Val CCC: 0.1027, MAE: 0.1237\n    Epoch 3/10 | Val CCC: 0.0780, MAE: 0.1230\n    Epoch 4/10 | Val CCC: 0.0971, MAE: 0.1233\n    Epoch 5/10 | Val CCC: 0.1170, MAE: 0.1224\n    Epoch 6/10 | Val CCC: 0.1017, MAE: 0.1214\n    Epoch 7/10 | Val CCC: 0.0853, MAE: 0.1219\n    Epoch 8/10 | Val CCC: 0.0991, MAE: 0.1211\n    Epoch 9/10 | Val CCC: 0.1013, MAE: 0.1222\n    Epoch 10/10 | Val CCC: 0.0816, MAE: 0.1218\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1068, MAE: 0.1292\n    Epoch 2/10 | Val CCC: 0.1123, MAE: 0.1255\n    Epoch 3/10 | Val CCC: 0.1146, MAE: 0.1231\n    Epoch 4/10 | Val CCC: 0.1121, MAE: 0.1227\n    Epoch 5/10 | Val CCC: 0.1377, MAE: 0.1199\n    Epoch 6/10 | Val CCC: 0.1052, MAE: 0.1205\n    Epoch 7/10 | Val CCC: 0.1222, MAE: 0.1211\n    Epoch 8/10 | Val CCC: 0.1172, MAE: 0.1204\n    Epoch 9/10 | Val CCC: 0.1186, MAE: 0.1196\n    Epoch 10/10 | Val CCC: 0.1337, MAE: 0.1197\n  Avg CCC: 0.1245, MAE: 0.1214\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0906, MAE: 0.1254\n    Epoch 2/10 | Val CCC: 0.0700, MAE: 0.1264\n    Epoch 3/10 | Val CCC: 0.0717, MAE: 0.1203\n    Epoch 4/10 | Val CCC: 0.0680, MAE: 0.1201\n    Epoch 5/10 | Val CCC: 0.0805, MAE: 0.1195\n    Epoch 6/10 | Val CCC: 0.0758, MAE: 0.1220\n    Epoch 7/10 | Val CCC: 0.0912, MAE: 0.1204\n    Epoch 8/10 | Val CCC: 0.0956, MAE: 0.1224\n    Epoch 9/10 | Val CCC: 0.1110, MAE: 0.1190\n    Epoch 10/10 | Val CCC: 0.1231, MAE: 0.1213\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0801, MAE: 0.1242\n    Epoch 2/10 | Val CCC: 0.0572, MAE: 0.1355\n    Epoch 3/10 | Val CCC: 0.0447, MAE: 0.1342\n    Epoch 4/10 | Val CCC: 0.0464, MAE: 0.1266\n    Epoch 5/10 | Val CCC: 0.0589, MAE: 0.1205\n    Epoch 6/10 | Val CCC: 0.0666, MAE: 0.1216\n    Epoch 7/10 | Val CCC: 0.0743, MAE: 0.1196\n    Epoch 8/10 | Val CCC: 0.0800, MAE: 0.1195\n    Epoch 9/10 | Val CCC: 0.0882, MAE: 0.1195\n    Epoch 10/10 | Val CCC: 0.1036, MAE: 0.1201\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1178, MAE: 0.1263\n    Epoch 2/10 | Val CCC: 0.0888, MAE: 0.1224\n    Epoch 3/10 | Val CCC: 0.0818, MAE: 0.1215\n    Epoch 4/10 | Val CCC: 0.0860, MAE: 0.1196\n    Epoch 5/10 | Val CCC: 0.0884, MAE: 0.1192\n    Epoch 6/10 | Val CCC: 0.0910, MAE: 0.1193\n    Epoch 7/10 | Val CCC: 0.0778, MAE: 0.1193\n    Epoch 8/10 | Val CCC: 0.0870, MAE: 0.1195\n    Epoch 9/10 | Val CCC: 0.1093, MAE: 0.1197\n    Epoch 10/10 | Val CCC: 0.1089, MAE: 0.1197\n  Avg CCC: 0.1148, MAE: 0.1225\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0994, MAE: 0.1345\n    Epoch 2/10 | Val CCC: 0.0763, MAE: 0.1202\n    Epoch 3/10 | Val CCC: 0.0963, MAE: 0.1330\n    Epoch 4/10 | Val CCC: 0.1152, MAE: 0.1191\n    Epoch 5/10 | Val CCC: 0.1172, MAE: 0.1190\n    Epoch 6/10 | Val CCC: 0.1349, MAE: 0.1214\n    Epoch 7/10 | Val CCC: 0.1009, MAE: 0.1266\n    Epoch 8/10 | Val CCC: 0.1373, MAE: 0.1228\n    Epoch 9/10 | Val CCC: 0.1188, MAE: 0.1223\n    Epoch 10/10 | Val CCC: 0.1179, MAE: 0.1217\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1127, MAE: 0.1213\n    Epoch 2/10 | Val CCC: 0.0618, MAE: 0.1214\n    Epoch 3/10 | Val CCC: 0.0838, MAE: 0.1192\n    Epoch 4/10 | Val CCC: 0.1130, MAE: 0.1194\n    Epoch 5/10 | Val CCC: 0.1006, MAE: 0.1238\n    Epoch 6/10 | Val CCC: 0.1168, MAE: 0.1245\n    Epoch 7/10 | Val CCC: 0.1065, MAE: 0.1215\n    Epoch 8/10 | Val CCC: 0.1143, MAE: 0.1193\n    Epoch 9/10 | Val CCC: 0.1248, MAE: 0.1200\n    Epoch 10/10 | Val CCC: 0.1049, MAE: 0.1227\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1385, MAE: 0.1211\n    Epoch 2/10 | Val CCC: 0.1340, MAE: 0.1192\n    Epoch 3/10 | Val CCC: 0.0973, MAE: 0.1248\n    Epoch 4/10 | Val CCC: 0.1224, MAE: 0.1197\n    Epoch 5/10 | Val CCC: 0.1115, MAE: 0.1226\n    Epoch 6/10 | Val CCC: 0.1066, MAE: 0.1279\n    Epoch 7/10 | Val CCC: 0.1139, MAE: 0.1200\n    Epoch 8/10 | Val CCC: 0.1053, MAE: 0.1222\n    Epoch 9/10 | Val CCC: 0.0989, MAE: 0.1199\n    Epoch 10/10 | Val CCC: 0.0972, MAE: 0.1246\n  Avg CCC: 0.1335, MAE: 0.1213\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1197, MAE: 0.1216\n    Epoch 2/10 | Val CCC: 0.1145, MAE: 0.1285\n    Epoch 3/10 | Val CCC: 0.0629, MAE: 0.1327\n    Epoch 4/10 | Val CCC: 0.0885, MAE: 0.1460\n    Epoch 5/10 | Val CCC: 0.1053, MAE: 0.1371\n    Epoch 6/10 | Val CCC: 0.1309, MAE: 0.1395\n    Epoch 7/10 | Val CCC: 0.1358, MAE: 0.1222\n    Epoch 8/10 | Val CCC: 0.1399, MAE: 0.1231\n    Epoch 9/10 | Val CCC: 0.1279, MAE: 0.1324\n    Epoch 10/10 | Val CCC: 0.1302, MAE: 0.1261\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1002, MAE: 0.1238\n    Epoch 2/10 | Val CCC: 0.0997, MAE: 0.1361\n    Epoch 3/10 | Val CCC: 0.1196, MAE: 0.1232\n    Epoch 4/10 | Val CCC: 0.1277, MAE: 0.1237\n    Epoch 5/10 | Val CCC: 0.0982, MAE: 0.1274\n    Epoch 6/10 | Val CCC: 0.1317, MAE: 0.1203\n    Epoch 7/10 | Val CCC: 0.1420, MAE: 0.1281\n    Epoch 8/10 | Val CCC: 0.1031, MAE: 0.1253\n    Epoch 9/10 | Val CCC: 0.1243, MAE: 0.1235\n    Epoch 10/10 | Val CCC: 0.1194, MAE: 0.1203\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0922, MAE: 0.1649\n    Epoch 2/10 | Val CCC: 0.1159, MAE: 0.1336\n    Epoch 3/10 | Val CCC: 0.0862, MAE: 0.1347\n    Epoch 4/10 | Val CCC: 0.0929, MAE: 0.1209\n    Epoch 5/10 | Val CCC: 0.1373, MAE: 0.1207\n    Epoch 6/10 | Val CCC: 0.1283, MAE: 0.1243\n    Epoch 7/10 | Val CCC: 0.0990, MAE: 0.1554\n    Epoch 8/10 | Val CCC: 0.1139, MAE: 0.1307\n    Epoch 9/10 | Val CCC: 0.1202, MAE: 0.1211\n    Epoch 10/10 | Val CCC: 0.1083, MAE: 0.1344\n  Avg CCC: 0.1397, MAE: 0.1240\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0958, MAE: 0.1200\n    Epoch 2/10 | Val CCC: 0.0645, MAE: 0.1201\n    Epoch 3/10 | Val CCC: 0.1068, MAE: 0.1206\n    Epoch 4/10 | Val CCC: 0.0858, MAE: 0.1194\n    Epoch 5/10 | Val CCC: 0.0839, MAE: 0.1205\n    Epoch 6/10 | Val CCC: 0.0818, MAE: 0.1285\n    Epoch 7/10 | Val CCC: 0.0925, MAE: 0.1222\n    Epoch 8/10 | Val CCC: 0.1296, MAE: 0.1200\n    Epoch 9/10 | Val CCC: 0.0943, MAE: 0.1198\n    Epoch 10/10 | Val CCC: 0.0916, MAE: 0.1196\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0900, MAE: 0.1232\n    Epoch 2/10 | Val CCC: 0.0680, MAE: 0.1210\n    Epoch 3/10 | Val CCC: 0.0634, MAE: 0.1195\n    Epoch 4/10 | Val CCC: 0.0790, MAE: 0.1190\n    Epoch 5/10 | Val CCC: 0.1021, MAE: 0.1203\n    Epoch 6/10 | Val CCC: 0.0923, MAE: 0.1193\n    Epoch 7/10 | Val CCC: 0.0862, MAE: 0.1254\n    Epoch 8/10 | Val CCC: 0.0793, MAE: 0.1195\n    Epoch 9/10 | Val CCC: 0.0875, MAE: 0.1228\n    Epoch 10/10 | Val CCC: 0.0790, MAE: 0.1236\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0845, MAE: 0.1194\n    Epoch 2/10 | Val CCC: 0.0730, MAE: 0.1299\n    Epoch 3/10 | Val CCC: 0.0793, MAE: 0.1311\n    Epoch 4/10 | Val CCC: 0.0760, MAE: 0.1362\n    Epoch 5/10 | Val CCC: 0.0847, MAE: 0.1184\n    Epoch 6/10 | Val CCC: 0.1153, MAE: 0.1200\n    Epoch 7/10 | Val CCC: 0.0959, MAE: 0.1202\n    Epoch 8/10 | Val CCC: 0.1052, MAE: 0.1243\n    Epoch 9/10 | Val CCC: 0.1187, MAE: 0.1206\n    Epoch 10/10 | Val CCC: 0.1360, MAE: 0.1214\n  Avg CCC: 0.1226, MAE: 0.1206\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0672, MAE: 0.1294\n    Epoch 2/10 | Val CCC: 0.0716, MAE: 0.1258\n    Epoch 3/10 | Val CCC: 0.1227, MAE: 0.1224\n    Epoch 4/10 | Val CCC: 0.1299, MAE: 0.1227\n    Epoch 5/10 | Val CCC: 0.0935, MAE: 0.1231\n    Epoch 6/10 | Val CCC: 0.1706, MAE: 0.1235\n    Epoch 7/10 | Val CCC: 0.1517, MAE: 0.1226\n    Epoch 8/10 | Val CCC: 0.0882, MAE: 0.1228\n    Epoch 9/10 | Val CCC: 0.0810, MAE: 0.1233\n    Epoch 10/10 | Val CCC: 0.1290, MAE: 0.1217\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0719, MAE: 0.1253\n    Epoch 2/10 | Val CCC: 0.0780, MAE: 0.1293\n    Epoch 3/10 | Val CCC: 0.1006, MAE: 0.1248\n    Epoch 4/10 | Val CCC: 0.0922, MAE: 0.1240\n    Epoch 5/10 | Val CCC: 0.0879, MAE: 0.1230\n    Epoch 6/10 | Val CCC: 0.0959, MAE: 0.1228\n    Epoch 7/10 | Val CCC: 0.0775, MAE: 0.1242\n    Epoch 8/10 | Val CCC: 0.0953, MAE: 0.1253\n    Epoch 9/10 | Val CCC: 0.1015, MAE: 0.1233\n    Epoch 10/10 | Val CCC: 0.1241, MAE: 0.1251\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1135, MAE: 0.1210\n    Epoch 2/10 | Val CCC: 0.1213, MAE: 0.1201\n    Epoch 3/10 | Val CCC: 0.1334, MAE: 0.1211\n    Epoch 4/10 | Val CCC: 0.1415, MAE: 0.1214\n    Epoch 5/10 | Val CCC: 0.1178, MAE: 0.1204\n    Epoch 6/10 | Val CCC: 0.0679, MAE: 0.1219\n    Epoch 7/10 | Val CCC: 0.1215, MAE: 0.1203\n    Epoch 8/10 | Val CCC: 0.1067, MAE: 0.1230\n    Epoch 9/10 | Val CCC: 0.1072, MAE: 0.1212\n    Epoch 10/10 | Val CCC: 0.1060, MAE: 0.1237\n  Avg CCC: 0.1454, MAE: 0.1233\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0605, MAE: 0.1212\n    Epoch 2/10 | Val CCC: 0.1000, MAE: 0.1276\n    Epoch 3/10 | Val CCC: 0.1199, MAE: 0.1183\n    Epoch 4/10 | Val CCC: 0.0819, MAE: 0.1202\n    Epoch 5/10 | Val CCC: 0.0935, MAE: 0.1191\n    Epoch 6/10 | Val CCC: 0.1127, MAE: 0.1233\n    Epoch 7/10 | Val CCC: 0.1205, MAE: 0.1197\n    Epoch 8/10 | Val CCC: 0.1099, MAE: 0.1221\n    Epoch 9/10 | Val CCC: 0.1203, MAE: 0.1192\n    Epoch 10/10 | Val CCC: 0.1205, MAE: 0.1196\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0771, MAE: 0.1226\n    Epoch 2/10 | Val CCC: 0.0797, MAE: 0.1200\n    Epoch 3/10 | Val CCC: 0.0786, MAE: 0.1199\n    Epoch 4/10 | Val CCC: 0.0749, MAE: 0.1233\n    Epoch 5/10 | Val CCC: 0.0755, MAE: 0.1214\n    Epoch 6/10 | Val CCC: 0.0995, MAE: 0.1216\n    Epoch 7/10 | Val CCC: 0.0796, MAE: 0.1219\n    Epoch 8/10 | Val CCC: 0.0847, MAE: 0.1198\n    Epoch 9/10 | Val CCC: 0.0760, MAE: 0.1198\n    Epoch 10/10 | Val CCC: 0.0886, MAE: 0.1199\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0983, MAE: 0.1190\n    Epoch 2/10 | Val CCC: 0.1027, MAE: 0.1208\n    Epoch 3/10 | Val CCC: 0.1310, MAE: 0.1235\n    Epoch 4/10 | Val CCC: 0.1268, MAE: 0.1201\n    Epoch 5/10 | Val CCC: 0.0985, MAE: 0.1208\n    Epoch 6/10 | Val CCC: 0.1157, MAE: 0.1198\n    Epoch 7/10 | Val CCC: 0.1139, MAE: 0.1187\n    Epoch 8/10 | Val CCC: 0.1155, MAE: 0.1212\n    Epoch 9/10 | Val CCC: 0.0987, MAE: 0.1231\n    Epoch 10/10 | Val CCC: 0.1161, MAE: 0.1198\n  Avg CCC: 0.1170, MAE: 0.1216\n\n>>> Best Config Selected: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n\n>>> Final Training for EXTRAVERSION (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0319\n  Epoch 2/10 - Train Loss: 0.0238\n  Epoch 3/10 - Train Loss: 0.0227\n  Epoch 4/10 - Train Loss: 0.0226\n  Epoch 5/10 - Train Loss: 0.0222\n  Epoch 6/10 - Train Loss: 0.0219\n  Epoch 7/10 - Train Loss: 0.0218\n  Epoch 8/10 - Train Loss: 0.0216\n  Epoch 9/10 - Train Loss: 0.0212\n  Epoch 10/10 - Train Loss: 0.0210\n\n==== EXTRAVERSION Evaluation on Test Set ====\nTest CCC: 0.1129, Test MAE: 0.1241, Accuracy (±0.1): 46.33%\nSaving final model for extraversion to best_text_transformer_model_extraversion.pth\n\n--- Training for Trait: agreeableness ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0017, MAE: 0.1214\n    Epoch 2/10 | Val CCC: 0.0035, MAE: 0.1070\n    Epoch 3/10 | Val CCC: 0.0112, MAE: 0.1127\n    Epoch 4/10 | Val CCC: 0.0445, MAE: 0.1119\n    Epoch 5/10 | Val CCC: 0.1081, MAE: 0.1045\n    Epoch 6/10 | Val CCC: 0.0784, MAE: 0.1210\n    Epoch 7/10 | Val CCC: 0.1255, MAE: 0.1048\n    Epoch 8/10 | Val CCC: 0.0546, MAE: 0.1157\n    Epoch 9/10 | Val CCC: 0.0762, MAE: 0.1073\n    Epoch 10/10 | Val CCC: 0.0858, MAE: 0.1108\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0018, MAE: 0.1061\n    Epoch 2/10 | Val CCC: 0.0039, MAE: 0.1176\n    Epoch 3/10 | Val CCC: 0.0636, MAE: 0.1052\n    Epoch 4/10 | Val CCC: 0.0630, MAE: 0.1041\n    Epoch 5/10 | Val CCC: 0.0917, MAE: 0.1057\n    Epoch 6/10 | Val CCC: 0.0621, MAE: 0.1147\n    Epoch 7/10 | Val CCC: 0.0649, MAE: 0.1104\n    Epoch 8/10 | Val CCC: 0.0614, MAE: 0.1044\n    Epoch 9/10 | Val CCC: 0.0785, MAE: 0.1113\n    Epoch 10/10 | Val CCC: 0.0793, MAE: 0.1119\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0064, MAE: 0.1039\n    Epoch 2/10 | Val CCC: 0.0603, MAE: 0.1084\n    Epoch 3/10 | Val CCC: 0.0817, MAE: 0.1047\n    Epoch 4/10 | Val CCC: 0.0815, MAE: 0.1143\n    Epoch 5/10 | Val CCC: 0.0840, MAE: 0.1022\n    Epoch 6/10 | Val CCC: 0.0994, MAE: 0.1091\n    Epoch 7/10 | Val CCC: 0.0875, MAE: 0.1022\n    Epoch 8/10 | Val CCC: 0.0923, MAE: 0.1018\n    Epoch 9/10 | Val CCC: 0.0767, MAE: 0.1021\n    Epoch 10/10 | Val CCC: 0.0514, MAE: 0.1154\n  Avg CCC: 0.1055, MAE: 0.1065\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1056, MAE: 0.1069\n    Epoch 2/10 | Val CCC: 0.0893, MAE: 0.1051\n    Epoch 3/10 | Val CCC: 0.1092, MAE: 0.1135\n    Epoch 4/10 | Val CCC: 0.1037, MAE: 0.1102\n    Epoch 5/10 | Val CCC: 0.1136, MAE: 0.1202\n    Epoch 6/10 | Val CCC: 0.1202, MAE: 0.1160\n    Epoch 7/10 | Val CCC: 0.1462, MAE: 0.1145\n    Epoch 8/10 | Val CCC: 0.1235, MAE: 0.1206\n    Epoch 9/10 | Val CCC: 0.1249, MAE: 0.1262\n    Epoch 10/10 | Val CCC: 0.1334, MAE: 0.1152\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0692, MAE: 0.1085\n    Epoch 2/10 | Val CCC: 0.0812, MAE: 0.1056\n    Epoch 3/10 | Val CCC: 0.0693, MAE: 0.1125\n    Epoch 4/10 | Val CCC: 0.1037, MAE: 0.1078\n    Epoch 5/10 | Val CCC: 0.0814, MAE: 0.1330\n    Epoch 6/10 | Val CCC: 0.0921, MAE: 0.1274\n    Epoch 7/10 | Val CCC: 0.0995, MAE: 0.1151\n    Epoch 8/10 | Val CCC: 0.0998, MAE: 0.1316\n    Epoch 9/10 | Val CCC: 0.0837, MAE: 0.1331\n    Epoch 10/10 | Val CCC: 0.0984, MAE: 0.1178\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0818, MAE: 0.1028\n    Epoch 2/10 | Val CCC: 0.1026, MAE: 0.1031\n    Epoch 3/10 | Val CCC: 0.0770, MAE: 0.1317\n    Epoch 4/10 | Val CCC: 0.1284, MAE: 0.1125\n    Epoch 5/10 | Val CCC: 0.1021, MAE: 0.1167\n    Epoch 6/10 | Val CCC: 0.1232, MAE: 0.1193\n    Epoch 7/10 | Val CCC: 0.1207, MAE: 0.1241\n    Epoch 8/10 | Val CCC: 0.1270, MAE: 0.1051\n    Epoch 9/10 | Val CCC: 0.1007, MAE: 0.1294\n    Epoch 10/10 | Val CCC: 0.1159, MAE: 0.1174\n  Avg CCC: 0.1261, MAE: 0.1116\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0931, MAE: 0.1063\n    Epoch 2/10 | Val CCC: 0.0447, MAE: 0.1059\n    Epoch 3/10 | Val CCC: 0.1019, MAE: 0.1042\n    Epoch 4/10 | Val CCC: 0.0820, MAE: 0.1056\n    Epoch 5/10 | Val CCC: 0.1010, MAE: 0.1084\n    Epoch 6/10 | Val CCC: 0.1141, MAE: 0.1056\n    Epoch 7/10 | Val CCC: 0.0954, MAE: 0.1061\n    Epoch 8/10 | Val CCC: 0.1191, MAE: 0.1081\n    Epoch 9/10 | Val CCC: 0.0966, MAE: 0.1052\n    Epoch 10/10 | Val CCC: 0.0892, MAE: 0.1044\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0474, MAE: 0.1104\n    Epoch 2/10 | Val CCC: 0.0701, MAE: 0.1091\n    Epoch 3/10 | Val CCC: 0.0813, MAE: 0.1048\n    Epoch 4/10 | Val CCC: 0.0842, MAE: 0.1052\n    Epoch 5/10 | Val CCC: 0.1063, MAE: 0.1050\n    Epoch 6/10 | Val CCC: 0.1012, MAE: 0.1067\n    Epoch 7/10 | Val CCC: 0.0628, MAE: 0.1045\n    Epoch 8/10 | Val CCC: 0.0946, MAE: 0.1066\n    Epoch 9/10 | Val CCC: 0.1095, MAE: 0.1055\n    Epoch 10/10 | Val CCC: 0.0931, MAE: 0.1054\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1109, MAE: 0.1038\n    Epoch 2/10 | Val CCC: 0.1026, MAE: 0.1035\n    Epoch 3/10 | Val CCC: 0.0792, MAE: 0.1094\n    Epoch 4/10 | Val CCC: 0.0758, MAE: 0.1024\n    Epoch 5/10 | Val CCC: 0.0988, MAE: 0.1022\n    Epoch 6/10 | Val CCC: 0.1207, MAE: 0.1037\n    Epoch 7/10 | Val CCC: 0.1014, MAE: 0.1045\n    Epoch 8/10 | Val CCC: 0.0819, MAE: 0.1031\n    Epoch 9/10 | Val CCC: 0.1001, MAE: 0.1046\n    Epoch 10/10 | Val CCC: 0.1173, MAE: 0.1036\n  Avg CCC: 0.1164, MAE: 0.1058\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0746, MAE: 0.1047\n    Epoch 2/10 | Val CCC: 0.1055, MAE: 0.1070\n    Epoch 3/10 | Val CCC: 0.0900, MAE: 0.1055\n    Epoch 4/10 | Val CCC: 0.1235, MAE: 0.1053\n    Epoch 5/10 | Val CCC: 0.1033, MAE: 0.1054\n    Epoch 6/10 | Val CCC: 0.1082, MAE: 0.1056\n    Epoch 7/10 | Val CCC: 0.0891, MAE: 0.1042\n    Epoch 8/10 | Val CCC: 0.1007, MAE: 0.1047\n    Epoch 9/10 | Val CCC: 0.1026, MAE: 0.1046\n    Epoch 10/10 | Val CCC: 0.1120, MAE: 0.1043\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0699, MAE: 0.1072\n    Epoch 2/10 | Val CCC: 0.0925, MAE: 0.1059\n    Epoch 3/10 | Val CCC: 0.0463, MAE: 0.1068\n    Epoch 4/10 | Val CCC: 0.0710, MAE: 0.1047\n    Epoch 5/10 | Val CCC: 0.0802, MAE: 0.1048\n    Epoch 6/10 | Val CCC: 0.0976, MAE: 0.1051\n    Epoch 7/10 | Val CCC: 0.0651, MAE: 0.1047\n    Epoch 8/10 | Val CCC: 0.0814, MAE: 0.1057\n    Epoch 9/10 | Val CCC: 0.0859, MAE: 0.1054\n    Epoch 10/10 | Val CCC: 0.0810, MAE: 0.1048\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0872, MAE: 0.1097\n    Epoch 2/10 | Val CCC: 0.0794, MAE: 0.1051\n    Epoch 3/10 | Val CCC: 0.0555, MAE: 0.1152\n    Epoch 4/10 | Val CCC: 0.0717, MAE: 0.1127\n    Epoch 5/10 | Val CCC: 0.0718, MAE: 0.1052\n    Epoch 6/10 | Val CCC: 0.0987, MAE: 0.1032\n    Epoch 7/10 | Val CCC: 0.1088, MAE: 0.1028\n    Epoch 8/10 | Val CCC: 0.1003, MAE: 0.1098\n    Epoch 9/10 | Val CCC: 0.0896, MAE: 0.1028\n    Epoch 10/10 | Val CCC: 0.0947, MAE: 0.1026\n  Avg CCC: 0.1099, MAE: 0.1044\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0972, MAE: 0.1175\n    Epoch 2/10 | Val CCC: 0.0691, MAE: 0.1112\n    Epoch 3/10 | Val CCC: 0.0823, MAE: 0.1089\n    Epoch 4/10 | Val CCC: 0.0813, MAE: 0.1073\n    Epoch 5/10 | Val CCC: 0.1023, MAE: 0.1069\n    Epoch 6/10 | Val CCC: 0.1111, MAE: 0.1063\n    Epoch 7/10 | Val CCC: 0.1128, MAE: 0.1054\n    Epoch 8/10 | Val CCC: 0.1110, MAE: 0.1062\n    Epoch 9/10 | Val CCC: 0.1042, MAE: 0.1054\n    Epoch 10/10 | Val CCC: 0.1127, MAE: 0.1051\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0283, MAE: 0.1156\n    Epoch 2/10 | Val CCC: 0.0555, MAE: 0.1115\n    Epoch 3/10 | Val CCC: 0.0883, MAE: 0.1082\n    Epoch 4/10 | Val CCC: 0.0938, MAE: 0.1072\n    Epoch 5/10 | Val CCC: 0.0744, MAE: 0.1084\n    Epoch 6/10 | Val CCC: 0.0833, MAE: 0.1060\n    Epoch 7/10 | Val CCC: 0.0885, MAE: 0.1061\n    Epoch 8/10 | Val CCC: 0.0841, MAE: 0.1060\n    Epoch 9/10 | Val CCC: 0.0894, MAE: 0.1054\n    Epoch 10/10 | Val CCC: 0.0820, MAE: 0.1056\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0987, MAE: 0.1162\n    Epoch 2/10 | Val CCC: 0.1054, MAE: 0.1088\n    Epoch 3/10 | Val CCC: 0.1094, MAE: 0.1059\n    Epoch 4/10 | Val CCC: 0.1105, MAE: 0.1057\n    Epoch 5/10 | Val CCC: 0.1053, MAE: 0.1043\n    Epoch 6/10 | Val CCC: 0.1013, MAE: 0.1033\n    Epoch 7/10 | Val CCC: 0.1120, MAE: 0.1035\n    Epoch 8/10 | Val CCC: 0.0942, MAE: 0.1055\n    Epoch 9/10 | Val CCC: 0.1010, MAE: 0.1030\n    Epoch 10/10 | Val CCC: 0.1003, MAE: 0.1024\n  Avg CCC: 0.1062, MAE: 0.1054\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1220, MAE: 0.1137\n    Epoch 2/10 | Val CCC: 0.1283, MAE: 0.1093\n    Epoch 3/10 | Val CCC: 0.1224, MAE: 0.1052\n    Epoch 4/10 | Val CCC: 0.1067, MAE: 0.1069\n    Epoch 5/10 | Val CCC: 0.1127, MAE: 0.1047\n    Epoch 6/10 | Val CCC: 0.1062, MAE: 0.1045\n    Epoch 7/10 | Val CCC: 0.0950, MAE: 0.1137\n    Epoch 8/10 | Val CCC: 0.0852, MAE: 0.1206\n    Epoch 9/10 | Val CCC: 0.1011, MAE: 0.1087\n    Epoch 10/10 | Val CCC: 0.0900, MAE: 0.1202\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0973, MAE: 0.1128\n    Epoch 2/10 | Val CCC: 0.0863, MAE: 0.1097\n    Epoch 3/10 | Val CCC: 0.0955, MAE: 0.1064\n    Epoch 4/10 | Val CCC: 0.0877, MAE: 0.1049\n    Epoch 5/10 | Val CCC: 0.1004, MAE: 0.1055\n    Epoch 6/10 | Val CCC: 0.1035, MAE: 0.1080\n    Epoch 7/10 | Val CCC: 0.0920, MAE: 0.1103\n    Epoch 8/10 | Val CCC: 0.0895, MAE: 0.1139\n    Epoch 9/10 | Val CCC: 0.1063, MAE: 0.1066\n    Epoch 10/10 | Val CCC: 0.1079, MAE: 0.1097\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0809, MAE: 0.1114\n    Epoch 2/10 | Val CCC: 0.0773, MAE: 0.1168\n    Epoch 3/10 | Val CCC: 0.1046, MAE: 0.1058\n    Epoch 4/10 | Val CCC: 0.0794, MAE: 0.1059\n    Epoch 5/10 | Val CCC: 0.0902, MAE: 0.1129\n    Epoch 6/10 | Val CCC: 0.1097, MAE: 0.1075\n    Epoch 7/10 | Val CCC: 0.0872, MAE: 0.1078\n    Epoch 8/10 | Val CCC: 0.0907, MAE: 0.1131\n    Epoch 9/10 | Val CCC: 0.0884, MAE: 0.1067\n    Epoch 10/10 | Val CCC: 0.0967, MAE: 0.1094\n  Avg CCC: 0.1153, MAE: 0.1088\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0873, MAE: 0.1103\n    Epoch 2/10 | Val CCC: 0.0524, MAE: 0.1084\n    Epoch 3/10 | Val CCC: 0.0502, MAE: 0.1051\n    Epoch 4/10 | Val CCC: 0.0979, MAE: 0.1048\n    Epoch 5/10 | Val CCC: 0.1110, MAE: 0.1076\n    Epoch 6/10 | Val CCC: 0.1064, MAE: 0.1045\n    Epoch 7/10 | Val CCC: 0.0762, MAE: 0.1059\n    Epoch 8/10 | Val CCC: 0.1231, MAE: 0.1067\n    Epoch 9/10 | Val CCC: 0.0995, MAE: 0.1045\n    Epoch 10/10 | Val CCC: 0.0569, MAE: 0.1061\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0973, MAE: 0.1107\n    Epoch 2/10 | Val CCC: 0.0535, MAE: 0.1050\n    Epoch 3/10 | Val CCC: 0.0625, MAE: 0.1075\n    Epoch 4/10 | Val CCC: 0.0541, MAE: 0.1046\n    Epoch 5/10 | Val CCC: 0.0581, MAE: 0.1052\n    Epoch 6/10 | Val CCC: 0.0862, MAE: 0.1043\n    Epoch 7/10 | Val CCC: 0.0753, MAE: 0.1053\n    Epoch 8/10 | Val CCC: 0.0944, MAE: 0.1061\n    Epoch 9/10 | Val CCC: 0.0855, MAE: 0.1048\n    Epoch 10/10 | Val CCC: 0.0687, MAE: 0.1058\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0794, MAE: 0.1031\n    Epoch 2/10 | Val CCC: 0.0715, MAE: 0.1037\n    Epoch 3/10 | Val CCC: 0.0603, MAE: 0.1034\n    Epoch 4/10 | Val CCC: 0.0680, MAE: 0.1025\n    Epoch 5/10 | Val CCC: 0.0625, MAE: 0.1028\n    Epoch 6/10 | Val CCC: 0.0782, MAE: 0.1026\n    Epoch 7/10 | Val CCC: 0.1001, MAE: 0.1028\n    Epoch 8/10 | Val CCC: 0.0967, MAE: 0.1055\n    Epoch 9/10 | Val CCC: 0.1072, MAE: 0.1030\n    Epoch 10/10 | Val CCC: 0.0951, MAE: 0.1027\n  Avg CCC: 0.1092, MAE: 0.1068\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0980, MAE: 0.1137\n    Epoch 2/10 | Val CCC: 0.1105, MAE: 0.1086\n    Epoch 3/10 | Val CCC: 0.1044, MAE: 0.1074\n    Epoch 4/10 | Val CCC: 0.1148, MAE: 0.1054\n    Epoch 5/10 | Val CCC: 0.1071, MAE: 0.1059\n    Epoch 6/10 | Val CCC: 0.0972, MAE: 0.1058\n    Epoch 7/10 | Val CCC: 0.1059, MAE: 0.1053\n    Epoch 8/10 | Val CCC: 0.1033, MAE: 0.1050\n    Epoch 9/10 | Val CCC: 0.1131, MAE: 0.1048\n    Epoch 10/10 | Val CCC: 0.1178, MAE: 0.1046\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0771, MAE: 0.1148\n    Epoch 2/10 | Val CCC: 0.0832, MAE: 0.1098\n    Epoch 3/10 | Val CCC: 0.0992, MAE: 0.1073\n    Epoch 4/10 | Val CCC: 0.0876, MAE: 0.1069\n    Epoch 5/10 | Val CCC: 0.0727, MAE: 0.1057\n    Epoch 6/10 | Val CCC: 0.0876, MAE: 0.1053\n    Epoch 7/10 | Val CCC: 0.0959, MAE: 0.1052\n    Epoch 8/10 | Val CCC: 0.0936, MAE: 0.1045\n    Epoch 9/10 | Val CCC: 0.0803, MAE: 0.1047\n    Epoch 10/10 | Val CCC: 0.0768, MAE: 0.1055\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1073, MAE: 0.1092\n    Epoch 2/10 | Val CCC: 0.1359, MAE: 0.1071\n    Epoch 3/10 | Val CCC: 0.1189, MAE: 0.1070\n    Epoch 4/10 | Val CCC: 0.0983, MAE: 0.1070\n    Epoch 5/10 | Val CCC: 0.1070, MAE: 0.1052\n    Epoch 6/10 | Val CCC: 0.1155, MAE: 0.1028\n    Epoch 7/10 | Val CCC: 0.1088, MAE: 0.1033\n    Epoch 8/10 | Val CCC: 0.1073, MAE: 0.1027\n    Epoch 9/10 | Val CCC: 0.1201, MAE: 0.1025\n    Epoch 10/10 | Val CCC: 0.1072, MAE: 0.1024\n  Avg CCC: 0.1177, MAE: 0.1063\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: -0.0002, MAE: 0.1254\n    Epoch 2/10 | Val CCC: 0.0003, MAE: 0.1307\n    Epoch 3/10 | Val CCC: 0.0010, MAE: 0.1098\n    Epoch 4/10 | Val CCC: 0.0007, MAE: 0.1111\n    Epoch 5/10 | Val CCC: 0.0013, MAE: 0.1109\n    Epoch 6/10 | Val CCC: 0.0014, MAE: 0.1112\n    Epoch 7/10 | Val CCC: 0.0023, MAE: 0.1450\n    Epoch 8/10 | Val CCC: 0.0120, MAE: 0.1274\n    Epoch 9/10 | Val CCC: 0.1298, MAE: 0.1264\n    Epoch 10/10 | Val CCC: 0.0694, MAE: 0.1077\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0008, MAE: 0.1401\n    Epoch 2/10 | Val CCC: 0.0004, MAE: 0.1154\n    Epoch 3/10 | Val CCC: 0.0016, MAE: 0.1113\n    Epoch 4/10 | Val CCC: 0.0029, MAE: 0.1289\n    Epoch 5/10 | Val CCC: 0.0056, MAE: 0.1185\n    Epoch 6/10 | Val CCC: 0.0230, MAE: 0.1437\n    Epoch 7/10 | Val CCC: 0.0689, MAE: 0.1164\n    Epoch 8/10 | Val CCC: 0.0864, MAE: 0.1097\n    Epoch 9/10 | Val CCC: 0.0786, MAE: 0.1049\n    Epoch 10/10 | Val CCC: 0.0611, MAE: 0.1205\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0146, MAE: 0.1341\n    Epoch 2/10 | Val CCC: 0.0469, MAE: 0.1750\n    Epoch 3/10 | Val CCC: 0.0877, MAE: 0.1066\n    Epoch 4/10 | Val CCC: 0.0684, MAE: 0.1310\n    Epoch 5/10 | Val CCC: 0.1163, MAE: 0.1141\n    Epoch 6/10 | Val CCC: 0.0865, MAE: 0.1143\n    Epoch 7/10 | Val CCC: 0.0657, MAE: 0.1060\n    Epoch 8/10 | Val CCC: 0.1053, MAE: 0.1138\n    Epoch 9/10 | Val CCC: 0.0766, MAE: 0.1161\n    Epoch 10/10 | Val CCC: 0.1067, MAE: 0.1025\n  Avg CCC: 0.1108, MAE: 0.1168\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 64, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0726, MAE: 0.1154\n    Epoch 2/10 | Val CCC: 0.1052, MAE: 0.1073\n    Epoch 3/10 | Val CCC: 0.0924, MAE: 0.1050\n    Epoch 4/10 | Val CCC: 0.1170, MAE: 0.1050\n    Epoch 5/10 | Val CCC: 0.0952, MAE: 0.1068\n    Epoch 6/10 | Val CCC: 0.0897, MAE: 0.1045\n    Epoch 7/10 | Val CCC: 0.0997, MAE: 0.1041\n    Epoch 8/10 | Val CCC: 0.1262, MAE: 0.1061\n    Epoch 9/10 | Val CCC: 0.1129, MAE: 0.1114\n    Epoch 10/10 | Val CCC: 0.1304, MAE: 0.1058\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0863, MAE: 0.1075\n    Epoch 2/10 | Val CCC: 0.0775, MAE: 0.1042\n    Epoch 3/10 | Val CCC: 0.0786, MAE: 0.1062\n    Epoch 4/10 | Val CCC: 0.0819, MAE: 0.1047\n    Epoch 5/10 | Val CCC: 0.0850, MAE: 0.1057\n    Epoch 6/10 | Val CCC: 0.0696, MAE: 0.1072\n    Epoch 7/10 | Val CCC: 0.0824, MAE: 0.1089\n    Epoch 8/10 | Val CCC: 0.0885, MAE: 0.1058\n    Epoch 9/10 | Val CCC: 0.1043, MAE: 0.1042\n    Epoch 10/10 | Val CCC: 0.1029, MAE: 0.1044\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0751, MAE: 0.1062\n    Epoch 2/10 | Val CCC: 0.0967, MAE: 0.1016\n    Epoch 3/10 | Val CCC: 0.0951, MAE: 0.1015\n    Epoch 4/10 | Val CCC: 0.1013, MAE: 0.1058\n    Epoch 5/10 | Val CCC: 0.1235, MAE: 0.1015\n    Epoch 6/10 | Val CCC: 0.0914, MAE: 0.1046\n    Epoch 7/10 | Val CCC: 0.0841, MAE: 0.1014\n    Epoch 8/10 | Val CCC: 0.1093, MAE: 0.1032\n    Epoch 9/10 | Val CCC: 0.1103, MAE: 0.1075\n    Epoch 10/10 | Val CCC: 0.1148, MAE: 0.1034\n  Avg CCC: 0.1194, MAE: 0.1038\n\n>>> Best Config Selected: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 0.0001}\n\n>>> Final Training for AGREEABLENESS (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0377\n  Epoch 2/10 - Train Loss: 0.0256\n  Epoch 3/10 - Train Loss: 0.0239\n  Epoch 4/10 - Train Loss: 0.0223\n  Epoch 5/10 - Train Loss: 0.0215\n  Epoch 6/10 - Train Loss: 0.0210\n  Epoch 7/10 - Train Loss: 0.0202\n  Epoch 8/10 - Train Loss: 0.0198\n  Epoch 9/10 - Train Loss: 0.0196\n  Epoch 10/10 - Train Loss: 0.0193\n\n==== AGREEABLENESS Evaluation on Test Set ====\nTest CCC: 0.1456, Test MAE: 0.1060, Accuracy (±0.1): 55.13%\nSaving final model for agreeableness to best_text_transformer_model_agreeableness.pth\n\n--- Training for Trait: neuroticism ---\n\n>>> Config 1/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: -0.0000, MAE: 0.1335\n    Epoch 2/10 | Val CCC: 0.0002, MAE: 0.1323\n    Epoch 3/10 | Val CCC: 0.0005, MAE: 0.1254\n    Epoch 4/10 | Val CCC: 0.0007, MAE: 0.1300\n    Epoch 5/10 | Val CCC: 0.0010, MAE: 0.1261\n    Epoch 6/10 | Val CCC: 0.0025, MAE: 0.1284\n    Epoch 7/10 | Val CCC: 0.0722, MAE: 0.1284\n    Epoch 8/10 | Val CCC: 0.1298, MAE: 0.1230\n    Epoch 9/10 | Val CCC: 0.0880, MAE: 0.1248\n    Epoch 10/10 | Val CCC: 0.0948, MAE: 0.1205\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0082, MAE: 0.1301\n    Epoch 2/10 | Val CCC: 0.0896, MAE: 0.1189\n    Epoch 3/10 | Val CCC: 0.1031, MAE: 0.1297\n    Epoch 4/10 | Val CCC: 0.1341, MAE: 0.1179\n    Epoch 5/10 | Val CCC: 0.1362, MAE: 0.1187\n    Epoch 6/10 | Val CCC: 0.0866, MAE: 0.1298\n    Epoch 7/10 | Val CCC: 0.1094, MAE: 0.1389\n    Epoch 8/10 | Val CCC: 0.1705, MAE: 0.1174\n    Epoch 9/10 | Val CCC: 0.1297, MAE: 0.1168\n    Epoch 10/10 | Val CCC: 0.1742, MAE: 0.1172\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0090, MAE: 0.1203\n    Epoch 2/10 | Val CCC: 0.1088, MAE: 0.1214\n    Epoch 3/10 | Val CCC: 0.1205, MAE: 0.1165\n    Epoch 4/10 | Val CCC: 0.1512, MAE: 0.1178\n    Epoch 5/10 | Val CCC: 0.1193, MAE: 0.1194\n    Epoch 6/10 | Val CCC: 0.1267, MAE: 0.1194\n    Epoch 7/10 | Val CCC: 0.1309, MAE: 0.1199\n    Epoch 8/10 | Val CCC: 0.1357, MAE: 0.1236\n    Epoch 9/10 | Val CCC: 0.1472, MAE: 0.1198\n    Epoch 10/10 | Val CCC: 0.1282, MAE: 0.1172\n  Avg CCC: 0.1518, MAE: 0.1193\n\n>>> Config 2/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0268, MAE: 0.1317\n    Epoch 2/10 | Val CCC: 0.1484, MAE: 0.1267\n    Epoch 3/10 | Val CCC: 0.1022, MAE: 0.1237\n    Epoch 4/10 | Val CCC: 0.1510, MAE: 0.1279\n    Epoch 5/10 | Val CCC: 0.1452, MAE: 0.1202\n    Epoch 6/10 | Val CCC: 0.1453, MAE: 0.1249\n    Epoch 7/10 | Val CCC: 0.1272, MAE: 0.1200\n    Epoch 8/10 | Val CCC: 0.1733, MAE: 0.1218\n    Epoch 9/10 | Val CCC: 0.1022, MAE: 0.1215\n    Epoch 10/10 | Val CCC: 0.1251, MAE: 0.1215\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0954, MAE: 0.1191\n    Epoch 2/10 | Val CCC: 0.1735, MAE: 0.1203\n    Epoch 3/10 | Val CCC: 0.1260, MAE: 0.1340\n    Epoch 4/10 | Val CCC: 0.1301, MAE: 0.1173\n    Epoch 5/10 | Val CCC: 0.1256, MAE: 0.1305\n    Epoch 6/10 | Val CCC: 0.1227, MAE: 0.1179\n    Epoch 7/10 | Val CCC: 0.0922, MAE: 0.1177\n    Epoch 8/10 | Val CCC: 0.0923, MAE: 0.1521\n    Epoch 9/10 | Val CCC: 0.1421, MAE: 0.1204\n    Epoch 10/10 | Val CCC: 0.1523, MAE: 0.1197\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1562, MAE: 0.1204\n    Epoch 2/10 | Val CCC: 0.1249, MAE: 0.1349\n    Epoch 3/10 | Val CCC: 0.1198, MAE: 0.1180\n    Epoch 4/10 | Val CCC: 0.1159, MAE: 0.1201\n    Epoch 5/10 | Val CCC: 0.1546, MAE: 0.1198\n    Epoch 6/10 | Val CCC: 0.1428, MAE: 0.1258\n    Epoch 7/10 | Val CCC: 0.0890, MAE: 0.1328\n    Epoch 8/10 | Val CCC: 0.1221, MAE: 0.1199\n    Epoch 9/10 | Val CCC: 0.1501, MAE: 0.1325\n    Epoch 10/10 | Val CCC: 0.1361, MAE: 0.1223\n  Avg CCC: 0.1676, MAE: 0.1208\n\n>>> Config 3/10\nEvaluating Config: {'embed_dim': 512, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0023, MAE: 0.1778\n    Epoch 2/10 | Val CCC: 0.0177, MAE: 0.1317\n    Epoch 3/10 | Val CCC: 0.1727, MAE: 0.1223\n    Epoch 4/10 | Val CCC: 0.0974, MAE: 0.1314\n    Epoch 5/10 | Val CCC: 0.1399, MAE: 0.1288\n    Epoch 6/10 | Val CCC: 0.1210, MAE: 0.1266\n    Epoch 7/10 | Val CCC: 0.1376, MAE: 0.1259\n    Epoch 8/10 | Val CCC: 0.1023, MAE: 0.1213\n    Epoch 9/10 | Val CCC: 0.1585, MAE: 0.1207\n    Epoch 10/10 | Val CCC: 0.1501, MAE: 0.1296\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0009, MAE: 0.1230\n    Epoch 2/10 | Val CCC: 0.0008, MAE: 0.1346\n    Epoch 3/10 | Val CCC: 0.0003, MAE: 0.1442\n    Epoch 4/10 | Val CCC: 0.0009, MAE: 0.1215\n    Epoch 5/10 | Val CCC: 0.0013, MAE: 0.1260\n    Epoch 6/10 | Val CCC: 0.0027, MAE: 0.1372\n    Epoch 7/10 | Val CCC: 0.0709, MAE: 0.1320\n    Epoch 8/10 | Val CCC: 0.0518, MAE: 0.1416\n    Epoch 9/10 | Val CCC: 0.1454, MAE: 0.1245\n    Epoch 10/10 | Val CCC: 0.0749, MAE: 0.1569\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0024, MAE: 0.1267\n    Epoch 2/10 | Val CCC: 0.0096, MAE: 0.1216\n    Epoch 3/10 | Val CCC: 0.0785, MAE: 0.1444\n    Epoch 4/10 | Val CCC: 0.0736, MAE: 0.1932\n    Epoch 5/10 | Val CCC: 0.0990, MAE: 0.1320\n    Epoch 6/10 | Val CCC: 0.0930, MAE: 0.1393\n    Epoch 7/10 | Val CCC: 0.1115, MAE: 0.1229\n    Epoch 8/10 | Val CCC: 0.1118, MAE: 0.1281\n    Epoch 9/10 | Val CCC: 0.1240, MAE: 0.1222\n    Epoch 10/10 | Val CCC: 0.1120, MAE: 0.1322\n  Avg CCC: 0.1474, MAE: 0.1230\n\n>>> Config 4/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1422, MAE: 0.1213\n    Epoch 2/10 | Val CCC: 0.1304, MAE: 0.1215\n    Epoch 3/10 | Val CCC: 0.1505, MAE: 0.1192\n    Epoch 4/10 | Val CCC: 0.1531, MAE: 0.1219\n    Epoch 5/10 | Val CCC: 0.1548, MAE: 0.1203\n    Epoch 6/10 | Val CCC: 0.1851, MAE: 0.1230\n    Epoch 7/10 | Val CCC: 0.1846, MAE: 0.1247\n    Epoch 8/10 | Val CCC: 0.1611, MAE: 0.1187\n    Epoch 9/10 | Val CCC: 0.2019, MAE: 0.1193\n    Epoch 10/10 | Val CCC: 0.2035, MAE: 0.1185\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0556, MAE: 0.1335\n    Epoch 2/10 | Val CCC: 0.0920, MAE: 0.1199\n    Epoch 3/10 | Val CCC: 0.1203, MAE: 0.1237\n    Epoch 4/10 | Val CCC: 0.1488, MAE: 0.1170\n    Epoch 5/10 | Val CCC: 0.1648, MAE: 0.1275\n    Epoch 6/10 | Val CCC: 0.1562, MAE: 0.1336\n    Epoch 7/10 | Val CCC: 0.1633, MAE: 0.1267\n    Epoch 8/10 | Val CCC: 0.1668, MAE: 0.1234\n    Epoch 9/10 | Val CCC: 0.1723, MAE: 0.1266\n    Epoch 10/10 | Val CCC: 0.1577, MAE: 0.1319\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1048, MAE: 0.1190\n    Epoch 2/10 | Val CCC: 0.1071, MAE: 0.1176\n    Epoch 3/10 | Val CCC: 0.1488, MAE: 0.1180\n    Epoch 4/10 | Val CCC: 0.1615, MAE: 0.1186\n    Epoch 5/10 | Val CCC: 0.1813, MAE: 0.1185\n    Epoch 6/10 | Val CCC: 0.1895, MAE: 0.1187\n    Epoch 7/10 | Val CCC: 0.1693, MAE: 0.1173\n    Epoch 8/10 | Val CCC: 0.1742, MAE: 0.1249\n    Epoch 9/10 | Val CCC: 0.1959, MAE: 0.1214\n    Epoch 10/10 | Val CCC: 0.1708, MAE: 0.1209\n  Avg CCC: 0.1906, MAE: 0.1221\n\n>>> Config 5/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0622, MAE: 0.1494\n    Epoch 2/10 | Val CCC: 0.1092, MAE: 0.1676\n    Epoch 3/10 | Val CCC: 0.1451, MAE: 0.1437\n    Epoch 4/10 | Val CCC: 0.1929, MAE: 0.1225\n    Epoch 5/10 | Val CCC: 0.1782, MAE: 0.1211\n    Epoch 6/10 | Val CCC: 0.1119, MAE: 0.1225\n    Epoch 7/10 | Val CCC: 0.1200, MAE: 0.1232\n    Epoch 8/10 | Val CCC: 0.1238, MAE: 0.1216\n    Epoch 9/10 | Val CCC: 0.2102, MAE: 0.1308\n    Epoch 10/10 | Val CCC: 0.1891, MAE: 0.1221\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.0838, MAE: 0.1462\n    Epoch 2/10 | Val CCC: 0.1484, MAE: 0.1184\n    Epoch 3/10 | Val CCC: 0.1077, MAE: 0.1632\n    Epoch 4/10 | Val CCC: 0.1297, MAE: 0.1250\n    Epoch 5/10 | Val CCC: 0.1533, MAE: 0.1460\n    Epoch 6/10 | Val CCC: 0.1482, MAE: 0.1528\n    Epoch 7/10 | Val CCC: 0.1767, MAE: 0.1228\n    Epoch 8/10 | Val CCC: 0.1791, MAE: 0.1206\n    Epoch 9/10 | Val CCC: 0.1503, MAE: 0.1184\n    Epoch 10/10 | Val CCC: 0.1978, MAE: 0.1216\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1078, MAE: 0.1423\n    Epoch 2/10 | Val CCC: 0.0779, MAE: 0.2005\n    Epoch 3/10 | Val CCC: 0.1298, MAE: 0.1357\n    Epoch 4/10 | Val CCC: 0.1245, MAE: 0.1350\n    Epoch 5/10 | Val CCC: 0.1329, MAE: 0.1493\n    Epoch 6/10 | Val CCC: 0.1594, MAE: 0.1186\n    Epoch 7/10 | Val CCC: 0.1587, MAE: 0.1308\n    Epoch 8/10 | Val CCC: 0.1776, MAE: 0.1272\n    Epoch 9/10 | Val CCC: 0.1857, MAE: 0.1294\n    Epoch 10/10 | Val CCC: 0.1617, MAE: 0.1189\n  Avg CCC: 0.1979, MAE: 0.1273\n\n>>> Config 6/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1715, MAE: 0.1260\n    Epoch 2/10 | Val CCC: 0.1604, MAE: 0.1247\n    Epoch 3/10 | Val CCC: 0.1377, MAE: 0.1193\n    Epoch 4/10 | Val CCC: 0.1213, MAE: 0.1216\n    Epoch 5/10 | Val CCC: 0.1575, MAE: 0.1231\n    Epoch 6/10 | Val CCC: 0.1721, MAE: 0.1204\n    Epoch 7/10 | Val CCC: 0.1282, MAE: 0.1202\n    Epoch 8/10 | Val CCC: 0.1519, MAE: 0.1186\n    Epoch 9/10 | Val CCC: 0.1538, MAE: 0.1192\n    Epoch 10/10 | Val CCC: 0.1666, MAE: 0.1194\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1553, MAE: 0.1192\n    Epoch 2/10 | Val CCC: 0.1538, MAE: 0.1187\n    Epoch 3/10 | Val CCC: 0.1366, MAE: 0.1187\n    Epoch 4/10 | Val CCC: 0.1157, MAE: 0.1213\n    Epoch 5/10 | Val CCC: 0.1654, MAE: 0.1211\n    Epoch 6/10 | Val CCC: 0.1472, MAE: 0.1182\n    Epoch 7/10 | Val CCC: 0.1315, MAE: 0.1200\n    Epoch 8/10 | Val CCC: 0.1227, MAE: 0.1184\n    Epoch 9/10 | Val CCC: 0.1409, MAE: 0.1195\n    Epoch 10/10 | Val CCC: 0.1293, MAE: 0.1208\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.0955, MAE: 0.1217\n    Epoch 2/10 | Val CCC: 0.1572, MAE: 0.1194\n    Epoch 3/10 | Val CCC: 0.1357, MAE: 0.1176\n    Epoch 4/10 | Val CCC: 0.1497, MAE: 0.1175\n    Epoch 5/10 | Val CCC: 0.1240, MAE: 0.1205\n    Epoch 6/10 | Val CCC: 0.1557, MAE: 0.1188\n    Epoch 7/10 | Val CCC: 0.1382, MAE: 0.1200\n    Epoch 8/10 | Val CCC: 0.1437, MAE: 0.1178\n    Epoch 9/10 | Val CCC: 0.1311, MAE: 0.1176\n    Epoch 10/10 | Val CCC: 0.1398, MAE: 0.1183\n  Avg CCC: 0.1649, MAE: 0.1203\n\n>>> Config 7/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0003, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1460, MAE: 0.1225\n    Epoch 2/10 | Val CCC: 0.1541, MAE: 0.1206\n    Epoch 3/10 | Val CCC: 0.1674, MAE: 0.1192\n    Epoch 4/10 | Val CCC: 0.1812, MAE: 0.1189\n    Epoch 5/10 | Val CCC: 0.1604, MAE: 0.1268\n    Epoch 6/10 | Val CCC: 0.1696, MAE: 0.1191\n    Epoch 7/10 | Val CCC: 0.1866, MAE: 0.1200\n    Epoch 8/10 | Val CCC: 0.1731, MAE: 0.1185\n    Epoch 9/10 | Val CCC: 0.1762, MAE: 0.1206\n    Epoch 10/10 | Val CCC: 0.1488, MAE: 0.1188\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1612, MAE: 0.1202\n    Epoch 2/10 | Val CCC: 0.1167, MAE: 0.1228\n    Epoch 3/10 | Val CCC: 0.1432, MAE: 0.1212\n    Epoch 4/10 | Val CCC: 0.1470, MAE: 0.1267\n    Epoch 5/10 | Val CCC: 0.0986, MAE: 0.1255\n    Epoch 6/10 | Val CCC: 0.1534, MAE: 0.1179\n    Epoch 7/10 | Val CCC: 0.1679, MAE: 0.1173\n    Epoch 8/10 | Val CCC: 0.1626, MAE: 0.1177\n    Epoch 9/10 | Val CCC: 0.1797, MAE: 0.1190\n    Epoch 10/10 | Val CCC: 0.1619, MAE: 0.1223\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1536, MAE: 0.1199\n    Epoch 2/10 | Val CCC: 0.1553, MAE: 0.1224\n    Epoch 3/10 | Val CCC: 0.1317, MAE: 0.1186\n    Epoch 4/10 | Val CCC: 0.1155, MAE: 0.1192\n    Epoch 5/10 | Val CCC: 0.1740, MAE: 0.1180\n    Epoch 6/10 | Val CCC: 0.1522, MAE: 0.1173\n    Epoch 7/10 | Val CCC: 0.1247, MAE: 0.1212\n    Epoch 8/10 | Val CCC: 0.1537, MAE: 0.1198\n    Epoch 9/10 | Val CCC: 0.1366, MAE: 0.1221\n    Epoch 10/10 | Val CCC: 0.1448, MAE: 0.1193\n  Avg CCC: 0.1801, MAE: 0.1190\n\n>>> Config 8/10\nEvaluating Config: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1526, MAE: 0.1255\n    Epoch 2/10 | Val CCC: 0.1641, MAE: 0.1224\n    Epoch 3/10 | Val CCC: 0.1704, MAE: 0.1218\n    Epoch 4/10 | Val CCC: 0.1854, MAE: 0.1211\n    Epoch 5/10 | Val CCC: 0.1648, MAE: 0.1191\n    Epoch 6/10 | Val CCC: 0.2021, MAE: 0.1195\n    Epoch 7/10 | Val CCC: 0.1614, MAE: 0.1191\n    Epoch 8/10 | Val CCC: 0.1765, MAE: 0.1188\n    Epoch 9/10 | Val CCC: 0.1610, MAE: 0.1193\n    Epoch 10/10 | Val CCC: 0.1776, MAE: 0.1185\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1468, MAE: 0.1252\n    Epoch 2/10 | Val CCC: 0.1493, MAE: 0.1194\n    Epoch 3/10 | Val CCC: 0.1650, MAE: 0.1173\n    Epoch 4/10 | Val CCC: 0.1705, MAE: 0.1170\n    Epoch 5/10 | Val CCC: 0.1516, MAE: 0.1169\n    Epoch 6/10 | Val CCC: 0.1801, MAE: 0.1175\n    Epoch 7/10 | Val CCC: 0.1521, MAE: 0.1176\n    Epoch 8/10 | Val CCC: 0.1646, MAE: 0.1173\n    Epoch 9/10 | Val CCC: 0.1453, MAE: 0.1172\n    Epoch 10/10 | Val CCC: 0.1567, MAE: 0.1175\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1230, MAE: 0.1231\n    Epoch 2/10 | Val CCC: 0.1579, MAE: 0.1185\n    Epoch 3/10 | Val CCC: 0.1530, MAE: 0.1179\n    Epoch 4/10 | Val CCC: 0.1419, MAE: 0.1177\n    Epoch 5/10 | Val CCC: 0.1616, MAE: 0.1177\n    Epoch 6/10 | Val CCC: 0.1390, MAE: 0.1172\n    Epoch 7/10 | Val CCC: 0.1631, MAE: 0.1173\n    Epoch 8/10 | Val CCC: 0.1441, MAE: 0.1167\n    Epoch 9/10 | Val CCC: 0.1635, MAE: 0.1167\n    Epoch 10/10 | Val CCC: 0.1608, MAE: 0.1166\n  Avg CCC: 0.1819, MAE: 0.1179\n\n>>> Config 9/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.1289, MAE: 0.1230\n    Epoch 2/10 | Val CCC: 0.1707, MAE: 0.1343\n    Epoch 3/10 | Val CCC: 0.1734, MAE: 0.1185\n    Epoch 4/10 | Val CCC: 0.1324, MAE: 0.1275\n    Epoch 5/10 | Val CCC: 0.1603, MAE: 0.1198\n    Epoch 6/10 | Val CCC: 0.1483, MAE: 0.1186\n    Epoch 7/10 | Val CCC: 0.1733, MAE: 0.1191\n    Epoch 8/10 | Val CCC: 0.1398, MAE: 0.1246\n    Epoch 9/10 | Val CCC: 0.1512, MAE: 0.1253\n    Epoch 10/10 | Val CCC: 0.1255, MAE: 0.1196\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1728, MAE: 0.1184\n    Epoch 2/10 | Val CCC: 0.1205, MAE: 0.1188\n    Epoch 3/10 | Val CCC: 0.1416, MAE: 0.1172\n    Epoch 4/10 | Val CCC: 0.1411, MAE: 0.1217\n    Epoch 5/10 | Val CCC: 0.1658, MAE: 0.1214\n    Epoch 6/10 | Val CCC: 0.1544, MAE: 0.1368\n    Epoch 7/10 | Val CCC: 0.1171, MAE: 0.1383\n    Epoch 8/10 | Val CCC: 0.1516, MAE: 0.1183\n    Epoch 9/10 | Val CCC: 0.1205, MAE: 0.1223\n    Epoch 10/10 | Val CCC: 0.1418, MAE: 0.1191\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1776, MAE: 0.1183\n    Epoch 2/10 | Val CCC: 0.0999, MAE: 0.1212\n    Epoch 3/10 | Val CCC: 0.1396, MAE: 0.1296\n    Epoch 4/10 | Val CCC: 0.1184, MAE: 0.1175\n    Epoch 5/10 | Val CCC: 0.1193, MAE: 0.1258\n    Epoch 6/10 | Val CCC: 0.1744, MAE: 0.1252\n    Epoch 7/10 | Val CCC: 0.1452, MAE: 0.1180\n    Epoch 8/10 | Val CCC: 0.1200, MAE: 0.1175\n    Epoch 9/10 | Val CCC: 0.1211, MAE: 0.1246\n    Epoch 10/10 | Val CCC: 0.1826, MAE: 0.1206\n  Avg CCC: 0.1763, MAE: 0.1192\n\n>>> Config 10/10\nEvaluating Config: {'embed_dim': 128, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n  Fold 1/3\n    Epoch 1/10 | Val CCC: 0.0995, MAE: 0.1240\n    Epoch 2/10 | Val CCC: 0.1404, MAE: 0.1222\n    Epoch 3/10 | Val CCC: 0.1150, MAE: 0.1243\n    Epoch 4/10 | Val CCC: 0.1357, MAE: 0.1198\n    Epoch 5/10 | Val CCC: 0.1580, MAE: 0.1193\n    Epoch 6/10 | Val CCC: 0.1032, MAE: 0.1208\n    Epoch 7/10 | Val CCC: 0.1205, MAE: 0.1201\n    Epoch 8/10 | Val CCC: 0.1564, MAE: 0.1193\n    Epoch 9/10 | Val CCC: 0.1386, MAE: 0.1196\n    Epoch 10/10 | Val CCC: 0.1397, MAE: 0.1203\n  Fold 2/3\n    Epoch 1/10 | Val CCC: 0.1506, MAE: 0.1224\n    Epoch 2/10 | Val CCC: 0.1048, MAE: 0.1206\n    Epoch 3/10 | Val CCC: 0.1512, MAE: 0.1180\n    Epoch 4/10 | Val CCC: 0.1399, MAE: 0.1175\n    Epoch 5/10 | Val CCC: 0.1477, MAE: 0.1174\n    Epoch 6/10 | Val CCC: 0.1414, MAE: 0.1177\n    Epoch 7/10 | Val CCC: 0.1358, MAE: 0.1191\n    Epoch 8/10 | Val CCC: 0.1465, MAE: 0.1195\n    Epoch 9/10 | Val CCC: 0.1233, MAE: 0.1184\n    Epoch 10/10 | Val CCC: 0.1462, MAE: 0.1187\n  Fold 3/3\n    Epoch 1/10 | Val CCC: 0.1276, MAE: 0.1209\n    Epoch 2/10 | Val CCC: 0.1158, MAE: 0.1182\n    Epoch 3/10 | Val CCC: 0.1413, MAE: 0.1192\n    Epoch 4/10 | Val CCC: 0.1300, MAE: 0.1187\n    Epoch 5/10 | Val CCC: 0.1452, MAE: 0.1174\n    Epoch 6/10 | Val CCC: 0.1459, MAE: 0.1187\n    Epoch 7/10 | Val CCC: 0.1508, MAE: 0.1185\n    Epoch 8/10 | Val CCC: 0.1505, MAE: 0.1186\n    Epoch 9/10 | Val CCC: 0.1520, MAE: 0.1171\n    Epoch 10/10 | Val CCC: 0.1287, MAE: 0.1188\n  Avg CCC: 0.1538, MAE: 0.1181\n\n>>> Best Config Selected: {'embed_dim': 256, 'num_heads': 2, 'num_layers': 4, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n\n>>> Final Training for NEUROTICISM (10 epochs)\n  Epoch 1/10 - Train Loss: 0.0384\n  Epoch 2/10 - Train Loss: 0.0275\n  Epoch 3/10 - Train Loss: 0.0257\n  Epoch 4/10 - Train Loss: 0.0246\n  Epoch 5/10 - Train Loss: 0.0238\n  Epoch 6/10 - Train Loss: 0.0230\n  Epoch 7/10 - Train Loss: 0.0227\n  Epoch 8/10 - Train Loss: 0.0224\n  Epoch 9/10 - Train Loss: 0.0222\n  Epoch 10/10 - Train Loss: 0.0219\n\n==== NEUROTICISM Evaluation on Test Set ====\nTest CCC: 0.0964, Test MAE: 0.1239, Accuracy (±0.1): 46.67%\nSaving final model for neuroticism to best_text_transformer_model_neuroticism.pth\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"final_train_and_evaluate(best_config, X_train, y_train, X_val, y_val, X_test, y_test)\n","metadata":{"id":"cVd8lAtP4SfV","trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final evaluation function\ndef final_train_and_evaluate(best_config, X_train, y_train, X_val, y_val, X_test, y_test, epochs=30):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Combine train and val sets for final training\n    X_final_train = torch.cat([X_train, X_val], dim=0)\n    y_final_train = torch.cat([y_train, y_val], dim=0)\n\n    final_train_loader = DataLoader(TextDataset(X_final_train, y_final_train), batch_size=int(best_config[\"batch_size\"]), shuffle=True)\n    test_loader = DataLoader(TextDataset(X_test, y_test), batch_size=int(best_config[\"batch_size\"]), shuffle=False)\n\n    # Initialize model\n    model = SimpleTransformerRegressor(\n        input_dim=X_train.shape[1],\n        embed_dim=best_config[\"embed_dim\"],\n        num_heads=best_config[\"num_heads\"],\n        num_layers=best_config[\"num_layers\"],\n        dropout=best_config[\"dropout\"]\n    ).to(device)\n\n    optimizer = optim.AdamW(model.parameters(), lr=best_config[\"lr\"], weight_decay=best_config[\"weight_decay\"])\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n    criterion = nn.MSELoss()\n\n    # Final training\n    for epoch in range(epochs):\n        train_loss = train_one_epoch(model, final_train_loader, optimizer, scheduler, criterion, device)\n        print(f\"Final Train Epoch {epoch+1}/{epochs} - Loss: {train_loss:.4f}\")\n\n    # Final evaluation on test set\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for X_batch, y_batch in test_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            preds = model(X_batch)\n            all_preds.append(preds)\n            all_labels.append(y_batch)\n\n    all_preds = torch.cat(all_preds, dim=0)\n    all_labels = torch.cat(all_labels, dim=0)\n\n    # Metrics\n    final_mae = mean_absolute_error(all_preds, all_labels)\n    final_ccc = concordance_correlation_coefficient(all_preds, all_labels)\n    \n    # Define \"accuracy\" for regression\n    tolerance = 0.1  # within 0.1 tolerance considered correct\n    correct = torch.abs(all_preds - all_labels) < tolerance\n    final_accuracy = correct.float().mean().item()\n\n    print(\"\\n==== Final Evaluation on Test Set ====\")\n    print(f\"Final Test CCC: {final_ccc:.4f}\")\n    print(f\"Final Test MAE: {final_mae:.4f}\")\n    print(f\"Final Test Accuracy (within {tolerance}): {final_accuracy*100:.2f}%\")\n    torch.save(model.state_dict(), \"best_text_transformer_model.pth\")\n    print(\"\\nModel saved to 'best_text_transformer_model.pth'.\")\n","metadata":{"id":"cVd8lAtP4SfV","trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split, KFold\nimport torch.optim as optim\nfrom sklearn.preprocessing import StandardScaler\n\n# Load dataset\ndf = pd.read_csv('/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/text_hc_features.csv')\n\n# Drop unnecessary columns\ndrop_cols = [\"Filename\", \"Segment_ID\", \"interview\", \"Gender\", \"Ethnicity\", \"AgeGroup\"]\ndf.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True, errors='ignore')\n\n# Define label columns\nlabel_columns = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n\n# Separate features and labels\nX = df.drop(columns=label_columns)\ny = df[label_columns]\n\n# Fill missing values\nX = X.fillna(X.mean())\ny = y.fillna(y.mean())\n\n# Normalize features\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n# Convert to tensors\nX_tensor = torch.tensor(X.values, dtype=torch.float32)\ny_tensor = torch.tensor(y.values, dtype=torch.float32)\n\n# Train/val/test split\ntrain_idx, temp_idx = train_test_split(range(len(X)), test_size=0.3, random_state=42)\nval_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n\nX_train, y_train = X_tensor[train_idx], y_tensor[train_idx]\nX_val, y_val = X_tensor[val_idx], y_tensor[val_idx]\nX_test, y_test = X_tensor[test_idx], y_tensor[test_idx]\n\n# Dataset and DataLoader\nclass TextDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\n# Model\nclass SimpleTransformerRegressor(nn.Module):\n    def __init__(self, input_dim, embed_dim=256, num_heads=4, num_layers=2, dropout=0.3):\n        super(SimpleTransformerRegressor, self).__init__()\n        self.project = nn.Linear(input_dim, embed_dim)\n        self.encoder = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout),\n            num_layers=num_layers\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, 128),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(128, 5)  # Predict 5 traits\n        )\n\n    def forward(self, x):\n        x = self.project(x)\n        x = x.unsqueeze(0)  # Add batch dimension for transformer\n        x = self.encoder(x)\n        x = x.squeeze(0)\n        return self.classifier(x)\n\n# Evaluation metrics\ndef mean_absolute_error(preds, labels):\n    return torch.mean(torch.abs(preds - labels)).item()\n\ndef concordance_correlation_coefficient(preds, labels):\n    preds_mean = torch.mean(preds)\n    labels_mean = torch.mean(labels)\n    preds_var = torch.var(preds)\n    labels_var = torch.var(labels)\n    covariance = torch.mean((preds - preds_mean) * (labels - labels_mean))\n    ccc = (2 * covariance) / (preds_var + labels_var + (preds_mean - labels_mean) ** 2)\n    return ccc.item()\n\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    total_loss, total_mae, total_ccc = 0, 0, 0\n    with torch.no_grad():\n        for X_batch, y_batch in loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            preds = model(X_batch)\n            loss = criterion(preds, y_batch)\n            total_loss += loss.item()\n            total_mae += mean_absolute_error(preds, y_batch)\n            total_ccc += concordance_correlation_coefficient(preds, y_batch)\n    n_batches = len(loader)\n    return total_loss/n_batches, total_mae/n_batches, total_ccc/n_batches\n\n# Training loop\ndef train_one_epoch(model, loader, optimizer, scheduler, criterion, device):\n    model.train()\n    total_loss = 0\n    for X_batch, y_batch in loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        preds = model(X_batch)\n        loss = criterion(preds, y_batch)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    scheduler.step()\n    return total_loss / len(loader)\n\n# Hyperparameter tuning\ndef generate_random_configs(search_space, num_configs=10):\n    configs = []\n    for _ in range(num_configs):\n        config = {\n            \"embed_dim\": np.random.choice(search_space[\"embed_dim\"]),\n            \"num_heads\": np.random.choice(search_space[\"num_heads\"]),\n            \"num_layers\": np.random.choice(search_space[\"num_layers\"]),\n            \"dropout\": np.random.choice(search_space[\"dropout\"]),\n            \"lr\": np.random.choice(search_space[\"lr\"]),\n            \"batch_size\": np.random.choice(search_space[\"batch_size\"]),\n            \"weight_decay\": np.random.choice(search_space[\"weight_decay\"])\n        }\n        configs.append(config)\n    return configs\n\ndef cross_validate(config, X_tensor, y_tensor, num_folds=3, epochs=30):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n    fold_metrics = {\"val_ccc\": [], \"val_mae\": [], \"val_loss\": []}\n\n    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_tensor)):\n        print(f\"\\n=== Fold {fold+1}/{num_folds} ===\")\n\n        X_train_fold, y_train_fold = X_tensor[train_idx], y_tensor[train_idx]\n        X_val_fold, y_val_fold = X_tensor[val_idx], y_tensor[val_idx]\n\n        train_loader = DataLoader(TextDataset(X_train_fold, y_train_fold), batch_size=int(config[\"batch_size\"]), shuffle=True)\n        val_loader = DataLoader(TextDataset(X_val_fold, y_val_fold), batch_size=int(config[\"batch_size\"]), shuffle=False)\n\n        model = SimpleTransformerRegressor(\n            input_dim=X_tensor.shape[1],\n            embed_dim=config[\"embed_dim\"],\n            num_heads=config[\"num_heads\"],\n            num_layers=config[\"num_layers\"],\n            dropout=config[\"dropout\"]\n        ).to(device)\n\n        optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n        criterion = nn.MSELoss()\n\n        best_ccc = -1\n        for epoch in range(epochs):\n            train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, device)\n            val_loss, val_mae, val_ccc = evaluate(model, val_loader, criterion, device)\n            print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {val_loss:.4f} - Val MAE: {val_mae:.4f} - Val CCC: {val_ccc:.4f}\")\n\n            if val_ccc > best_ccc:\n                best_ccc = val_ccc\n                best_metrics = (val_loss, val_mae, val_ccc)\n\n        fold_metrics[\"val_loss\"].append(best_metrics[0])\n        fold_metrics[\"val_mae\"].append(best_metrics[1])\n        fold_metrics[\"val_ccc\"].append(best_metrics[2])\n\n    return {\n        \"ccc\": np.mean(fold_metrics[\"val_ccc\"]),\n        \"mae\": np.mean(fold_metrics[\"val_mae\"]),\n        \"loss\": np.mean(fold_metrics[\"val_loss\"])\n    }\n\ndef hyperparameter_tuning(X_tensor, y_tensor, num_configs=10):\n    search_space = {\n        \"embed_dim\": [128, 256, 512],\n        \"num_heads\": [2, 4, 8],\n        \"num_layers\": [2, 4],\n        \"dropout\": [0.1, 0.3, 0.5],\n        \"lr\": [1e-4, 3e-4, 1e-3],\n        \"batch_size\": [32, 64],\n        \"weight_decay\": [1e-5, 1e-4]\n    }\n    configs = generate_random_configs(search_space, num_configs)\n    best_config = None\n    best_ccc = -1\n    results = []\n\n    for i, config in enumerate(configs):\n        print(f\"\\n=== Testing Config {i+1}/{len(configs)} ===\")\n        print(config)\n\n        metrics = cross_validate(config, X_tensor, y_tensor)\n        results.append((config, metrics))\n\n        if metrics[\"ccc\"] > best_ccc:\n            best_ccc = metrics[\"ccc\"]\n            best_config = config\n\n        print(f\"Config {i+1} Metrics - CCC: {metrics['ccc']:.4f}, MAE: {metrics['mae']:.4f}, Loss: {metrics['loss']:.4f}\")\n\n    results_df = pd.DataFrame([\n        {\"config\": str(c), **m} for c, m in results\n    ])\n    results_df.to_csv(\"hyperparameter_tuning_text_hc.csv\", index=False)\n\n    return best_config\n\n# Start hyperparameter tuning\nbest_config = hyperparameter_tuning(X_tensor, y_tensor, num_configs=10)\nprint(\"\\nBest Config Found:\", best_config)\n","metadata":{"id":"cVd8lAtP4SfV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split, KFold\nimport torch.optim as optim\nfrom sklearn.preprocessing import StandardScaler\n\n# 1. Load dataset\ndf = pd.read_csv('/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/audio_hc_features.csv')\n\n# Drop unnecessary non-numeric columns\ndf = df.select_dtypes(include=[np.number])  # Keep only numeric columns\n\n# 2. Define features and labels\n# Assume last 5 columns are [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\nlabel_columns = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n\nX = df.drop(columns=label_columns)\ny = df[label_columns]\n\n# Fill missing values if any\nX = X.fillna(X.mean())\ny = y.fillna(y.mean())\n\n# Normalize features\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n# Convert to tensors\nX_tensor = torch.tensor(X.values, dtype=torch.float32)\ny_tensor = torch.tensor(y.values, dtype=torch.float32)\n\n# 3. Train/Val/Test Split\ntrain_idx, temp_idx = train_test_split(range(len(X)), test_size=0.3, random_state=42)\nval_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n\nX_train, y_train = X_tensor[train_idx], y_tensor[train_idx]\nX_val, y_val = X_tensor[val_idx], y_tensor[val_idx]\nX_test, y_test = X_tensor[test_idx], y_tensor[test_idx]\n\n# 4. Dataset and DataLoader\nclass AudioDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\n# 5. Model\nclass SimpleTransformerRegressor(nn.Module):\n    def __init__(self, input_dim, embed_dim=256, num_heads=4, num_layers=2, dropout=0.3):\n        super(SimpleTransformerRegressor, self).__init__()\n        self.project = nn.Linear(input_dim, embed_dim)\n        self.encoder = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout),\n            num_layers=num_layers\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, 128),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(128, 5)  # 5 labels\n        )\n\n    def forward(self, x):\n        x = self.project(x)\n        x = x.unsqueeze(0)  # Transformer expects (seq_len, batch, feature)\n        x = self.encoder(x)\n        x = x.squeeze(0)\n        return self.classifier(x)\n\n# 6. Evaluation Metrics\ndef mean_absolute_error(preds, labels):\n    return torch.mean(torch.abs(preds - labels)).item()\n\ndef concordance_correlation_coefficient(preds, labels):\n    preds_mean = torch.mean(preds)\n    labels_mean = torch.mean(labels)\n    preds_var = torch.var(preds)\n    labels_var = torch.var(labels)\n    covariance = torch.mean((preds - preds_mean) * (labels - labels_mean))\n    ccc = (2 * covariance) / (preds_var + labels_var + (preds_mean - labels_mean)**2)\n    return ccc.item()\n\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    total_loss, total_mae, total_ccc = 0, 0, 0\n    with torch.no_grad():\n        for X_batch, y_batch in loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            preds = model(X_batch)\n            loss = criterion(preds, y_batch)\n            total_loss += loss.item()\n            total_mae += mean_absolute_error(preds, y_batch)\n            total_ccc += concordance_correlation_coefficient(preds, y_batch)\n    n_batches = len(loader)\n    return total_loss/n_batches, total_mae/n_batches, total_ccc/n_batches\n\n# 7. Training Loop\ndef train_one_epoch(model, loader, optimizer, scheduler, criterion, device):\n    model.train()\n    total_loss = 0\n    for X_batch, y_batch in loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        preds = model(X_batch)\n        loss = criterion(preds, y_batch)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    scheduler.step()\n    return total_loss / len(loader)\n\n# 8. Hyperparameter tuning\ndef generate_random_configs(search_space, num_configs=10):\n    configs = []\n    for _ in range(num_configs):\n        config = {\n            \"embed_dim\": np.random.choice(search_space[\"embed_dim\"]),\n            \"num_heads\": np.random.choice(search_space[\"num_heads\"]),\n            \"num_layers\": np.random.choice(search_space[\"num_layers\"]),\n            \"dropout\": np.random.choice(search_space[\"dropout\"]),\n            \"lr\": np.random.choice(search_space[\"lr\"]),\n            \"batch_size\": np.random.choice(search_space[\"batch_size\"]),\n            \"weight_decay\": np.random.choice(search_space[\"weight_decay\"])\n        }\n        configs.append(config)\n    return configs\n\ndef cross_validate(config, X_tensor, y_tensor, num_folds=3, epochs=10):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n    fold_metrics = {\"val_ccc\": [], \"val_mae\": [], \"val_loss\": []}\n\n    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_tensor)):\n        print(f\"\\n=== Fold {fold+1}/{num_folds} ===\")\n        X_train_fold, y_train_fold = X_tensor[train_idx], y_tensor[train_idx]\n        X_val_fold, y_val_fold = X_tensor[val_idx], y_tensor[val_idx]\n\n        train_loader = DataLoader(AudioDataset(X_train_fold, y_train_fold), batch_size=int(config[\"batch_size\"]), shuffle=True)\n        val_loader = DataLoader(AudioDataset(X_val_fold, y_val_fold), batch_size=int(config[\"batch_size\"]), shuffle=False)\n\n        model = SimpleTransformerRegressor(\n            input_dim=X_tensor.shape[1],\n            embed_dim=config[\"embed_dim\"],\n            num_heads=config[\"num_heads\"],\n            num_layers=config[\"num_layers\"],\n            dropout=config[\"dropout\"]\n        ).to(device)\n\n        optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n        criterion = nn.MSELoss()\n\n        best_ccc = -1\n        for epoch in range(epochs):\n            train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, device)\n            val_loss, val_mae, val_ccc = evaluate(model, val_loader, criterion, device)\n            print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {val_loss:.4f} - Val MAE: {val_mae:.4f} - Val CCC: {val_ccc:.4f}\")\n\n            if val_ccc > best_ccc:\n                best_ccc = val_ccc\n                best_metrics = (val_loss, val_mae, val_ccc)\n\n        fold_metrics[\"val_loss\"].append(best_metrics[0])\n        fold_metrics[\"val_mae\"].append(best_metrics[1])\n        fold_metrics[\"val_ccc\"].append(best_metrics[2])\n\n    return {\n        \"ccc\": np.mean(fold_metrics[\"val_ccc\"]),\n        \"mae\": np.mean(fold_metrics[\"val_mae\"]),\n        \"loss\": np.mean(fold_metrics[\"val_loss\"])\n    }\n\ndef hyperparameter_tuning(X_tensor, y_tensor, num_configs=10):\n    search_space = {\n        \"embed_dim\": [128, 256, 512],\n        \"num_heads\": [2, 4, 8],\n        \"num_layers\": [2, 4],\n        \"dropout\": [0.1, 0.3, 0.5],\n        \"lr\": [1e-4, 3e-4, 1e-3],\n        \"batch_size\": [32, 64],\n        \"weight_decay\": [1e-5, 1e-4]\n    }\n    configs = generate_random_configs(search_space, num_configs)\n    best_config = None\n    best_ccc = -1\n    results = []\n\n    for i, config in enumerate(configs):\n        print(f\"\\n=== Testing Config {i+1}/{len(configs)} ===\")\n        print(config)\n\n        metrics = cross_validate(config, X_tensor, y_tensor)\n        results.append((config, metrics))\n\n        if metrics[\"ccc\"] > best_ccc:\n            best_ccc = metrics[\"ccc\"]\n            best_config = config\n\n        print(f\"Config {i+1} Metrics - CCC: {metrics['ccc']:.4f}, MAE: {metrics['mae']:.4f}, Loss: {metrics['loss']:.4f}\")\n\n    results_df = pd.DataFrame([\n        {\"config\": str(c), **m} for c, m in results\n    ])\n    results_df.to_csv(\"hyperparameter_tuning_audio_hc.csv\", index=False)\n\n    return best_config\n\n# 9. Start hyperparameter tuning\nbest_config = hyperparameter_tuning(X_tensor, y_tensor, num_configs=10)\nprint(\"\\nBest Config Found:\", best_config)\n\n# 10. Final training and evaluation\ndef final_train_and_evaluate(best_config, X_train, y_train, X_val, y_val, X_test, y_test, epochs=30):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    X_final_train = torch.cat([X_train, X_val], dim=0)\n    y_final_train = torch.cat([y_train, y_val], dim=0)\n\n    final_train_loader = DataLoader(AudioDataset(X_final_train, y_final_train), batch_size=int(best_config[\"batch_size\"]), shuffle=True)\n    test_loader = DataLoader(AudioDataset(X_test, y_test), batch_size=int(best_config[\"batch_size\"]), shuffle=False)\n\n    model = SimpleTransformerRegressor(\n        input_dim=X_train.shape[1],\n        embed_dim=best_config[\"embed_dim\"],\n        num_heads=best_config[\"num_heads\"],\n        num_layers=best_config[\"num_layers\"],\n        dropout=best_config[\"dropout\"]\n    ).to(device)\n\n    optimizer = optim.AdamW(model.parameters(), lr=best_config[\"lr\"], weight_decay=best_config[\"weight_decay\"])\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n    criterion = nn.MSELoss()\n\n    for epoch in range(epochs):\n        train_loss = train_one_epoch(model, final_train_loader, optimizer, scheduler, criterion, device)\n        print(f\"Final Train Epoch {epoch+1}/{epochs} - Loss: {train_loss:.4f}\")\n\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for X_batch, y_batch in test_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            preds = model(X_batch)\n            all_preds.append(preds)\n            all_labels.append(y_batch)\n\n    all_preds = torch.cat(all_preds, dim=0)\n    all_labels = torch.cat(all_labels, dim=0)\n\n    final_mae = mean_absolute_error(all_preds, all_labels)\n    final_ccc = concordance_correlation_coefficient(all_preds, all_labels)\n\n    tolerance = 0.1\n    correct = torch.abs(all_preds - all_labels) < tolerance\n    final_accuracy = correct.float().mean().item()\n\n    print(\"\\n==== Final Evaluation on Test Set ====\")\n    print(f\"Final Test CCC: {final_ccc:.4f}\")\n    print(f\"Final Test MAE: {final_mae:.4f}\")\n    print(f\"Final Test Accuracy (within {tolerance}): {final_accuracy*100:.2f}%\")# Save model\n    torch.save(model.state_dict(), \"best_audio_transformer_model.pth\")\n    print(\"\\nModel saved to 'best_audio_transformer_model.pth'.\")\n\nfinal_train_and_evaluate(best_config, X_train, y_train, X_val, y_val, X_test, y_test)\n","metadata":{"id":"7qBzI4nT5Lf8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split, KFold\nimport torch.optim as optim\nfrom sklearn.preprocessing import StandardScaler\n\n# 1. Load dataset\ndf = pd.read_csv('/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/video_hc_features.csv')  # <-- VIDEO HC path\n\n# Drop unnecessary non-numeric columns\ndf = df.select_dtypes(include=[np.number])\n\n# 2. Define features and labels\nlabel_columns = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n\nX = df.drop(columns=label_columns)\ny = df[label_columns]\n\n# Fill missing values if any\nX = X.fillna(X.mean())\ny = y.fillna(y.mean())\n\n# Normalize features\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n# Convert to tensors\nX_tensor = torch.tensor(X.values, dtype=torch.float32)\ny_tensor = torch.tensor(y.values, dtype=torch.float32)\n\n# 3. Train/Val/Test Split\ntrain_idx, temp_idx = train_test_split(range(len(X)), test_size=0.3, random_state=42)\nval_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n\nX_train, y_train = X_tensor[train_idx], y_tensor[train_idx]\nX_val, y_val = X_tensor[val_idx], y_tensor[val_idx]\nX_test, y_test = X_tensor[test_idx], y_tensor[test_idx]\n\n# 4. Dataset and DataLoader\nclass VideoDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\n# 5. Model (Same as before)\nclass SimpleTransformerRegressor(nn.Module):\n    def __init__(self, input_dim, embed_dim=256, num_heads=4, num_layers=2, dropout=0.3):\n        super(SimpleTransformerRegressor, self).__init__()\n        self.project = nn.Linear(input_dim, embed_dim)\n        self.encoder = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout),\n            num_layers=num_layers\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, 128),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(128, 5)\n        )\n\n    def forward(self, x):\n        x = self.project(x)\n        x = x.unsqueeze(0)\n        x = self.encoder(x)\n        x = x.squeeze(0)\n        return self.classifier(x)\n\n# 6–8: Metrics, training functions, and hyperparameter tuning — same as before\n\n# Just rename the dataset used for clarity and the CSV/model output\ndef hyperparameter_tuning(X_tensor, y_tensor, num_configs=10):\n    search_space = {\n        \"embed_dim\": [128, 256, 512],\n        \"num_heads\": [2, 4, 8],\n        \"num_layers\": [2, 4],\n        \"dropout\": [0.1, 0.3, 0.5],\n        \"lr\": [1e-4, 3e-4, 1e-3],\n        \"batch_size\": [32, 64],\n        \"weight_decay\": [1e-5, 1e-4]\n    }\n    configs = generate_random_configs(search_space, num_configs)\n    best_config = None\n    best_ccc = -1\n    results = []\n\n    for i, config in enumerate(configs):\n        print(f\"\\n=== Testing Config {i+1}/{len(configs)} ===\")\n        print(config)\n\n        metrics = cross_validate(config, X_tensor, y_tensor)\n        results.append((config, metrics))\n\n        if metrics[\"ccc\"] > best_ccc:\n            best_ccc = metrics[\"ccc\"]\n            best_config = config\n\n        print(f\"Config {i+1} Metrics - CCC: {metrics['ccc']:.4f}, MAE: {metrics['mae']:.4f}, Loss: {metrics['loss']:.4f}\")\n\n    results_df = pd.DataFrame([\n        {\"config\": str(c), **m} for c, m in results\n    ])\n    results_df.to_csv(\"hyperparameter_tuning_video_hc.csv\", index=False)\n\n    return best_config\n\n# 9. Run tuning\nbest_config = hyperparameter_tuning(X_tensor, y_tensor, num_configs=10)\nprint(\"\\nBest Config Found:\", best_config)\n\n# 10. Final training\ndef final_train_and_evaluate(best_config, X_train, y_train, X_val, y_val, X_test, y_test, epochs=30):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    X_final_train = torch.cat([X_train, X_val], dim=0)\n    y_final_train = torch.cat([y_train, y_val], dim=0)\n\n    final_train_loader = DataLoader(VideoDataset(X_final_train, y_final_train), batch_size=int(best_config[\"batch_size\"]), shuffle=True)\n    test_loader = DataLoader(VideoDataset(X_test, y_test), batch_size=int(best_config[\"batch_size\"]), shuffle=False)\n\n    model = SimpleTransformerRegressor(\n        input_dim=X_train.shape[1],\n        embed_dim=best_config[\"embed_dim\"],\n        num_heads=best_config[\"num_heads\"],\n        num_layers=best_config[\"num_layers\"],\n        dropout=best_config[\"dropout\"]\n    ).to(device)\n\n    optimizer = optim.AdamW(model.parameters(), lr=best_config[\"lr\"], weight_decay=best_config[\"weight_decay\"])\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n    criterion = nn.MSELoss()\n\n    for epoch in range(epochs):\n        train_loss = train_one_epoch(model, final_train_loader, optimizer, scheduler, criterion, device)\n        print(f\"Final Train Epoch {epoch+1}/{epochs} - Loss: {train_loss:.4f}\")\n\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for X_batch, y_batch in test_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            preds = model(X_batch)\n            all_preds.append(preds)\n            all_labels.append(y_batch)\n\n    all_preds = torch.cat(all_preds, dim=0)\n    all_labels = torch.cat(all_labels, dim=0)\n\n    final_mae = mean_absolute_error(all_preds, all_labels)\n    final_ccc = concordance_correlation_coefficient(all_preds, all_labels)\n\n    tolerance = 0.1\n    correct = torch.abs(all_preds - all_labels) < tolerance\n    final_accuracy = correct.float().mean().item()\n\n    print(\"\\n==== Final Evaluation on Test Set ====\")\n    print(f\"Final Test CCC: {final_ccc:.4f}\")\n    print(f\"Final Test MAE: {final_mae:.4f}\")\n    print(f\"Final Test Accuracy (within {tolerance}): {final_accuracy*100:.2f}%\")\n    \n    torch.save(model.state_dict(), \"best_video_transformer_model.pth\")\n    print(\"\\nModel saved to 'best_video_transformer_model.pth'.\")\n\nfinal_train_and_evaluate(best_config, X_train, y_train, X_val, y_val, X_test, y_test)\n","metadata":{"id":"wJiDIVfnar0V","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Imports ---\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport shap # Make sure you have shap installed: pip install shap\nimport os\nimport gc # Garbage collector\nimport time # For timing\nimport traceback # For detailed error printing\n\n# --- Configuration ---\nSEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n    # Note: SHAP might not always be deterministic on GPU even with seeds\n    # torch.backends.cudnn.deterministic = True # Can sometimes cause issues or slow down\n    # torch.backends.cudnn.benchmark = False\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {DEVICE}\")\n\n# --- Paths ---\nORIGINAL_DATA_PATH = '/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/text_hc_features.csv' # Or /kaggle/working/text_hc_features.csv if it's there\n\nNEW_DATA_PATH = '/kaggle/input/fi-v2-hc-dataset-for-shapley/renamed_text_hc_features.csv'\n\nMODEL_SAVE_DIR = '/kaggle/working/'\n\nPLOTS_SAVE_DIR = '/kaggle/working/shap/text/'\n\n# --- Constants ---\nlabel_columns = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n# Columns to drop from BOTH datasets (ensure consistency)\ncols_to_drop = [\"Filename\", \"Segment_ID\", \"interview\", \"Gender\", \"Ethnicity\", \"AgeGroup\"]\n\n# --- SHAP Configuration ---\n# Samples from ORIGINAL training data split for background summary (KMeans)\nSHAP_BACKGROUND_SAMPLES = 100\n# Samples from the NEW data to explain. Reduce if kernel dies (RAM issue).\nSHAP_EXPLAIN_SAMPLES = 100\n# Samples per explanation point for KernelExplainer. More = more accurate but MUCH slower.\nSHAP_KERNEL_NSAMPLES = 100\n\n# --- Ensure Plots Directory Exists ---\nos.makedirs(PLOTS_SAVE_DIR, exist_ok=True)\n\nclass SimpleTransformerRegressor(nn.Module):\n    \"\"\"\n    Simple Transformer Regressor using batch_first=True convention.\n    Takes tabular features, projects them, passes through a Transformer Encoder,\n    and predicts a single regression value.\n    \"\"\"\n    def __init__(self, input_dim, embed_dim=256, num_heads=4, num_layers=2, dropout=0.3, ff_dim_multiplier=4):\n        \"\"\"\n        Args:\n            input_dim (int): Number of input features.\n            embed_dim (int): Dimension for projecting features and for the Transformer. Must be divisible by num_heads.\n            num_heads (int): Number of attention heads in the Transformer.\n            num_layers (int): Number of layers in the Transformer Encoder.\n            dropout (float): Dropout rate.\n            ff_dim_multiplier (int): Multiplier for the feed-forward layer dimension within the Transformer.\n        \"\"\"\n        super(SimpleTransformerRegressor, self).__init__()\n\n        # Ensure embed_dim is divisible by num_heads\n        if embed_dim % num_heads != 0:\n            # Adjust embed_dim up to the nearest multiple of num_heads\n            original_embed_dim = embed_dim\n            embed_dim = (embed_dim // num_heads + 1) * num_heads\n            print(f\"Warning: embed_dim ({original_embed_dim}) not divisible by num_heads ({num_heads}).\")\n            print(f\"Adjusted embed_dim to {embed_dim}.\")\n\n        self.input_dim = input_dim\n        self.embed_dim = embed_dim\n\n        # Project input features to embedding dimension\n        self.project = nn.Linear(input_dim, embed_dim)\n\n        # Define the Transformer Encoder Layer with batch_first=True\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim,\n            nhead=num_heads,\n            dim_feedforward=embed_dim * ff_dim_multiplier, # Standard practice\n            dropout=dropout,\n            batch_first=True  # <<< Input tensor shape: (batch, seq_len, features)\n        )\n\n        # Stack the encoder layers\n        self.encoder = nn.TransformerEncoder(\n            encoder_layer=encoder_layer,\n            num_layers=num_layers\n        )\n\n        # Classifier head\n        self.classifier = nn.Sequential(\n            nn.LayerNorm(embed_dim),      # Add LayerNorm for stability before classifier\n            nn.Linear(embed_dim, 128),    # Linear layer 1\n            nn.ReLU(),                    # Activation\n            nn.Dropout(dropout),          # Dropout\n            nn.Linear(128, 1)             # Final output layer (regression target)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass.\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, input_dim).\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size).\n        \"\"\"\n        # 1. Project features\n        # x shape: (batch_size, input_dim)\n        x = self.project(x)\n        # x shape: (batch_size, embed_dim)\n\n        # 2. Add sequence dimension for Transformer\n        # TransformerEncoderLayer with batch_first=True expects (batch, seq_len, features)\n        x = x.unsqueeze(1)\n        # x shape: (batch_size, seq_len=1, embed_dim)\n\n        # 3. Pass through Transformer Encoder\n        x = self.encoder(x)\n        # x shape: (batch_size, seq_len=1, embed_dim)\n\n        # 4. Remove sequence dimension\n        x = x.squeeze(1)\n        # x shape: (batch_size, embed_dim)\n\n        # 5. Pass through classifier\n        output = self.classifier(x)\n        # output shape: (batch_size, 1)\n\n        # 6. Squeeze final dimension for regression output\n        return output.squeeze(-1)\n        # final shape: (batch_size)\n\n\n\n# --- Step 1 & 2: Get Feature Names ---\nprint(\"Loading feature names...\")\ntry:\n    df_orig_temp = pd.read_csv(ORIGINAL_DATA_PATH)\n    X_orig_temp = df_orig_temp.drop(columns=[col for col in cols_to_drop if col in df_orig_temp.columns], errors='ignore')\n    X_orig_temp = X_orig_temp.drop(columns=[col for col in label_columns if col in X_orig_temp.columns], errors='ignore')\n    original_numeric_feature_order = list(X_orig_temp.columns)\n    num_original_features = len(original_numeric_feature_order)\n    print(f\"Determined original feature order (numeric headers). Count: {num_original_features}\")\n    del df_orig_temp, X_orig_temp\n    gc.collect()\nexcept FileNotFoundError:\n    print(f\"Error: Original dataset file not found at {ORIGINAL_DATA_PATH}. Cannot proceed.\")\n    exit()\nexcept Exception as e:\n    print(f\"Error reading original data file {ORIGINAL_DATA_PATH}: {e}\")\n    exit()\n\ntry:\n    df_new_temp = pd.read_csv(NEW_DATA_PATH)\n    X_new_temp = df_new_temp.drop(columns=[col for col in cols_to_drop if col in df_new_temp.columns], errors='ignore')\n    X_new_temp = X_new_temp.drop(columns=[col for col in label_columns if col in X_new_temp.columns], errors='ignore')\n    descriptive_feature_names = list(X_new_temp.columns)\n    num_new_features = len(descriptive_feature_names)\n    print(f\"Found descriptive feature names in new data. Count: {num_new_features}\")\n    del df_new_temp, X_new_temp\n    gc.collect()\nexcept FileNotFoundError:\n    print(f\"Error: New dataset file not found at {NEW_DATA_PATH}. Cannot proceed.\")\n    exit()\nexcept Exception as e:\n    print(f\"Error reading new data file {NEW_DATA_PATH}: {e}\")\n    exit()\n\n# --- Step 3: Verification ---\nprint(\"Verifying feature count consistency...\")\nif num_original_features != num_new_features:\n    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    print(\"! ERROR: Mismatch in feature counts between original and new data!\")\n    print(f\"! Original data features: {num_original_features}, New data features: {num_new_features}\")\n    print(\"! Cannot proceed. Ensure both CSVs have the same features after dropping metadata/labels.\")\n    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    exit()\nelse:\n    print(\"Feature counts match. Proceeding.\")\ninput_dim = num_original_features\n\n\n# --- Step 4: Load Model Function ---\ndef load_trained_model(trait_name, input_dim, device):\n    \"\"\"Loads a trained model state and configuration.\"\"\"\n    model_path = os.path.join(MODEL_SAVE_DIR, f\"best_text_transformer_model_{trait_name}.pth\")\n    if not os.path.exists(model_path):\n        print(f\"Error: Model file not found for trait '{trait_name}' at {model_path}\")\n        return None, None, None\n    print(f\"Loading checkpoint for {trait_name} from {model_path}...\")\n    try:\n        # Load onto CPU first, explicitly set weights_only=False as checkpoint contains non-tensor data\n        checkpoint = torch.load(model_path, map_location='cpu', weights_only=False) # <<< CRITICAL FIX\n    except Exception as e:\n        print(f\"Error loading checkpoint file {model_path}: {e}\")\n        # Print detailed traceback if loading fails\n        traceback.print_exc()\n        return None, None, None\n\n    required_keys = ['best_config', 'model_state_dict', 'scaler_mean', 'scaler_scale']\n    if not all(key in checkpoint for key in required_keys):\n        missing = [key for key in required if key not in checkpoint]\n        print(f\"Error: Checkpoint for {trait_name} is missing required keys: {missing}.\")\n        return None, None, None\n\n    config = checkpoint['best_config']\n    scaler_mean = np.array(checkpoint['scaler_mean']) # Ensure numpy array\n    scaler_scale = np.array(checkpoint['scaler_scale']) # Ensure numpy array\n\n    required_config_keys = ['embed_dim', 'num_heads', 'num_layers', 'dropout']\n    if not all(key in config for key in required_config_keys):\n        print(f\"Error: Checkpoint config for {trait_name} is missing required model parameters: {required_config_keys}\")\n        return None, None, None\n\n    try:\n        model = SimpleTransformerRegressor(\n            input_dim=input_dim, embed_dim=config[\"embed_dim\"], num_heads=config[\"num_heads\"],\n            num_layers=config[\"num_layers\"], dropout=config[\"dropout\"]\n            # ff_dim_multiplier might not be in older configs, handle potential KeyError or provide default\n            # ff_dim_multiplier=config.get(\"ff_dim_multiplier\", 4) # Example handling\n        )\n        model.load_state_dict(checkpoint['model_state_dict'])\n        model = model.to(device)\n        model.eval()\n        print(f\"Model for {trait_name} loaded successfully.\")\n    except Exception as e:\n        print(f\"Error reconstructing or loading model state for {trait_name}: {e}\")\n        traceback.print_exc() # Print detailed error for state_dict issues\n        return None, None, None\n\n    if scaler_mean.shape[0] != input_dim or scaler_scale.shape[0] != input_dim:\n         print(f\"Error: Loaded scaler params shape mismatch for {trait_name}. Mean: {scaler_mean.shape}, Scale: {scaler_scale.shape}, Expected: {input_dim}\")\n         return None, None, None\n\n    return model, scaler_mean, scaler_scale\n\n\n# --- Step 5: Preprocessing Function for New Data ---\ndef preprocess_explanation_data(df_new, target_feature_order, scaler_mean, scaler_scale):\n    \"\"\"Preprocesses the new dataframe using descriptive feature order and loaded scaler parameters.\"\"\"\n    print(f\"Preprocessing explanation data. Initial shape: {df_new.shape}\")\n    try:\n        df_features = df_new[target_feature_order].copy()\n    except KeyError as e:\n        print(f\"Error: Columns mismatch during preprocessing. Missing: {e}. Ensure NEW data has all descriptive columns.\")\n        return None, None\n    if len(scaler_mean) != len(target_feature_order) or len(scaler_scale) != len(target_feature_order):\n         print(f\"Error: Scaler param length mismatch. Mean: {len(scaler_mean)}, Scale: {len(scaler_scale)}, Features: {len(target_feature_order)}\")\n         return None, None\n\n    original_means_series = pd.Series(scaler_mean, index=target_feature_order)\n    df_features_filled = df_features.fillna(original_means_series)\n\n    if df_features_filled.isnull().sum().sum() > 0:\n        print(f\"Info: Found {df_features_filled.isnull().sum().sum()} NaNs after filling with means. Filling remaining with 0.\")\n        df_features_filled = df_features_filled.fillna(0)\n\n    try:\n        X_new_scaled_values = (df_features_filled.values - scaler_mean) / scaler_scale\n    except ValueError as e:\n        print(f\"Error during scaling: {e}. Check shapes: df values {df_features_filled.values.shape}, mean {scaler_mean.shape}, scale {scaler_scale.shape}\")\n        return None, None\n\n    X_new_tensor = torch.tensor(X_new_scaled_values, dtype=torch.float32)\n    print(f\"Preprocessing complete. Final tensor shape: {X_new_tensor.shape}\")\n    return X_new_tensor, df_features_filled # Return processed df for SHAP labels\n\n\n# --- Step 6: Prepare Background Data (Once before loop) ---\nprint(\"\\nPreparing background data for SHAP...\")\nbackground_data = None # Initialize\ntry:\n    # Load scaler params from one representative model (e.g., openness)\n    _, bg_scaler_mean, bg_scaler_scale = load_trained_model(label_columns[0], input_dim, DEVICE)\n    if bg_scaler_mean is None or bg_scaler_scale is None:\n        raise ValueError(f\"Failed to load scaler parameters from {label_columns[0]} model checkpoint.\")\n\n    df_orig_background = pd.read_csv(ORIGINAL_DATA_PATH)\n    X_orig_background = df_orig_background.drop(columns=[col for col in cols_to_drop if col in df_orig_background.columns], errors='ignore')\n    X_orig_background = X_orig_background.drop(columns=[col for col in label_columns if col in X_orig_background.columns], errors='ignore')\n    X_orig_background = X_orig_background[original_numeric_feature_order] # Use numeric order\n\n    orig_means_series_bg = pd.Series(bg_scaler_mean, index=original_numeric_feature_order)\n    X_orig_background_filled = X_orig_background.fillna(orig_means_series_bg)\n    if X_orig_background_filled.isnull().sum().sum() > 0:\n        print(f\"Info: Found {X_orig_background_filled.isnull().sum().sum()} NaNs in background data after filling with means. Filling remaining with 0.\")\n        X_orig_background_filled = X_orig_background_filled.fillna(0)\n\n    X_orig_background_scaled = (X_orig_background_filled.values - bg_scaler_mean) / bg_scaler_scale\n    X_orig_background_tensor = torch.tensor(X_orig_background_scaled, dtype=torch.float32)\n\n    train_indices, _ = train_test_split(range(len(X_orig_background_tensor)), test_size=0.3, random_state=SEED)\n    X_train_orig_tensor = X_orig_background_tensor[train_indices]\n\n    num_background_available = X_train_orig_tensor.shape[0]\n    actual_background_samples = min(SHAP_BACKGROUND_SAMPLES, num_background_available)\n    if actual_background_samples < SHAP_BACKGROUND_SAMPLES:\n        print(f\"Warning: Requested {SHAP_BACKGROUND_SAMPLES} background samples, but only {num_background_available} available. Using {actual_background_samples}.\")\n\n    background_indices = np.random.choice(num_background_available, actual_background_samples, replace=False)\n    # Keep background data on CPU for potential numpy operations (like kmeans)\n    background_data_cpu = X_train_orig_tensor[background_indices].cpu() # Store on CPU\n    print(f\"Background data prepared. Shape: {background_data_cpu.shape}\")\n\n    del df_orig_background, X_orig_background, X_orig_background_filled, X_orig_background_scaled\n    del X_orig_background_tensor, X_train_orig_tensor, bg_scaler_mean, bg_scaler_scale\n    gc.collect()\n\nexcept FileNotFoundError:\n    print(f\"Error: Original dataset file not found at {ORIGINAL_DATA_PATH}. Cannot prepare background data.\")\n    exit()\nexcept Exception as e:\n    print(f\"FATAL ERROR during background data preparation: {e}\")\n    traceback.print_exc()\n    exit()\n\n\n# --- Step 7: Load Explanation Data (Once before loop) ---\nprint(f\"\\n--- Loading Explanation Data from {NEW_DATA_PATH} ---\")\ntry:\n    df_explain_full = pd.read_csv(NEW_DATA_PATH)\n    print(f\"Loaded explanation dataset. Full shape: {df_explain_full.shape}\")\nexcept FileNotFoundError:\n    print(f\"Error: Explanation dataset file not found at {NEW_DATA_PATH}. Cannot proceed.\")\n    exit()\nexcept Exception as e:\n    print(f\"Error reading explanation dataset {NEW_DATA_PATH}: {e}\")\n    exit()\n\n# --- Step 8: SHAP Analysis Loop ---\nprint(f\"\\n--- Starting SHAP Analysis Loop (Using KernelExplainer) ---\")\nif background_data_cpu is None:\n     print(\"FATAL ERROR: Background data was not prepared successfully. Stopping.\")\n     exit()\n\nfor trait in label_columns:\n    print(f\"\\n--- Processing Trait: {trait.upper()} ---\")\n    trait_start_time = time.time()\n    # Initialize variables for cleanup in finally block\n    model = None\n    scaler_mean = None\n    scaler_scale = None\n    X_explain_tensor = None\n    df_explain_processed = None\n    df_explain_sample = None\n    explainer = None\n    shap_values = None\n    X_explain_numpy = None\n    background_summary = None\n\n    try:\n        # 1. Load Model and Scaler for the current trait\n        model, scaler_mean, scaler_scale = load_trained_model(trait, input_dim, DEVICE)\n        if model is None:\n            print(f\"Skipping trait {trait} due to model loading issues.\")\n            continue\n\n        # 2. Sample and Preprocess Explanation Data for this trait\n        num_explain_available = len(df_explain_full)\n        actual_explain_samples = min(SHAP_EXPLAIN_SAMPLES, num_explain_available)\n        if actual_explain_samples < num_explain_available:\n             print(f\"Sampling {actual_explain_samples} rows from explanation data for analysis.\")\n             df_explain_sample = df_explain_full.sample(n=actual_explain_samples, random_state=SEED)\n        else:\n             print(f\"Using all {num_explain_available} rows from explanation data.\")\n             df_explain_sample = df_explain_full\n\n        X_explain_tensor, df_explain_processed = preprocess_explanation_data(\n            df_explain_sample.copy(), descriptive_feature_names, scaler_mean, scaler_scale\n        )\n        if X_explain_tensor is None:\n            print(f\"Skipping trait {trait} due to preprocessing errors.\")\n            continue\n\n        # 3. Initialize SHAP KernelExplainer\n        print(\"Initializing SHAP KernelExplainer...\")\n        kernel_explainer_start_time = time.time()\n\n        # Define prediction wrapper (takes numpy, returns numpy)\n        def predict_wrapper_numpy(x_np):\n            x_tensor = torch.tensor(x_np, dtype=torch.float32).to(DEVICE)\n            with torch.no_grad():\n                predictions = model(x_tensor)\n            return predictions.cpu().numpy()\n\n        # Summarize background data\n        print(f\"Summarizing background data ({background_data_cpu.shape[0]} samples) using k-means...\")\n        num_clusters = min(25, background_data_cpu.shape[0]) # Adjust cluster count if needed\n        background_data_np = background_data_cpu.numpy() # Convert background tensor (CPU) to numpy\n        background_summary = shap.kmeans(background_data_np, num_clusters) # Run kmeans\n\n        # --- DEBUG INSPECTION of kmeans output ---\n        print(f\"DEBUG: Type of background_summary: {type(background_summary)}\")\n        print(f\"DEBUG: Attributes of background_summary: {dir(background_summary)}\")\n        num_means = 0\n        summary_data_valid = False\n        if hasattr(background_summary, 'data') and isinstance(background_summary.data, np.ndarray):\n            num_means = background_summary.data.shape[0]\n            print(f\"DEBUG: background_summary.data found. Shape: {background_summary.data.shape}\")\n            print(f\"Background data summarized to {num_means} means.\")\n            summary_data_valid = True\n        else:\n            print(\"DEBUG: background_summary.data attribute not found or not a numpy array.\")\n        # --- END DEBUG INSPECTION ---\n\n        # Proceed only if summary data seems valid\n        if summary_data_valid:\n            # Initialize Explainer - Pass the summary object directly\n            explainer = shap.KernelExplainer(predict_wrapper_numpy, background_summary)\n\n            # 4. Calculate SHAP values\n            X_explain_numpy = X_explain_tensor.cpu().numpy() # Use CPU numpy data for explanation\n            print(f\"Calculating SHAP values using KernelExplainer for {X_explain_numpy.shape[0]} samples (nsamples={SHAP_KERNEL_NSAMPLES})... BE PATIENT!\")\n            shap_values = explainer.shap_values(X_explain_numpy, nsamples=SHAP_KERNEL_NSAMPLES)\n            print(f\"SHAP values calculated. Shape: {np.shape(shap_values)}\") # Use np.shape for robustness\n            kernel_explainer_time = time.time() - kernel_explainer_start_time\n            print(f\"KernelExplainer calculation took {kernel_explainer_time:.2f} seconds.\")\n\n            # 5. Generate and Save Summary Plot\n            print(\"Generating SHAP summary plot...\")\n            plt.figure(figsize=(10, 8)) # Adjust figure size if needed\n            shap.summary_plot(\n                shap_values,\n                features=df_explain_processed, # Use processed df for values\n                feature_names=descriptive_feature_names, # Use descriptive names for labels\n                max_display=20, # Show top N features\n                show=False\n            )\n            plt.title(f'SHAP Summary Plot ({trait.capitalize()}) - Text Features')\n            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n            plot_filename = os.path.join(PLOTS_SAVE_DIR, f'shap_summary_kernel_{trait}.png')\n            plt.savefig(plot_filename, dpi=150, bbox_inches='tight')\n            plt.close() # Close figure to free memory\n            print(f\"SHAP summary plot saved to {plot_filename}\")\n\n        else:\n            # Handle case where summary data was invalid\n            print(\"ERROR: Could not validate structure of shap.kmeans output from debug info.\")\n            print(\"Cannot proceed with KernelExplainer initialization or SHAP value calculation.\")\n            # No need to raise error here, loop will continue to finally block\n\n    except Exception as e:\n        print(f\"ERROR during SHAP processing for trait {trait}: {e}\")\n        print(\"--- Traceback ---\")\n        traceback.print_exc()\n        print(\"--- End Traceback ---\")\n        print(f\"Skipping plot generation for {trait} due to error.\")\n\n    finally:\n        # 6. Clean up memory for the next trait\n        print(f\"Cleaning up memory after trait {trait}...\")\n        # Use 'in locals()' or 'in globals()' to check before deleting\n        # Check for None as well, as variables might be assigned None on error\n        if 'model' in locals() and model is not None: del model\n        if 'scaler_mean' in locals() and scaler_mean is not None: del scaler_mean\n        if 'scaler_scale' in locals() and scaler_scale is not None: del scaler_scale\n        if 'X_explain_tensor' in locals() and X_explain_tensor is not None: del X_explain_tensor\n        if 'df_explain_processed' in locals() and df_explain_processed is not None: del df_explain_processed\n        if 'df_explain_sample' in locals() and df_explain_sample is not None: del df_explain_sample\n        if 'explainer' in locals() and explainer is not None: del explainer\n        if 'shap_values' in locals() and shap_values is not None: del shap_values\n        if 'X_explain_numpy' in locals() and X_explain_numpy is not None: del X_explain_numpy\n        if 'background_summary' in locals() and background_summary is not None: del background_summary\n        # Note: background_data_cpu is kept for the next loop's kmeans\n\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n    trait_time = time.time() - trait_start_time\n    print(f\"Finished processing {trait}. Total time: {trait_time:.2f}s\")\n\n\nprint(\"\\n--- SHAP Analysis Complete ---\")\nprint(f\"Plots saved in: {PLOTS_SAVE_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:51.345871Z","iopub.execute_input":"2025-05-07T16:00:51.346053Z","iopub.status.idle":"2025-05-07T16:02:18.060463Z","shell.execute_reply.started":"2025-05-07T16:00:51.346037Z","shell.execute_reply":"2025-05-07T16:02:18.059621Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading feature names...\nDetermined original feature order (numeric headers). Count: 128\nFound descriptive feature names in new data. Count: 128\nVerifying feature count consistency...\nFeature counts match. Proceeding.\n\nPreparing background data for SHAP...\nLoading checkpoint for openness from /kaggle/working/best_text_transformer_model_openness.pth...\nModel for openness loaded successfully.\nBackground data prepared. Shape: torch.Size([100, 128])\n\n--- Loading Explanation Data from /kaggle/input/fi-v2-hc-dataset-for-shapley/renamed_text_hc_features.csv ---\nLoaded explanation dataset. Full shape: (10000, 138)\n\n--- Starting SHAP Analysis Loop (Using KernelExplainer) ---\n\n--- Processing Trait: OPENNESS ---\nLoading checkpoint for openness from /kaggle/working/best_text_transformer_model_openness.pth...\nModel for openness loaded successfully.\nSampling 100 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (100, 138)\nPreprocessing complete. Final tensor shape: torch.Size([100, 128])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nDEBUG: Type of background_summary: <class 'shap.utils._legacy.DenseData'>\nDEBUG: Attributes of background_summary: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'group_names', 'groups', 'groups_size', 'transposed', 'weights']\nDEBUG: background_summary.data found. Shape: (25, 128)\nBackground data summarized to 25 means.\nCalculating SHAP values using KernelExplainer for 100 samples (nsamples=100)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"919e03d397fa4b8ea5bc0afabfa95772"}},"metadata":{}},{"name":"stdout","text":"SHAP values calculated. Shape: (100, 128)\nKernelExplainer calculation took 16.19 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/text/shap_summary_kernel_openness.png\nCleaning up memory after trait openness...\nFinished processing openness. Total time: 17.13s\n\n--- Processing Trait: CONSCIENTIOUSNESS ---\nLoading checkpoint for conscientiousness from /kaggle/working/best_text_transformer_model_conscientiousness.pth...\nModel for conscientiousness loaded successfully.\nSampling 100 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (100, 138)\nPreprocessing complete. Final tensor shape: torch.Size([100, 128])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nDEBUG: Type of background_summary: <class 'shap.utils._legacy.DenseData'>\nDEBUG: Attributes of background_summary: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'group_names', 'groups', 'groups_size', 'transposed', 'weights']\nDEBUG: background_summary.data found. Shape: (25, 128)\nBackground data summarized to 25 means.\nCalculating SHAP values using KernelExplainer for 100 samples (nsamples=100)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91cf3646529940e6b0b66a4a85c37b98"}},"metadata":{}},{"name":"stderr","text":"Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.644e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\nRegressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.678e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\nRegressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.855e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\nEarly stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 38 iterations, alpha=1.789e-04, previous alpha=1.751e-04, with an active set of 27 regressors.\n","output_type":"stream"},{"name":"stdout","text":"SHAP values calculated. Shape: (100, 128)\nKernelExplainer calculation took 16.27 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/text/shap_summary_kernel_conscientiousness.png\nCleaning up memory after trait conscientiousness...\nFinished processing conscientiousness. Total time: 17.29s\n\n--- Processing Trait: EXTRAVERSION ---\nLoading checkpoint for extraversion from /kaggle/working/best_text_transformer_model_extraversion.pth...\nModel for extraversion loaded successfully.\nSampling 100 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (100, 138)\nPreprocessing complete. Final tensor shape: torch.Size([100, 128])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nDEBUG: Type of background_summary: <class 'shap.utils._legacy.DenseData'>\nDEBUG: Attributes of background_summary: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'group_names', 'groups', 'groups_size', 'transposed', 'weights']\nDEBUG: background_summary.data found. Shape: (25, 128)\nBackground data summarized to 25 means.\nCalculating SHAP values using KernelExplainer for 100 samples (nsamples=100)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9386ae8419ea4bf48bc4ad9e28850a17"}},"metadata":{}},{"name":"stdout","text":"SHAP values calculated. Shape: (100, 128)\nKernelExplainer calculation took 16.07 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/text/shap_summary_kernel_extraversion.png\nCleaning up memory after trait extraversion...\nFinished processing extraversion. Total time: 17.08s\n\n--- Processing Trait: AGREEABLENESS ---\nLoading checkpoint for agreeableness from /kaggle/working/best_text_transformer_model_agreeableness.pth...\nModel for agreeableness loaded successfully.\nSampling 100 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (100, 138)\nPreprocessing complete. Final tensor shape: torch.Size([100, 128])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nDEBUG: Type of background_summary: <class 'shap.utils._legacy.DenseData'>\nDEBUG: Attributes of background_summary: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'group_names', 'groups', 'groups_size', 'transposed', 'weights']\nDEBUG: background_summary.data found. Shape: (25, 128)\nBackground data summarized to 25 means.\nCalculating SHAP values using KernelExplainer for 100 samples (nsamples=100)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b73a70e1574fc7a672a813746ba389"}},"metadata":{}},{"name":"stdout","text":"SHAP values calculated. Shape: (100, 128)\nKernelExplainer calculation took 16.19 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/text/shap_summary_kernel_agreeableness.png\nCleaning up memory after trait agreeableness...\nFinished processing agreeableness. Total time: 17.17s\n\n--- Processing Trait: NEUROTICISM ---\nLoading checkpoint for neuroticism from /kaggle/working/best_text_transformer_model_neuroticism.pth...\nModel for neuroticism loaded successfully.\nSampling 100 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (100, 138)\nPreprocessing complete. Final tensor shape: torch.Size([100, 128])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nDEBUG: Type of background_summary: <class 'shap.utils._legacy.DenseData'>\nDEBUG: Attributes of background_summary: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'group_names', 'groups', 'groups_size', 'transposed', 'weights']\nDEBUG: background_summary.data found. Shape: (25, 128)\nBackground data summarized to 25 means.\nCalculating SHAP values using KernelExplainer for 100 samples (nsamples=100)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a602dca539c4e5eac1027fe4fa90039"}},"metadata":{}},{"name":"stdout","text":"SHAP values calculated. Shape: (100, 128)\nKernelExplainer calculation took 15.86 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/text/shap_summary_kernel_neuroticism.png\nCleaning up memory after trait neuroticism...\nFinished processing neuroticism. Total time: 16.84s\n\n--- SHAP Analysis Complete ---\nPlots saved in: /kaggle/working/shap/text/\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# --- Imports ---\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport shap # Make sure you have shap installed: pip install shap\nimport os\nimport gc # Garbage collector\nimport time # For timing\nimport traceback # For detailed error printing\n\n# --- Configuration ---\nSEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {DEVICE}\")\n\n# --- Paths ---\n\nORIGINAL_DATA_PATH = '/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/video_hc_features.csv'\n\nNEW_DATA_PATH = '/kaggle/input/fi-v2-hc-dataset-for-shapley/renamed_video_hc_features.csv' # e.g., /kaggle/input/my-shap-video-data/renamed_video_hc_features.csv\n\nMODEL_SAVE_DIR = '/kaggle/working/'\n\nPLOTS_SAVE_DIR = '/kaggle/working/shap/video/'\n\n# --- Constants ---\nlabel_columns = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n\ncols_to_drop = [\"Filename\", \"Segment_ID\", \"interview\", \"Gender\", \"Ethnicity\", \"AgeGroup\"]\n\n# --- SHAP Configuration ---\n# Samples from ORIGINAL training data split for background summary (KMeans)\nSHAP_BACKGROUND_SAMPLES = 100\n# Samples from the NEW data to explain. Reduce if kernel dies (RAM issue).\nSHAP_EXPLAIN_SAMPLES = 50\n# Samples per explanation point for KernelExplainer. More = more accurate but MUCH slower.\nSHAP_KERNEL_NSAMPLES = 1000\n\n# --- Ensure Plots Directory Exists ---\nos.makedirs(PLOTS_SAVE_DIR, exist_ok=True)\n\n# --- Model Definition (Must be IDENTICAL to your training script) ---\nclass SimpleTransformerRegressor(nn.Module):\n    def __init__(self, input_dim, embed_dim=256, num_heads=4, num_layers=2, dropout=0.3, ff_dim_multiplier=4):\n        super(SimpleTransformerRegressor, self).__init__()\n        if embed_dim % num_heads != 0:\n            original_embed_dim = embed_dim\n            embed_dim = (embed_dim // num_heads + 1) * num_heads\n            # print(f\"Warning: embed_dim ({original_embed_dim}) not divisible by num_heads ({num_heads}). Adjusted to {embed_dim}.\")\n        self.input_dim = input_dim\n        self.embed_dim = embed_dim\n        self.project = nn.Linear(input_dim, embed_dim)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim, nhead=num_heads,\n            dim_feedforward=embed_dim * ff_dim_multiplier,\n            dropout=dropout, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=num_layers)\n        self.classifier = nn.Sequential(\n            nn.LayerNorm(embed_dim),\n            nn.Linear(embed_dim, 128), nn.ReLU(),\n            nn.Dropout(dropout), nn.Linear(128, 1)\n        )\n    def forward(self, x):\n        x = self.project(x)\n        x = x.unsqueeze(1)\n        x = self.encoder(x)\n        x = x.squeeze(1)\n        output = self.classifier(x)\n        return output.squeeze(-1)\n\n# --- Step 1 & 2: Get Feature Names ---\nprint(\"Loading feature names...\")\ntry:\n    df_orig_temp = pd.read_csv(ORIGINAL_DATA_PATH)\n    X_orig_temp = df_orig_temp.drop(columns=[col for col in cols_to_drop if col in df_orig_temp.columns], errors='ignore')\n    X_orig_temp = X_orig_temp.drop(columns=[col for col in label_columns if col in X_orig_temp.columns], errors='ignore')\n    # Ensure only numeric columns are considered features for order determination\n    X_orig_temp = X_orig_temp.select_dtypes(include=np.number)\n    original_numeric_feature_order = list(X_orig_temp.columns)\n    num_original_features = len(original_numeric_feature_order)\n    print(f\"Determined original feature order (numeric headers from {os.path.basename(ORIGINAL_DATA_PATH)}). Count: {num_original_features}\")\n    del df_orig_temp, X_orig_temp\n    gc.collect()\nexcept FileNotFoundError:\n    print(f\"Error: Original dataset file not found at {ORIGINAL_DATA_PATH}. Cannot proceed.\")\n    exit()\nexcept Exception as e:\n    print(f\"Error reading original data file {ORIGINAL_DATA_PATH}: {e}\")\n    traceback.print_exc()\n    exit()\n\ntry:\n    df_new_temp = pd.read_csv(NEW_DATA_PATH)\n    X_new_temp = df_new_temp.drop(columns=[col for col in cols_to_drop if col in df_new_temp.columns], errors='ignore')\n    X_new_temp = X_new_temp.drop(columns=[col for col in label_columns if col in X_new_temp.columns], errors='ignore')\n    # Ensure only numeric columns are considered features for descriptive names\n    X_new_temp = X_new_temp.select_dtypes(include=np.number)\n    descriptive_feature_names = list(X_new_temp.columns)\n    num_new_features = len(descriptive_feature_names)\n    print(f\"Found descriptive feature names in new data ({os.path.basename(NEW_DATA_PATH)}). Count: {num_new_features}\")\n    del df_new_temp, X_new_temp\n    gc.collect()\nexcept FileNotFoundError:\n    print(f\"Error: New dataset file not found at {NEW_DATA_PATH}.\")\n    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    print(\"!!! PLEASE UPDATE THE 'NEW_DATA_PATH' variable in the script to point  !!!\")\n    print(\"!!! to your CSV file containing descriptive video feature names.       !!!\")\n    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    exit()\nexcept Exception as e:\n    print(f\"Error reading new data file {NEW_DATA_PATH}: {e}\")\n    traceback.print_exc()\n    exit()\n\n# --- Step 3: Verification ---\nprint(\"Verifying feature count consistency...\")\nif num_original_features != num_new_features:\n    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    print(\"! ERROR: Mismatch in feature counts between original and new data!\")\n    print(f\"! Original data ({os.path.basename(ORIGINAL_DATA_PATH)}) features: {num_original_features}\")\n    print(f\"! New data ({os.path.basename(NEW_DATA_PATH)}) features: {num_new_features}\")\n    print(\"! Cannot proceed. Ensure both CSVs have the same number of numeric feature columns\")\n    print(\"! after dropping metadata/labels, and that NEW_DATA_PATH is correct.\")\n    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    exit()\nelse:\n    print(f\"Feature counts match ({num_original_features}). Proceeding.\")\ninput_dim = num_original_features\n\n\n# --- Step 4: Load Model Function ---\ndef load_trained_model(trait_name, input_dim_model, device):\n    \"\"\"Loads a trained model state and configuration for VIDEO features.\"\"\"\n    model_path = os.path.join(MODEL_SAVE_DIR, f\"best_video_transformer_model_{trait_name}.pth\") # VIDEO model name\n    if not os.path.exists(model_path):\n        print(f\"Error: Model file not found for trait '{trait_name}' at {model_path}\")\n        return None, None, None\n    print(f\"Loading checkpoint for {trait_name} from {model_path}...\")\n    try:\n        checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)\n    except Exception as e:\n        print(f\"Error loading checkpoint file {model_path}: {e}\")\n        traceback.print_exc()\n        return None, None, None\n\n    required_keys = ['best_config', 'model_state_dict', 'scaler_mean', 'scaler_scale']\n    if not all(key in checkpoint for key in required_keys):\n        missing = [key for key in required_keys if key not in checkpoint]\n        print(f\"Error: Checkpoint for {trait_name} is missing required keys: {missing}.\")\n        return None, None, None\n\n    config = checkpoint['best_config']\n    # Ensure scaler params are numpy arrays and float type for consistency\n    scaler_mean = np.array(checkpoint['scaler_mean'], dtype=np.float64)\n    scaler_scale = np.array(checkpoint['scaler_scale'], dtype=np.float64)\n\n\n    # The ff_dim_multiplier should be handled by the model's default if not in config\n    # as SimpleTransformerRegressor has a default for it.\n    try:\n        model = SimpleTransformerRegressor(\n            input_dim=input_dim_model, # Use the input_dim derived from original data\n            embed_dim=config[\"embed_dim\"],\n            num_heads=config[\"num_heads\"],\n            num_layers=config[\"num_layers\"],\n            dropout=config[\"dropout\"],\n            ff_dim_multiplier=config.get(\"ff_dim_multiplier\", 4) # Use config if available, else default\n        )\n        model.load_state_dict(checkpoint['model_state_dict'])\n        model = model.to(device)\n        model.eval()\n        print(f\"Model for {trait_name} loaded successfully.\")\n    except Exception as e:\n        print(f\"Error reconstructing or loading model state for {trait_name}: {e}\")\n        traceback.print_exc()\n        return None, None, None\n\n    if scaler_mean.shape[0] != input_dim_model or scaler_scale.shape[0] != input_dim_model:\n         print(f\"Error: Loaded scaler params shape mismatch for {trait_name}. Mean: {scaler_mean.shape}, Scale: {scaler_scale.shape}, Expected from data: {input_dim_model}\")\n         return None, None, None\n\n    return model, scaler_mean, scaler_scale\n\n\n# --- Step 5: Preprocessing Function for New Data ---\ndef preprocess_explanation_data(df_new, target_feature_order_desc, scaler_mean_arr, scaler_scale_arr):\n    \"\"\"Preprocesses the new dataframe using descriptive feature order and loaded scaler parameters.\"\"\"\n    print(f\"Preprocessing explanation data. Initial shape: {df_new.shape}\")\n    try:\n        # Select only numeric columns that are in target_feature_order_desc\n        df_features_numeric = df_new.select_dtypes(include=np.number)\n        df_features = df_features_numeric[target_feature_order_desc].copy()\n    except KeyError as e:\n        missing_cols = [col for col in target_feature_order_desc if col not in df_features_numeric.columns]\n        print(f\"Error: Columns mismatch during preprocessing. Missing in new data: {missing_cols}. Ensure NEW data has all descriptive columns.\")\n        return None, None\n\n    if len(scaler_mean_arr) != len(target_feature_order_desc) or len(scaler_scale_arr) != len(target_feature_order_desc):\n         print(f\"Error: Scaler param length mismatch. Mean: {len(scaler_mean_arr)}, Scale: {len(scaler_scale_arr)}, Features: {len(target_feature_order_desc)}\")\n         return None, None\n\n    # Fill NaNs: The i-th mean in scaler_mean_arr (from original data) corresponds to the i-th feature in target_feature_order_desc\n    # This assumes the order of features in NEW_DATA_PATH columns matches the conceptual order of features in ORIGINAL_DATA_PATH\n    means_for_filling = pd.Series(scaler_mean_arr, index=target_feature_order_desc)\n    df_features_filled = df_features.fillna(means_for_filling)\n\n    # Handle any remaining NaNs (e.g., if a feature was all NaN in original data, its mean might be NaN)\n    if df_features_filled.isnull().sum().sum() > 0:\n        print(f\"Info: Found {df_features_filled.isnull().sum().sum()} NaNs after filling with original means. Filling remaining with 0 (global column mean might be better if available).\")\n        df_features_filled = df_features_filled.fillna(0) # Fallback\n\n    try:\n        # Scale: Apply scaler_mean_arr and scaler_scale_arr directly.\n        # This relies on df_features_filled.values being in the same order as target_feature_order_desc,\n        # and scaler_mean_arr/scaler_scale_arr also corresponding to this order.\n        X_new_scaled_values = (df_features_filled.values - scaler_mean_arr) / scaler_scale_arr\n    except ValueError as e:\n        print(f\"Error during scaling: {e}. Check shapes: df values {df_features_filled.values.shape}, mean {scaler_mean_arr.shape}, scale {scaler_scale_arr.shape}\")\n        return None, None\n\n    X_new_tensor = torch.tensor(X_new_scaled_values, dtype=torch.float32)\n    print(f\"Preprocessing complete. Final tensor shape for explanation: {X_new_tensor.shape}\")\n    return X_new_tensor, df_features_filled # Return processed df for SHAP labels\n\n\n# --- Step 6: Prepare Background Data (Once before loop) ---\nprint(\"\\nPreparing background data for SHAP...\")\nbackground_data_cpu_scaled_np = None # Initialize\ntry:\n    # Load scaler params from one representative model (e.g., openness)\n    _, bg_scaler_mean, bg_scaler_scale = load_trained_model(label_columns[0], input_dim, DEVICE)\n    if bg_scaler_mean is None or bg_scaler_scale is None:\n        raise ValueError(f\"Failed to load scaler parameters from {label_columns[0]} model checkpoint for background data.\")\n\n    df_orig_background = pd.read_csv(ORIGINAL_DATA_PATH)\n    X_orig_background_temp = df_orig_background.drop(columns=[col for col in cols_to_drop if col in df_orig_background.columns], errors='ignore')\n    X_orig_background_temp = X_orig_background_temp.drop(columns=[col for col in label_columns if col in X_orig_background_temp.columns], errors='ignore')\n    \n    # Select only numeric types and ensure order matches original_numeric_feature_order\n    X_orig_background_numeric = X_orig_background_temp.select_dtypes(include=np.number)\n    X_orig_background = X_orig_background_numeric[original_numeric_feature_order].copy() # Enforce original order\n\n\n    # Fill NaNs using the loaded scaler means (which are in original_numeric_feature_order)\n    orig_means_series_bg = pd.Series(bg_scaler_mean, index=original_numeric_feature_order)\n    X_orig_background_filled = X_orig_background.fillna(orig_means_series_bg)\n    if X_orig_background_filled.isnull().sum().sum() > 0:\n        print(f\"Info: Found {X_orig_background_filled.isnull().sum().sum()} NaNs in background data after filling with means. Filling remaining with 0.\")\n        X_orig_background_filled = X_orig_background_filled.fillna(0)\n\n    # Scale using the loaded scaler parameters\n    X_orig_background_scaled_np = (X_orig_background_filled.values - bg_scaler_mean) / bg_scaler_scale\n    \n    # We need a subset of the *training* part of this original data for background\n    # Your original training script used a 0.3 test_size, then 0.5 for val from temp.\n    # So, train is 0.7 of total.\n    # Let's roughly simulate a training split for background.\n    train_indices_bg, _ = train_test_split(range(len(X_orig_background_scaled_np)), train_size=0.7, random_state=SEED)\n    X_train_orig_scaled_np = X_orig_background_scaled_np[train_indices_bg]\n\n    num_background_available = X_train_orig_scaled_np.shape[0]\n    actual_background_samples = min(SHAP_BACKGROUND_SAMPLES, num_background_available)\n    if actual_background_samples < SHAP_BACKGROUND_SAMPLES:\n        print(f\"Warning: Requested {SHAP_BACKGROUND_SAMPLES} background samples, but only {num_background_available} available in train split. Using {actual_background_samples}.\")\n    if actual_background_samples == 0:\n        raise ValueError(\"No background samples available after splitting. Check data or split logic.\")\n\n    background_indices = np.random.choice(num_background_available, actual_background_samples, replace=False)\n    background_data_cpu_scaled_np = X_train_orig_scaled_np[background_indices] # This is already scaled and numpy\n    print(f\"Background data prepared (scaled, numpy). Shape: {background_data_cpu_scaled_np.shape}\")\n\n    del df_orig_background, X_orig_background_temp, X_orig_background_numeric, X_orig_background, X_orig_background_filled\n    del X_orig_background_scaled_np, X_train_orig_scaled_np, bg_scaler_mean, bg_scaler_scale\n    gc.collect()\n\nexcept FileNotFoundError:\n    print(f\"Error: Original dataset file not found at {ORIGINAL_DATA_PATH}. Cannot prepare background data.\")\n    exit()\nexcept Exception as e:\n    print(f\"FATAL ERROR during background data preparation: {e}\")\n    traceback.print_exc()\n    exit()\n\n\n# --- Step 7: Load Explanation Data (Once before loop) ---\nprint(f\"\\n--- Loading Explanation Data from {NEW_DATA_PATH} ---\")\ntry:\n    df_explain_full = pd.read_csv(NEW_DATA_PATH)\n    print(f\"Loaded explanation dataset. Full shape: {df_explain_full.shape}\")\nexcept FileNotFoundError:\n    print(f\"Error: Explanation dataset file not found at {NEW_DATA_PATH}. Cannot proceed.\")\n    print(\"Please ensure 'NEW_DATA_PATH' is correctly set.\")\n    exit()\nexcept Exception as e:\n    print(f\"Error reading explanation dataset {NEW_DATA_PATH}: {e}\")\n    exit()\n\n# --- Step 8: SHAP Analysis Loop ---\nprint(f\"\\n--- Starting SHAP Analysis Loop (Using KernelExplainer) ---\")\nif background_data_cpu_scaled_np is None:\n     print(\"FATAL ERROR: Background data was not prepared successfully. Stopping.\")\n     exit()\n\nfor trait in label_columns:\n    print(f\"\\n--- Processing Trait: {trait.upper()} ---\")\n    trait_start_time = time.time()\n    model, scaler_mean_trait, scaler_scale_trait = None, None, None\n    X_explain_tensor, df_explain_processed, df_explain_sample = None, None, None\n    explainer, shap_values, background_summary_obj = None, None, None\n    X_explain_numpy_scaled = None\n\n    try:\n        # 1. Load Model and Scaler for the current trait\n        model, scaler_mean_trait, scaler_scale_trait = load_trained_model(trait, input_dim, DEVICE)\n        if model is None:\n            print(f\"Skipping trait {trait} due to model loading issues.\")\n            continue\n\n        # 2. Sample and Preprocess Explanation Data for this trait\n        num_explain_available = len(df_explain_full)\n        actual_explain_samples = min(SHAP_EXPLAIN_SAMPLES, num_explain_available)\n        if actual_explain_samples < num_explain_available:\n             print(f\"Sampling {actual_explain_samples} rows from explanation data for analysis.\")\n             df_explain_sample = df_explain_full.sample(n=actual_explain_samples, random_state=SEED)\n        else:\n             print(f\"Using all {num_explain_available} rows from explanation data.\")\n             df_explain_sample = df_explain_full.copy() # Use a copy to avoid modifying original df_explain_full\n\n        # Preprocess using descriptive_feature_names and the loaded scaler specific to this trait\n        X_explain_tensor, df_explain_processed = preprocess_explanation_data(\n            df_explain_sample, descriptive_feature_names, scaler_mean_trait, scaler_scale_trait\n        )\n        if X_explain_tensor is None:\n            print(f\"Skipping trait {trait} due to preprocessing errors for explanation data.\")\n            continue\n        X_explain_numpy_scaled = X_explain_tensor.cpu().numpy() # This is the SCALED data for explanation\n\n        # 3. Initialize SHAP KernelExplainer\n        print(\"Initializing SHAP KernelExplainer...\")\n        kernel_explainer_start_time = time.time()\n\n        def predict_wrapper_numpy(x_np_scaled): # Expects SCALED numpy data\n            x_tensor = torch.tensor(x_np_scaled, dtype=torch.float32).to(DEVICE)\n            with torch.no_grad():\n                predictions = model(x_tensor)\n            return predictions.cpu().numpy()\n\n        print(f\"Summarizing background data ({background_data_cpu_scaled_np.shape[0]} samples) using k-means...\")\n        num_clusters = min(25, background_data_cpu_scaled_np.shape[0])\n        if num_clusters < 1: # Edge case: very few background samples\n            print(f\"Warning: Not enough background samples ({background_data_cpu_scaled_np.shape[0]}) for k-means with min clusters. Using raw background.\")\n            background_summary_obj = background_data_cpu_scaled_np # Use raw if too few for kmeans\n        else:\n            background_summary_obj = shap.kmeans(background_data_cpu_scaled_np, num_clusters)\n        \n        print(f\"Type of background_summary_obj: {type(background_summary_obj)}\")\n        # The object returned by shap.kmeans is directly usable. If it's just a numpy array (e.g. raw background), that's also fine.\n\n        explainer = shap.KernelExplainer(predict_wrapper_numpy, background_summary_obj)\n\n        # 4. Calculate SHAP values\n        print(f\"Calculating SHAP values using KernelExplainer for {X_explain_numpy_scaled.shape[0]} samples (nsamples={SHAP_KERNEL_NSAMPLES})... BE PATIENT!\")\n        shap_values = explainer.shap_values(X_explain_numpy_scaled, nsamples=SHAP_KERNEL_NSAMPLES)\n        # For single output regression, shap_values is (N, M)\n        print(f\"SHAP values calculated. Shape: {np.shape(shap_values)}\")\n        kernel_explainer_time = time.time() - kernel_explainer_start_time\n        print(f\"KernelExplainer calculation took {kernel_explainer_time:.2f} seconds.\")\n\n        # 5. Generate and Save Summary Plot\n        print(\"Generating SHAP summary plot...\")\n        plt.figure() # Create new figure for each plot\n        shap.summary_plot(\n            shap_values,\n            features=df_explain_processed, # This DataFrame has descriptive column names and values corresponding to X_explain_numpy_scaled\n            feature_names=descriptive_feature_names, # Explicitly provide descriptive names\n            max_display=20,\n            show=False\n        )\n        plt.title(f'SHAP Summary Plot ({trait.capitalize()}) - Video Features')\n        plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout\n        plot_filename = os.path.join(PLOTS_SAVE_DIR, f'shap_summary_kernel_video_{trait}.png')\n        plt.savefig(plot_filename, dpi=150, bbox_inches='tight')\n        plt.close()\n        print(f\"SHAP summary plot saved to {plot_filename}\")\n\n    except Exception as e:\n        print(f\"ERROR during SHAP processing for trait {trait}: {e}\")\n        print(\"--- Traceback ---\")\n        traceback.print_exc()\n        print(\"--- End Traceback ---\")\n        print(f\"Skipping plot generation for {trait} due to error.\")\n\n    finally:\n        print(f\"Cleaning up memory after trait {trait}...\")\n        del model, scaler_mean_trait, scaler_scale_trait\n        del X_explain_tensor, df_explain_processed, df_explain_sample\n        del explainer, shap_values, X_explain_numpy_scaled, background_summary_obj\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n    trait_time = time.time() - trait_start_time\n    print(f\"Finished processing {trait}. Total time: {trait_time:.2f}s\")\n\nprint(\"\\n--- SHAP Analysis Complete for Video Features ---\")\nprint(f\"Plots saved in: {PLOTS_SAVE_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:55:57.007027Z","iopub.execute_input":"2025-05-06T12:55:57.007875Z","iopub.status.idle":"2025-05-06T13:03:46.993262Z","shell.execute_reply.started":"2025-05-06T12:55:57.007839Z","shell.execute_reply":"2025-05-06T13:03:46.992607Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading feature names...\n","output_type":"stream"},{"name":"stderr","text":"Columns (0,944) have mixed types. Specify dtype option on import or set low_memory=False.\n","output_type":"stream"},{"name":"stdout","text":"Determined original feature order (numeric headers from video_hc_features.csv). Count: 936\n","output_type":"stream"},{"name":"stderr","text":"Columns (0,944) have mixed types. Specify dtype option on import or set low_memory=False.\n","output_type":"stream"},{"name":"stdout","text":"Found descriptive feature names in new data (renamed_video_hc_features.csv). Count: 936\nVerifying feature count consistency...\nFeature counts match (936). Proceeding.\n\nPreparing background data for SHAP...\nLoading checkpoint for openness from /kaggle/working/best_video_transformer_model_openness.pth...\nModel for openness loaded successfully.\n","output_type":"stream"},{"name":"stderr","text":"Columns (0,944) have mixed types. Specify dtype option on import or set low_memory=False.\n","output_type":"stream"},{"name":"stdout","text":"Background data prepared (scaled, numpy). Shape: (100, 936)\n\n--- Loading Explanation Data from /kaggle/input/fi-v2-hc-dataset-for-shapley/renamed_video_hc_features.csv ---\n","output_type":"stream"},{"name":"stderr","text":"Columns (0,944) have mixed types. Specify dtype option on import or set low_memory=False.\n","output_type":"stream"},{"name":"stdout","text":"Loaded explanation dataset. Full shape: (51325, 948)\n\n--- Starting SHAP Analysis Loop (Using KernelExplainer) ---\n\n--- Processing Trait: OPENNESS ---\nLoading checkpoint for openness from /kaggle/working/best_video_transformer_model_openness.pth...\nModel for openness loaded successfully.\nSampling 50 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (50, 948)\nPreprocessing complete. Final tensor shape for explanation: torch.Size([50, 936])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nType of background_summary_obj: <class 'shap.utils._legacy.DenseData'>\nCalculating SHAP values using KernelExplainer for 50 samples (nsamples=1000)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cec3e22706964bfda757120e08dd2364"}},"metadata":{}},{"name":"stdout","text":"SHAP values calculated. Shape: (50, 936)\nKernelExplainer calculation took 83.73 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/video/shap_summary_kernel_video_openness.png\nCleaning up memory after trait openness...\nFinished processing openness. Total time: 84.82s\n\n--- Processing Trait: CONSCIENTIOUSNESS ---\nLoading checkpoint for conscientiousness from /kaggle/working/best_video_transformer_model_conscientiousness.pth...\nModel for conscientiousness loaded successfully.\nSampling 50 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (50, 948)\nPreprocessing complete. Final tensor shape for explanation: torch.Size([50, 936])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nType of background_summary_obj: <class 'shap.utils._legacy.DenseData'>\nCalculating SHAP values using KernelExplainer for 50 samples (nsamples=1000)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c74842d38f9462a9ab1961baf61c1f1"}},"metadata":{}},{"name":"stdout","text":"SHAP values calculated. Shape: (50, 936)\nKernelExplainer calculation took 83.58 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/video/shap_summary_kernel_video_extraversion.png\nCleaning up memory after trait extraversion...\nFinished processing extraversion. Total time: 84.72s\n\n--- Processing Trait: AGREEABLENESS ---\nLoading checkpoint for agreeableness from /kaggle/working/best_video_transformer_model_agreeableness.pth...\nModel for agreeableness loaded successfully.\nSampling 50 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (50, 948)\nPreprocessing complete. Final tensor shape for explanation: torch.Size([50, 936])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nType of background_summary_obj: <class 'shap.utils._legacy.DenseData'>\nCalculating SHAP values using KernelExplainer for 50 samples (nsamples=1000)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85a73ceff6df49a991405a06910ed5cd"}},"metadata":{}},{"name":"stdout","text":"SHAP values calculated. Shape: (50, 936)\nKernelExplainer calculation took 83.88 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/video/shap_summary_kernel_video_agreeableness.png\nCleaning up memory after trait agreeableness...\nFinished processing agreeableness. Total time: 85.03s\n\n--- Processing Trait: NEUROTICISM ---\nLoading checkpoint for neuroticism from /kaggle/working/best_video_transformer_model_neuroticism.pth...\nModel for neuroticism loaded successfully.\nSampling 50 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (50, 948)\nPreprocessing complete. Final tensor shape for explanation: torch.Size([50, 936])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nType of background_summary_obj: <class 'shap.utils._legacy.DenseData'>\nCalculating SHAP values using KernelExplainer for 50 samples (nsamples=1000)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd3a491761184c9c8309c342a0b14cc0"}},"metadata":{}},{"name":"stdout","text":"SHAP values calculated. Shape: (50, 936)\nKernelExplainer calculation took 87.23 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/video/shap_summary_kernel_video_neuroticism.png\nCleaning up memory after trait neuroticism...\nFinished processing neuroticism. Total time: 88.34s\n\n--- SHAP Analysis Complete for Video Features ---\nPlots saved in: /kaggle/working/shap/video/\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# --- Imports ---\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport shap # Make sure you have shap installed: pip install shap\nimport os\nimport gc # Garbage collector\nimport time # For timing\nimport traceback # For detailed error printing\n\n# --- Configuration ---\nSEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {DEVICE}\")\n\n# --- Paths ---\nORIGINAL_DATA_PATH = '/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/audio_hc_features.csv'\n\nNEW_DATA_PATH = '/kaggle/input/fi-v2-hc-dataset-for-shapley/renamed_audio_hc_features.csv'\n\nMODEL_SAVE_DIR = '/kaggle/working/'\n\nPLOTS_SAVE_DIR = '/kaggle/working/shap/audio/'\n\n# --- Constants ---\nlabel_columns = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n\ncols_to_drop = [\"Filename\", \"Segment_ID\", \"interview\", \"Gender\", \"Ethnicity\", \"AgeGroup\"]\n\n# --- SHAP Configuration ---\n# Samples from ORIGINAL training data split for background summary (KMeans)\nSHAP_BACKGROUND_SAMPLES = 100\n# Samples from the NEW data to explain. Reduce if kernel dies (RAM issue).\nSHAP_EXPLAIN_SAMPLES = 50\n# Samples per explanation point for KernelExplainer. More = more accurate but MUCH slower.\nSHAP_KERNEL_NSAMPLES = 50\n\n# --- Ensure Plots Directory Exists ---\nos.makedirs(PLOTS_SAVE_DIR, exist_ok=True)\n\n# --- Model Definition (Must be IDENTICAL to your training script) ---\nclass SimpleTransformerRegressor(nn.Module):\n    def __init__(self, input_dim, embed_dim=256, num_heads=4, num_layers=2, dropout=0.3, ff_dim_multiplier=4):\n        super(SimpleTransformerRegressor, self).__init__()\n        if embed_dim % num_heads != 0:\n            original_embed_dim = embed_dim\n            embed_dim = (embed_dim // num_heads + 1) * num_heads\n            # print(f\"Warning: embed_dim ({original_embed_dim}) not divisible by num_heads ({num_heads}). Adjusted to {embed_dim}.\")\n        self.input_dim = input_dim\n        self.embed_dim = embed_dim\n        self.project = nn.Linear(input_dim, embed_dim)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim, nhead=num_heads,\n            dim_feedforward=embed_dim * ff_dim_multiplier,\n            dropout=dropout, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=num_layers)\n        self.classifier = nn.Sequential(\n            nn.LayerNorm(embed_dim),\n            nn.Linear(embed_dim, 128), nn.ReLU(),\n            nn.Dropout(dropout), nn.Linear(128, 1)\n        )\n    def forward(self, x):\n        x = self.project(x)\n        x = x.unsqueeze(1)\n        x = self.encoder(x)\n        x = x.squeeze(1)\n        output = self.classifier(x)\n        return output.squeeze(-1)\n\n# --- Step 1 & 2: Get Feature Names ---\nprint(\"Loading feature names...\")\ntry:\n    df_orig_temp = pd.read_csv(ORIGINAL_DATA_PATH)\n    X_orig_temp = df_orig_temp.drop(columns=[col for col in cols_to_drop if col in df_orig_temp.columns], errors='ignore')\n    X_orig_temp = X_orig_temp.drop(columns=[col for col in label_columns if col in X_orig_temp.columns], errors='ignore')\n    # Ensure only numeric columns are considered features for order determination\n    X_orig_temp = X_orig_temp.select_dtypes(include=np.number)\n    original_numeric_feature_order = list(X_orig_temp.columns)\n    num_original_features = len(original_numeric_feature_order)\n    print(f\"Determined original feature order (numeric headers from {os.path.basename(ORIGINAL_DATA_PATH)}). Count: {num_original_features}\")\n    del df_orig_temp, X_orig_temp\n    gc.collect()\nexcept FileNotFoundError:\n    print(f\"Error: Original dataset file not found at {ORIGINAL_DATA_PATH}. Cannot proceed.\")\n    exit()\nexcept Exception as e:\n    print(f\"Error reading original data file {ORIGINAL_DATA_PATH}: {e}\")\n    traceback.print_exc()\n    exit()\n\ntry:\n    df_new_temp = pd.read_csv(NEW_DATA_PATH)\n    X_new_temp = df_new_temp.drop(columns=[col for col in cols_to_drop if col in df_new_temp.columns], errors='ignore')\n    X_new_temp = X_new_temp.drop(columns=[col for col in label_columns if col in X_new_temp.columns], errors='ignore')\n    # Ensure only numeric columns are considered features for descriptive names\n    X_new_temp = X_new_temp.select_dtypes(include=np.number)\n    descriptive_feature_names = list(X_new_temp.columns)\n    num_new_features = len(descriptive_feature_names)\n    print(f\"Found descriptive feature names in new data ({os.path.basename(NEW_DATA_PATH)}). Count: {num_new_features}\")\n    del df_new_temp, X_new_temp\n    gc.collect()\nexcept FileNotFoundError:\n    print(f\"Error: New dataset file not found at {NEW_DATA_PATH}.\")\n    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    print(\"!!! PLEASE UPDATE THE 'NEW_DATA_PATH' variable in the script to point  !!!\")\n    print(\"!!! to your CSV file containing descriptive video feature names.       !!!\")\n    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    exit()\nexcept Exception as e:\n    print(f\"Error reading new data file {NEW_DATA_PATH}: {e}\")\n    traceback.print_exc()\n    exit()\n\n# --- Step 3: Verification ---\nprint(\"Verifying feature count consistency...\")\nif num_original_features != num_new_features:\n    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    print(\"! ERROR: Mismatch in feature counts between original and new data!\")\n    print(f\"! Original data ({os.path.basename(ORIGINAL_DATA_PATH)}) features: {num_original_features}\")\n    print(f\"! New data ({os.path.basename(NEW_DATA_PATH)}) features: {num_new_features}\")\n    print(\"! Cannot proceed. Ensure both CSVs have the same number of numeric feature columns\")\n    print(\"! after dropping metadata/labels, and that NEW_DATA_PATH is correct.\")\n    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    exit()\nelse:\n    print(f\"Feature counts match ({num_original_features}). Proceeding.\")\ninput_dim = num_original_features\n\n\n# --- Step 4: Load Model Function ---\ndef load_trained_model(trait_name, input_dim_model, device):\n    \"\"\"Loads a trained model state and configuration for VIDEO features.\"\"\"\n    model_path = os.path.join(MODEL_SAVE_DIR, f\"best_audio_transformer_model_{trait_name}.pth\") # VIDEO model name\n    if not os.path.exists(model_path):\n        print(f\"Error: Model file not found for trait '{trait_name}' at {model_path}\")\n        return None, None, None\n    print(f\"Loading checkpoint for {trait_name} from {model_path}...\")\n    try:\n        checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)\n    except Exception as e:\n        print(f\"Error loading checkpoint file {model_path}: {e}\")\n        traceback.print_exc()\n        return None, None, None\n\n    required_keys = ['best_config', 'model_state_dict', 'scaler_mean', 'scaler_scale']\n    if not all(key in checkpoint for key in required_keys):\n        missing = [key for key in required_keys if key not in checkpoint]\n        print(f\"Error: Checkpoint for {trait_name} is missing required keys: {missing}.\")\n        return None, None, None\n\n    config = checkpoint['best_config']\n    # Ensure scaler params are numpy arrays and float type for consistency\n    scaler_mean = np.array(checkpoint['scaler_mean'], dtype=np.float64)\n    scaler_scale = np.array(checkpoint['scaler_scale'], dtype=np.float64)\n\n\n    # The ff_dim_multiplier should be handled by the model's default if not in config\n    # as SimpleTransformerRegressor has a default for it.\n    try:\n        model = SimpleTransformerRegressor(\n            input_dim=input_dim_model, # Use the input_dim derived from original data\n            embed_dim=config[\"embed_dim\"],\n            num_heads=config[\"num_heads\"],\n            num_layers=config[\"num_layers\"],\n            dropout=config[\"dropout\"],\n            ff_dim_multiplier=config.get(\"ff_dim_multiplier\", 4) # Use config if available, else default\n        )\n        model.load_state_dict(checkpoint['model_state_dict'])\n        model = model.to(device)\n        model.eval()\n        print(f\"Model for {trait_name} loaded successfully.\")\n    except Exception as e:\n        print(f\"Error reconstructing or loading model state for {trait_name}: {e}\")\n        traceback.print_exc()\n        return None, None, None\n\n    if scaler_mean.shape[0] != input_dim_model or scaler_scale.shape[0] != input_dim_model:\n         print(f\"Error: Loaded scaler params shape mismatch for {trait_name}. Mean: {scaler_mean.shape}, Scale: {scaler_scale.shape}, Expected from data: {input_dim_model}\")\n         return None, None, None\n\n    return model, scaler_mean, scaler_scale\n\n\n# --- Step 5: Preprocessing Function for New Data ---\ndef preprocess_explanation_data(df_new, target_feature_order_desc, scaler_mean_arr, scaler_scale_arr):\n    \"\"\"Preprocesses the new dataframe using descriptive feature order and loaded scaler parameters.\"\"\"\n    print(f\"Preprocessing explanation data. Initial shape: {df_new.shape}\")\n    try:\n        # Select only numeric columns that are in target_feature_order_desc\n        df_features_numeric = df_new.select_dtypes(include=np.number)\n        df_features = df_features_numeric[target_feature_order_desc].copy()\n    except KeyError as e:\n        missing_cols = [col for col in target_feature_order_desc if col not in df_features_numeric.columns]\n        print(f\"Error: Columns mismatch during preprocessing. Missing in new data: {missing_cols}. Ensure NEW data has all descriptive columns.\")\n        return None, None\n\n    if len(scaler_mean_arr) != len(target_feature_order_desc) or len(scaler_scale_arr) != len(target_feature_order_desc):\n         print(f\"Error: Scaler param length mismatch. Mean: {len(scaler_mean_arr)}, Scale: {len(scaler_scale_arr)}, Features: {len(target_feature_order_desc)}\")\n         return None, None\n\n    # Fill NaNs: The i-th mean in scaler_mean_arr (from original data) corresponds to the i-th feature in target_feature_order_desc\n    # This assumes the order of features in NEW_DATA_PATH columns matches the conceptual order of features in ORIGINAL_DATA_PATH\n    means_for_filling = pd.Series(scaler_mean_arr, index=target_feature_order_desc)\n    df_features_filled = df_features.fillna(means_for_filling)\n\n    # Handle any remaining NaNs (e.g., if a feature was all NaN in original data, its mean might be NaN)\n    if df_features_filled.isnull().sum().sum() > 0:\n        print(f\"Info: Found {df_features_filled.isnull().sum().sum()} NaNs after filling with original means. Filling remaining with 0 (global column mean might be better if available).\")\n        df_features_filled = df_features_filled.fillna(0) # Fallback\n\n    try:\n        # Scale: Apply scaler_mean_arr and scaler_scale_arr directly.\n        # This relies on df_features_filled.values being in the same order as target_feature_order_desc,\n        # and scaler_mean_arr/scaler_scale_arr also corresponding to this order.\n        X_new_scaled_values = (df_features_filled.values - scaler_mean_arr) / scaler_scale_arr\n    except ValueError as e:\n        print(f\"Error during scaling: {e}. Check shapes: df values {df_features_filled.values.shape}, mean {scaler_mean_arr.shape}, scale {scaler_scale_arr.shape}\")\n        return None, None\n\n    X_new_tensor = torch.tensor(X_new_scaled_values, dtype=torch.float32)\n    print(f\"Preprocessing complete. Final tensor shape for explanation: {X_new_tensor.shape}\")\n    return X_new_tensor, df_features_filled # Return processed df for SHAP labels\n\n\n# --- Step 6: Prepare Background Data (Once before loop) ---\nprint(\"\\nPreparing background data for SHAP...\")\nbackground_data_cpu_scaled_np = None # Initialize\ntry:\n    # Load scaler params from one representative model (e.g., openness)\n    _, bg_scaler_mean, bg_scaler_scale = load_trained_model(label_columns[0], input_dim, DEVICE)\n    if bg_scaler_mean is None or bg_scaler_scale is None:\n        raise ValueError(f\"Failed to load scaler parameters from {label_columns[0]} model checkpoint for background data.\")\n\n    df_orig_background = pd.read_csv(ORIGINAL_DATA_PATH)\n    X_orig_background_temp = df_orig_background.drop(columns=[col for col in cols_to_drop if col in df_orig_background.columns], errors='ignore')\n    X_orig_background_temp = X_orig_background_temp.drop(columns=[col for col in label_columns if col in X_orig_background_temp.columns], errors='ignore')\n    \n    # Select only numeric types and ensure order matches original_numeric_feature_order\n    X_orig_background_numeric = X_orig_background_temp.select_dtypes(include=np.number)\n    X_orig_background = X_orig_background_numeric[original_numeric_feature_order].copy() # Enforce original order\n\n\n    # Fill NaNs using the loaded scaler means (which are in original_numeric_feature_order)\n    orig_means_series_bg = pd.Series(bg_scaler_mean, index=original_numeric_feature_order)\n    X_orig_background_filled = X_orig_background.fillna(orig_means_series_bg)\n    if X_orig_background_filled.isnull().sum().sum() > 0:\n        print(f\"Info: Found {X_orig_background_filled.isnull().sum().sum()} NaNs in background data after filling with means. Filling remaining with 0.\")\n        X_orig_background_filled = X_orig_background_filled.fillna(0)\n\n    # Scale using the loaded scaler parameters\n    X_orig_background_scaled_np = (X_orig_background_filled.values - bg_scaler_mean) / bg_scaler_scale\n    \n    # We need a subset of the *training* part of this original data for background\n    # Your original training script used a 0.3 test_size, then 0.5 for val from temp.\n    # So, train is 0.7 of total.\n    # Let's roughly simulate a training split for background.\n    train_indices_bg, _ = train_test_split(range(len(X_orig_background_scaled_np)), train_size=0.7, random_state=SEED)\n    X_train_orig_scaled_np = X_orig_background_scaled_np[train_indices_bg]\n\n    num_background_available = X_train_orig_scaled_np.shape[0]\n    actual_background_samples = min(SHAP_BACKGROUND_SAMPLES, num_background_available)\n    if actual_background_samples < SHAP_BACKGROUND_SAMPLES:\n        print(f\"Warning: Requested {SHAP_BACKGROUND_SAMPLES} background samples, but only {num_background_available} available in train split. Using {actual_background_samples}.\")\n    if actual_background_samples == 0:\n        raise ValueError(\"No background samples available after splitting. Check data or split logic.\")\n\n    background_indices = np.random.choice(num_background_available, actual_background_samples, replace=False)\n    background_data_cpu_scaled_np = X_train_orig_scaled_np[background_indices] # This is already scaled and numpy\n    print(f\"Background data prepared (scaled, numpy). Shape: {background_data_cpu_scaled_np.shape}\")\n\n    del df_orig_background, X_orig_background_temp, X_orig_background_numeric, X_orig_background, X_orig_background_filled\n    del X_orig_background_scaled_np, X_train_orig_scaled_np, bg_scaler_mean, bg_scaler_scale\n    gc.collect()\n\nexcept FileNotFoundError:\n    print(f\"Error: Original dataset file not found at {ORIGINAL_DATA_PATH}. Cannot prepare background data.\")\n    exit()\nexcept Exception as e:\n    print(f\"FATAL ERROR during background data preparation: {e}\")\n    traceback.print_exc()\n    exit()\n\n\n# --- Step 7: Load Explanation Data (Once before loop) ---\nprint(f\"\\n--- Loading Explanation Data from {NEW_DATA_PATH} ---\")\ntry:\n    df_explain_full = pd.read_csv(NEW_DATA_PATH)\n    print(f\"Loaded explanation dataset. Full shape: {df_explain_full.shape}\")\nexcept FileNotFoundError:\n    print(f\"Error: Explanation dataset file not found at {NEW_DATA_PATH}. Cannot proceed.\")\n    print(\"Please ensure 'NEW_DATA_PATH' is correctly set.\")\n    exit()\nexcept Exception as e:\n    print(f\"Error reading explanation dataset {NEW_DATA_PATH}: {e}\")\n    exit()\n\n# --- Step 8: SHAP Analysis Loop ---\nprint(f\"\\n--- Starting SHAP Analysis Loop (Using KernelExplainer) ---\")\nif background_data_cpu_scaled_np is None:\n     print(\"FATAL ERROR: Background data was not prepared successfully. Stopping.\")\n     exit()\n\nfor trait in label_columns:\n    print(f\"\\n--- Processing Trait: {trait.upper()} ---\")\n    trait_start_time = time.time()\n    model, scaler_mean_trait, scaler_scale_trait = None, None, None\n    X_explain_tensor, df_explain_processed, df_explain_sample = None, None, None\n    explainer, shap_values, background_summary_obj = None, None, None\n    X_explain_numpy_scaled = None\n\n    try:\n        # 1. Load Model and Scaler for the current trait\n        model, scaler_mean_trait, scaler_scale_trait = load_trained_model(trait, input_dim, DEVICE)\n        if model is None:\n            print(f\"Skipping trait {trait} due to model loading issues.\")\n            continue\n\n        # 2. Sample and Preprocess Explanation Data for this trait\n        num_explain_available = len(df_explain_full)\n        actual_explain_samples = min(SHAP_EXPLAIN_SAMPLES, num_explain_available)\n        if actual_explain_samples < num_explain_available:\n             print(f\"Sampling {actual_explain_samples} rows from explanation data for analysis.\")\n             df_explain_sample = df_explain_full.sample(n=actual_explain_samples, random_state=SEED)\n        else:\n             print(f\"Using all {num_explain_available} rows from explanation data.\")\n             df_explain_sample = df_explain_full.copy() # Use a copy to avoid modifying original df_explain_full\n\n        # Preprocess using descriptive_feature_names and the loaded scaler specific to this trait\n        X_explain_tensor, df_explain_processed = preprocess_explanation_data(\n            df_explain_sample, descriptive_feature_names, scaler_mean_trait, scaler_scale_trait\n        )\n        if X_explain_tensor is None:\n            print(f\"Skipping trait {trait} due to preprocessing errors for explanation data.\")\n            continue\n        X_explain_numpy_scaled = X_explain_tensor.cpu().numpy() # This is the SCALED data for explanation\n\n        # 3. Initialize SHAP KernelExplainer\n        print(\"Initializing SHAP KernelExplainer...\")\n        kernel_explainer_start_time = time.time()\n\n        def predict_wrapper_numpy(x_np_scaled): # Expects SCALED numpy data\n            x_tensor = torch.tensor(x_np_scaled, dtype=torch.float32).to(DEVICE)\n            with torch.no_grad():\n                predictions = model(x_tensor)\n            return predictions.cpu().numpy()\n\n        print(f\"Summarizing background data ({background_data_cpu_scaled_np.shape[0]} samples) using k-means...\")\n        num_clusters = min(25, background_data_cpu_scaled_np.shape[0])\n        if num_clusters < 1: # Edge case: very few background samples\n            print(f\"Warning: Not enough background samples ({background_data_cpu_scaled_np.shape[0]}) for k-means with min clusters. Using raw background.\")\n            background_summary_obj = background_data_cpu_scaled_np # Use raw if too few for kmeans\n        else:\n            background_summary_obj = shap.kmeans(background_data_cpu_scaled_np, num_clusters)\n        \n        print(f\"Type of background_summary_obj: {type(background_summary_obj)}\")\n        # The object returned by shap.kmeans is directly usable. If it's just a numpy array (e.g. raw background), that's also fine.\n\n        explainer = shap.KernelExplainer(predict_wrapper_numpy, background_summary_obj)\n\n        # 4. Calculate SHAP values\n        print(f\"Calculating SHAP values using KernelExplainer for {X_explain_numpy_scaled.shape[0]} samples (nsamples={SHAP_KERNEL_NSAMPLES})... BE PATIENT!\")\n        shap_values = explainer.shap_values(X_explain_numpy_scaled, nsamples=SHAP_KERNEL_NSAMPLES)\n        # For single output regression, shap_values is (N, M)\n        print(f\"SHAP values calculated. Shape: {np.shape(shap_values)}\")\n        kernel_explainer_time = time.time() - kernel_explainer_start_time\n        print(f\"KernelExplainer calculation took {kernel_explainer_time:.2f} seconds.\")\n\n        # 5. Generate and Save Summary Plot\n        print(\"Generating SHAP summary plot...\")\n        plt.figure() # Create new figure for each plot\n        shap.summary_plot(\n            shap_values,\n            features=df_explain_processed, # This DataFrame has descriptive column names and values corresponding to X_explain_numpy_scaled\n            feature_names=descriptive_feature_names, # Explicitly provide descriptive names\n            max_display=20,\n            show=False\n        )\n        plt.title(f'SHAP Summary Plot ({trait.capitalize()}) - Audio Features')\n        plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout\n        plot_filename = os.path.join(PLOTS_SAVE_DIR, f'shap_summary_kernel_audio_{trait}.png')\n        plt.savefig(plot_filename, dpi=150, bbox_inches='tight')\n        plt.close()\n        print(f\"SHAP summary plot saved to {plot_filename}\")\n\n    except Exception as e:\n        print(f\"ERROR during SHAP processing for trait {trait}: {e}\")\n        print(\"--- Traceback ---\")\n        traceback.print_exc()\n        print(\"--- End Traceback ---\")\n        print(f\"Skipping plot generation for {trait} due to error.\")\n\n    finally:\n        print(f\"Cleaning up memory after trait {trait}...\")\n        del model, scaler_mean_trait, scaler_scale_trait\n        del X_explain_tensor, df_explain_processed, df_explain_sample\n        del explainer, shap_values, X_explain_numpy_scaled, background_summary_obj\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n    trait_time = time.time() - trait_start_time\n    print(f\"Finished processing {trait}. Total time: {trait_time:.2f}s\")\n\nprint(\"\\n--- SHAP Analysis Complete for Video Features ---\")\nprint(f\"Plots saved in: {PLOTS_SAVE_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:35.718128Z","iopub.execute_input":"2025-05-07T16:00:35.718432Z","iopub.status.idle":"2025-05-07T16:00:51.342383Z","shell.execute_reply.started":"2025-05-07T16:00:35.718411Z","shell.execute_reply":"2025-05-07T16:00:51.341615Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading feature names...\n","output_type":"stream"},{"name":"stderr","text":"Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n","output_type":"stream"},{"name":"stdout","text":"Determined original feature order (numeric headers from audio_hc_features.csv). Count: 25\n","output_type":"stream"},{"name":"stderr","text":"Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n","output_type":"stream"},{"name":"stdout","text":"Found descriptive feature names in new data (renamed_audio_hc_features.csv). Count: 25\nVerifying feature count consistency...\nFeature counts match (25). Proceeding.\n\nPreparing background data for SHAP...\nLoading checkpoint for openness from /kaggle/working/best_audio_transformer_model_openness.pth...\nModel for openness loaded successfully.\n","output_type":"stream"},{"name":"stderr","text":"Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n","output_type":"stream"},{"name":"stdout","text":"Background data prepared (scaled, numpy). Shape: (100, 25)\n\n--- Loading Explanation Data from /kaggle/input/fi-v2-hc-dataset-for-shapley/renamed_audio_hc_features.csv ---\n","output_type":"stream"},{"name":"stderr","text":"Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n","output_type":"stream"},{"name":"stdout","text":"Loaded explanation dataset. Full shape: (57949, 37)\n\n--- Starting SHAP Analysis Loop (Using KernelExplainer) ---\n\n--- Processing Trait: OPENNESS ---\nLoading checkpoint for openness from /kaggle/working/best_audio_transformer_model_openness.pth...\nModel for openness loaded successfully.\nSampling 50 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (50, 37)\nPreprocessing complete. Final tensor shape for explanation: torch.Size([50, 25])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nType of background_summary_obj: <class 'shap.utils._legacy.DenseData'>\nCalculating SHAP values using KernelExplainer for 50 samples (nsamples=50)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d42a866ea396425c8e8e3d785820f9d2"}},"metadata":{}},{"name":"stdout","text":"SHAP values calculated. Shape: (50, 25)\nKernelExplainer calculation took 1.81 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/audio/shap_summary_kernel_audio_openness.png\nCleaning up memory after trait openness...\nFinished processing openness. Total time: 2.83s\n\n--- Processing Trait: CONSCIENTIOUSNESS ---\nLoading checkpoint for conscientiousness from /kaggle/working/best_audio_transformer_model_conscientiousness.pth...\nModel for conscientiousness loaded successfully.\nSampling 50 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (50, 37)\nPreprocessing complete. Final tensor shape for explanation: torch.Size([50, 25])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nType of background_summary_obj: <class 'shap.utils._legacy.DenseData'>\nCalculating SHAP values using KernelExplainer for 50 samples (nsamples=50)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8a8257c63b34ac5a148fc0b47be6da4"}},"metadata":{}},{"name":"stdout","text":"SHAP values calculated. Shape: (50, 25)\nKernelExplainer calculation took 1.71 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/audio/shap_summary_kernel_audio_conscientiousness.png\nCleaning up memory after trait conscientiousness...\nFinished processing conscientiousness. Total time: 2.69s\n\n--- Processing Trait: EXTRAVERSION ---\nLoading checkpoint for extraversion from /kaggle/working/best_audio_transformer_model_extraversion.pth...\nModel for extraversion loaded successfully.\nSampling 50 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (50, 37)\nPreprocessing complete. Final tensor shape for explanation: torch.Size([50, 25])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nType of background_summary_obj: <class 'shap.utils._legacy.DenseData'>\nCalculating SHAP values using KernelExplainer for 50 samples (nsamples=50)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"300f9ff415c341d8bf403a5ae7c05a8f"}},"metadata":{}},{"name":"stdout","text":"SHAP values calculated. Shape: (50, 25)\nKernelExplainer calculation took 1.56 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/audio/shap_summary_kernel_audio_extraversion.png\nCleaning up memory after trait extraversion...\nFinished processing extraversion. Total time: 2.46s\n\n--- Processing Trait: AGREEABLENESS ---\nLoading checkpoint for agreeableness from /kaggle/working/best_audio_transformer_model_agreeableness.pth...\nModel for agreeableness loaded successfully.\nSampling 50 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (50, 37)\nPreprocessing complete. Final tensor shape for explanation: torch.Size([50, 25])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nType of background_summary_obj: <class 'shap.utils._legacy.DenseData'>\nCalculating SHAP values using KernelExplainer for 50 samples (nsamples=50)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db5d5dc34b1a4b4ab614ff924f1d3ad0"}},"metadata":{}},{"name":"stderr","text":"Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.562e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\nRegressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.145e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\nRegressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.636e-05, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\nRegressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.481e-05, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\nRegressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.133e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\nRegressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.998e-06, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\nRegressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.708e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n","output_type":"stream"},{"name":"stdout","text":"SHAP values calculated. Shape: (50, 25)\nKernelExplainer calculation took 1.53 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/audio/shap_summary_kernel_audio_agreeableness.png\nCleaning up memory after trait agreeableness...\nFinished processing agreeableness. Total time: 2.40s\n\n--- Processing Trait: NEUROTICISM ---\nLoading checkpoint for neuroticism from /kaggle/working/best_audio_transformer_model_neuroticism.pth...\nModel for neuroticism loaded successfully.\nSampling 50 rows from explanation data for analysis.\nPreprocessing explanation data. Initial shape: (50, 37)\nPreprocessing complete. Final tensor shape for explanation: torch.Size([50, 25])\nInitializing SHAP KernelExplainer...\nSummarizing background data (100 samples) using k-means...\nType of background_summary_obj: <class 'shap.utils._legacy.DenseData'>\nCalculating SHAP values using KernelExplainer for 50 samples (nsamples=50)... BE PATIENT!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"342e41d52a5b43f58bf66b79f7266301"}},"metadata":{}},{"name":"stdout","text":"SHAP values calculated. Shape: (50, 25)\nKernelExplainer calculation took 1.61 seconds.\nGenerating SHAP summary plot...\nSHAP summary plot saved to /kaggle/working/shap/audio/shap_summary_kernel_audio_neuroticism.png\nCleaning up memory after trait neuroticism...\nFinished processing neuroticism. Total time: 2.62s\n\n--- SHAP Analysis Complete for Video Features ---\nPlots saved in: /kaggle/working/shap/audio/\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!zip -r /kaggle/working/working_dir.zip /kaggle/working/ -x \"/kaggle/working/working_dir.zip\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:03:41.179439Z","iopub.execute_input":"2025-05-07T16:03:41.179724Z","iopub.status.idle":"2025-05-07T16:06:04.693288Z","shell.execute_reply.started":"2025-05-07T16:03:41.179689Z","shell.execute_reply":"2025-05-07T16:06:04.692350Z"}},"outputs":[{"name":"stdout","text":"updating: kaggle/working/ (stored 0%)\nupdating: kaggle/working/best_audio_transformer_model_neuroticism.pth (deflated 7%)\nupdating: kaggle/working/best_video_transformer_model_openness.pth (deflated 8%)\nupdating: kaggle/working/best_audio_transformer_model_agreeableness.pth (deflated 8%)\nupdating: kaggle/working/best_text_transformer_model_neuroticism.pth (deflated 9%)\nupdating: kaggle/working/best_audio_transformer_model_openness.pth (deflated 8%)\nupdating: kaggle/working/best_text_transformer_model_conscientiousness.pth (deflated 9%)\nupdating: kaggle/working/best_text_transformer_model_extraversion.pth (deflated 9%)\nupdating: kaggle/working/best_text_transformer_model_openness.pth (deflated 9%)\nupdating: kaggle/working/best_video_transformer_model_extraversion.pth (deflated 8%)\nupdating: kaggle/working/best_video_transformer_model_agreeableness.pth (deflated 8%)\nupdating: kaggle/working/best_audio_transformer_model_conscientiousness.pth (deflated 8%)\nupdating: kaggle/working/.virtual_documents/ (stored 0%)\nupdating: kaggle/working/best_video_transformer_model_conscientiousness.pth (deflated 8%)\nupdating: kaggle/working/shap/ (stored 0%)\nupdating: kaggle/working/shap/text/ (stored 0%)\nupdating: kaggle/working/shap/text/shap_summary_kernel_conscientiousness.png (deflated 5%)\nupdating: kaggle/working/shap/text/shap_summary_kernel_extraversion.png (deflated 5%)\nupdating: kaggle/working/shap/text/shap_summary_kernel_agreeableness.png (deflated 6%)\nupdating: kaggle/working/shap/text/shap_summary_kernel_neuroticism.png (deflated 6%)\nupdating: kaggle/working/shap/text/shap_summary_kernel_openness.png (deflated 6%)\nupdating: kaggle/working/shap/audio/ (stored 0%)\nupdating: kaggle/working/shap/audio/shap_summary_kernel_video_openness.png (deflated 10%)\nupdating: kaggle/working/shap/audio/shap_summary_kernel_video_extraversion.png (deflated 9%)\nupdating: kaggle/working/shap/audio/shap_summary_kernel_video_conscientiousness.png (deflated 8%)\nupdating: kaggle/working/shap/audio/shap_summary_kernel_video_agreeableness.png (deflated 7%)\nupdating: kaggle/working/shap/audio/shap_summary_kernel_video_neuroticism.png (deflated 9%)\nupdating: kaggle/working/shap/video/ (stored 0%)\nupdating: kaggle/working/shap/video/shap_summary_kernel_video_openness.png (deflated 8%)\nupdating: kaggle/working/shap/video/shap_summary_kernel_video_extraversion.png (deflated 8%)\nupdating: kaggle/working/shap/video/shap_summary_kernel_video_conscientiousness.png (deflated 9%)\nupdating: kaggle/working/shap/video/shap_summary_kernel_video_agreeableness.png (deflated 9%)\nupdating: kaggle/working/shap/video/shap_summary_kernel_video_neuroticism.png (deflated 9%)\nupdating: kaggle/working/best_audio_transformer_model_extraversion.pth (deflated 8%)\nupdating: kaggle/working/best_video_transformer_model_neuroticism.pth (deflated 8%)\nupdating: kaggle/working/state.db (deflated 24%)\nupdating: kaggle/working/best_text_transformer_model_agreeableness.pth (deflated 9%)\n  adding: kaggle/working/shap/audio/shap_summary_kernel_audio_neuroticism.png (deflated 9%)\n  adding: kaggle/working/shap/audio/shap_summary_kernel_audio_agreeableness.png (deflated 8%)\n  adding: kaggle/working/shap/audio/shap_summary_kernel_audio_conscientiousness.png (deflated 8%)\n  adding: kaggle/working/shap/audio/shap_summary_kernel_audio_extraversion.png (deflated 9%)\n  adding: kaggle/working/shap/audio/shap_summary_kernel_audio_openness.png (deflated 10%)\n","output_type":"stream"}],"execution_count":4}]}