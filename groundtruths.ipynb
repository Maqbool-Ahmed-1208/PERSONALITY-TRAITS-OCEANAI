{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10545318,"sourceType":"datasetVersion","datasetId":6524649},{"sourceId":11331676,"sourceType":"datasetVersion","datasetId":7088546},{"sourceId":11586348,"sourceType":"datasetVersion","datasetId":7264479}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# Base directory containing all the folders and CSV files\nbase_directory = \"/kaggle/input/fi-v2-test-val-data/VALIDATION/VAL - AUDIO\"\n\n# List to hold dataframes\ndataframes = []\n\n# Walk through all directories and files\nfor root, dirs, files in os.walk(base_directory):\n    for file in files:\n        if file.endswith(\".csv\"):\n            filepath = os.path.join(root, file)\n            # Read the CSV file and append it to the list\n            df = pd.read_csv(filepath)\n            dataframes.append(df)\n\n# Concatenate all dataframes into one\nmerged_df = pd.concat(dataframes, ignore_index=True)\n\n# Save the combined dataframe to a new CSV file\noutput_filepath = \"val_audio_features.csv\"\nmerged_df.to_csv(output_filepath, index=False)\n\nprint(f\"Combined CSV file saved to: {output_filepath}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"video = pd.read_csv('/kaggle/input/first-impression-annotationslabels/eth_gender_annotations_dev.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\ndf = pd.read_csv('/kaggle/input/first-impression-annotationslabels/fi_age_labels/age_anno_dev.csv' )\n\n# Save the corrected CSV\n# df.to_csv('eth.csv', index=False)\n\n# print(\"CSV has been corrected and saved as 'eth.csv'.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[df['VideoName'] == 'gM_KAA-ejJA.005.mp4']\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"video.head(20)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pickle\n\n# # Load the transcription_training.pkl file\n# with open('/kaggle/input/first-impression-annotationslabels/train-annotation/annotation_training.pkl', 'rb') as file:\n#     # Specify the encoding as 'latin1' or 'utf-8', depending on the file's source\n#     data = pickle.load(file, encoding='latin1')\n\n# # Inspect the first few entries\n# # for key, value in list(data.items())[:]:\n# #     print(f\"{key}: {value}\") # Adjust this based on your dataset structure\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport pickle\n\n# Load the video features CSV\nvideo = pd.read_csv('/kaggle/input/fi-v2-test-val-data/TESTING/TEST - VIDEO/test_video_features.csv')\n\n# Load the annotation pickle file\nwith open('/kaggle/input/fi-v2-test-set/fi v2 test/annotation_test.pkl', 'rb') as file:\n    annotations = pickle.load(file, encoding='latin1')\n\nCreate a DataFrame from the annotations\ntraits = pd.DataFrame(annotations)\n\n# traits = pd.read_csv('/kaggle/working/eth.csv')\n\n# Reset the index to make it easier to join\ntraits = traits.reset_index().rename(columns={'index': 'VideoName'})\n\n# Remove the \".mp4\" extension from the Video_File column for matching\n# traits['Filename'] = traits['Video_File'].str.replace('.mp4', '', regex=False)\ntraits['Filename'] = traits['VideoName'].str.replace('', '', regex=False)\n\n# Merge the two datasets based on the Video_ID column\nmerged_data = pd.merge(video, traits, on='Filename', how='left')\n\n# Save the merged data to a new file\nmerged_data.to_csv('/kaggle/working/test_video_features.csv', index=False)\n\nprint(\"Data merged and saved successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"video = pd.read_csv('/kaggle/working/test_video_features.csv')\nvideo","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load the video features CSV\nvideo = pd.read_csv('/kaggle/working/merged_video_features.csv')\n\n# Load the ethnicity and gender data CSV\neth_data = pd.read_csv('/kaggle/working/eth.csv')\n\n# Remove the \".mp4\" extension from VideoName in eth_data for matching\neth_data['Video_ID'] = eth_data['VideoName'].str.replace('.mp4', '', regex=False)\n\n# Merge the two datasets based on the Video_ID column\nmerged_data = pd.merge(video, eth_data[['Video_ID', 'Ethnicity', 'Gender']], on='Video_ID', how='left')\n\n# Save the merged data to a new file\nmerged_data.to_csv('/kaggle/working/merged2_video_features.csv', index=False)\n\nprint(\"Data merged and saved successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"video = pd.read_csv('/kaggle/working/merged2_video_features.csv')\nvideo","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load the video features CSV\nvideo = pd.read_csv('/kaggle/working/merged2_video_features.csv')\n\n# Load the ethnicity and gender data CSV\neth_data = pd.read_csv('/kaggle/input/first-impression-annotationslabels/fi_age_labels/age_anno_dev.csv')\n\n# Remove the \".mp4\" extension from VideoName in eth_data for matching\neth_data['Video_ID'] = eth_data['VideoName'].str.replace('.mp4', '', regex=False)\n\n# Merge the two datasets based on the Video_ID column\nmerged_data = pd.merge(video, eth_data[['Video_ID', 'AgeGroup']], on='Video_ID', how='left')\n\n# Save the merged data to a new file\nmerged_data.to_csv('/kaggle/working/merged3_video_features.csv', index=False)\n\nprint(\"Data merged and saved successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"video = pd.read_csv('/kaggle/working/merged3_text_handcrafted_features.csv')\nvideo","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}