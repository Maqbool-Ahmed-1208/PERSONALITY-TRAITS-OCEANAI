{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10073328,"sourceType":"datasetVersion","datasetId":6209069},{"sourceId":10267016,"sourceType":"datasetVersion","datasetId":6351877}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\n\n# Load the transcription_training.pkl file\nwith open('/kaggle/input/first-impression-v2-train-dataset/train-transcription/transcription_training.pkl', 'rb') as file:\n    data = pickle.load(file)\n\n# Inspect the first few entries\nfor key, value in list(data.items())[:5]:\n    print(f\"{key}: {value}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:42:13.524145Z","iopub.execute_input":"2024-12-21T03:42:13.524566Z","iopub.status.idle":"2024-12-21T03:42:13.580325Z","shell.execute_reply.started":"2024-12-21T03:42:13.524529Z","shell.execute_reply":"2024-12-21T03:42:13.579659Z"}},"outputs":[{"name":"stdout","text":"J4GQm9j0JZ0.003.mp4: He's cutting it and then turn around and see the end result, but I'm glad he didn't do that because I probably would've lost my mind. As it was getting cut, I was just excited. I saw the snippets of hair falling to the floor and I was like, \"Yes!\"\nzEyRyTnIw5I.005.mp4: Responsibility to house the organ I had been given and I needed to tell them I was going to take good care of that organ and that I so appreciated what they had done. Almost immediately I sent a letter to them\nnskJh7v6v1U.004.mp4: I actually got quite a few sets of black pens this year, because I bought one pack. I think I bought two packs, actually, that I really liked, and then I found ... Some people at my work had these really cool pens that I liked a lot, and I liked how they wrote-\n6wHQsN5g2RM.000.mp4: I ate a lot. I'd like a lot of foods. I remember I have favorite, maybe Mexican chicken or barbecue, pork chops. I don't know. I've got a lot of favorite foods. What's your favorite ice cream?\ndQOeQYWIgm8.000.mp4: Now I'll ask you guys to leave a question in the comments. Hopefully, I'll get 30 questions. I'm going to answer one comment per video in December. Be sure to leave a comment below this video.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\nimport torch\nimport numpy as np\n\n# Load Multilingual BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\nmodel = BertModel.from_pretrained('bert-base-multilingual-cased')\n\n# Maximum feature size for FIv2\nMAX_FEATURE_SIZE = 104\nEMBEDDING_DIM = 768\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:42:58.656423Z","iopub.execute_input":"2024-12-21T03:42:58.656727Z","iopub.status.idle":"2024-12-21T03:43:10.750997Z","shell.execute_reply.started":"2024-12-21T03:42:58.656701Z","shell.execute_reply":"2024-12-21T03:43:10.750090Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76acba1e9a384f62a3b9c806e7132322"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c14f590ed8ab4f7c8d2dcb08723a3e13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34bfa69984a947acb731ad8f869ed3d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9abe2921e0dd4327bf0315464831ef3d"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44ac4cca661e4fcf85c5404fa2bfb596"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"def extract_deep_features(text):\n    # Tokenize and encode the text\n    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n    with torch.no_grad():\n        outputs = model(**inputs)\n    # Extract embeddings from the last hidden layer\n    embeddings = outputs.last_hidden_state.squeeze(0).numpy()\n    # Zero-pad to match MAX_FEATURE_SIZE Ã— EMBEDDING_DIM\n    padded_embeddings = np.zeros((MAX_FEATURE_SIZE, EMBEDDING_DIM))\n    padded_embeddings[:min(embeddings.shape[0], MAX_FEATURE_SIZE), :] = embeddings[:MAX_FEATURE_SIZE, :]\n    return padded_embeddings\n\n# Apply to the dataset\ndeep_features = {key: extract_deep_features(value) for key, value in data.items()}\n\n# Save the extracted deep features\nnp.save('deep_features_fiv2.npy', deep_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:43:57.295546Z","iopub.execute_input":"2024-12-21T03:43:57.296067Z","iopub.status.idle":"2024-12-21T03:50:36.172681Z","shell.execute_reply.started":"2024-12-21T03:43:57.296036Z","shell.execute_reply":"2024-12-21T03:50:36.170942Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-9fd7a1806b3e>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Apply to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdeep_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mextract_deep_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Save the extracted deep features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-9fd7a1806b3e>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Apply to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdeep_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mextract_deep_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Save the extracted deep features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-9fd7a1806b3e>\u001b[0m in \u001b[0;36mextract_deep_features\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Extract embeddings from the last hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1142\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 )\n\u001b[1;32m    693\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    695\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         )\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"# Dummy LIWC implementation\nLIWC_CATEGORIES = [\"work\", \"perceptual_processes\", \"cognitive_processes\", \"anxiety\"]  # Extend with real categories\nCATEGORY_COUNT = 64\nMAX_SEQUENCE_LENGTH = 89\n\ndef liwc_feature_extraction(text):\n    words = text.split()  # Split text into words\n    features = np.zeros((len(words), CATEGORY_COUNT))\n    for i, word in enumerate(words):\n        # Dummy example: Randomly assign categories (replace with real LIWC logic)\n        features[i, np.random.choice(CATEGORY_COUNT, size=5, replace=False)] = 1\n    # Zero-pad to match MAX_SEQUENCE_LENGTH Ã— CATEGORY_COUNT\n    padded_features = np.zeros((MAX_SEQUENCE_LENGTH, CATEGORY_COUNT))\n    padded_features[:min(features.shape[0], MAX_SEQUENCE_LENGTH), :] = features[:MAX_SEQUENCE_LENGTH, :]\n    return padded_features\n\n# Apply to the dataset\nhand_crafted_features = {key: liwc_feature_extraction(value) for key, value in data.items()}\n\n# Save the extracted hand-crafted features\nnp.save('hand_crafted_features_fiv2.npy', hand_crafted_features)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport pickle\nfrom transformers import BertTokenizer, BertModel\nimport torch\nimport re\n\n# Load transcription data\nwith open('/kaggle/input/first-impression-v2-train-dataset/train-transcription/transcription_training.pkl', 'rb') as f:\n    transcriptions = pickle.load(f)\n\n# Initialize BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\nmodel = BertModel.from_pretrained('bert-base-multilingual-cased')\n\n# Load the LIWC dictionary from the provided file path\nliwc_dict_path = '/kaggle/input/liwc2007/LIWC2007.txt'\n\ndef load_liwc_dict(file_path):\n    \"\"\"Parse the LIWC dictionary and return a mapping from words to categories.\"\"\"\n    liwc_dict = {}\n    with open(file_path, 'r') as file:\n        for line in file:\n            if not line.startswith('%'):  # Skip comment lines\n                parts = line.strip().split('\\t')\n                word = parts[0].lower()\n                categories = parts[1:]  # All the categories for the word\n                liwc_dict[word] = categories\n    return liwc_dict\n\nliwc_dict = load_liwc_dict(liwc_dict_path)\n\ndef extract_bert_features(text):\n    \"\"\"Extract deep features using the multilingual BERT model.\"\"\"\n    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=104)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    sentence_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n    return sentence_embedding\n\ndef extract_liwc_features(text):\n    \"\"\"Extract hand-crafted features using the LIWC dictionary.\"\"\"\n    words = re.findall(r'\\b\\w+\\b', text.lower())  # Normalize to lowercase and split into words\n    feature_vector = [0] * 64  # LIWC categories have 64 features\n    for word in words:\n        if word in liwc_dict:\n            categories = liwc_dict[word]\n            for category in categories:\n                # Ensure the category index is valid and increment the corresponding category count\n                try:\n                    category_index = int(category) - 1  # LIWC categories are 1-indexed\n                    if 0 <= category_index < 64:\n                        feature_vector[category_index] += 1\n                except ValueError:\n                    continue  # Skip if the category isn't a valid number\n    return feature_vector\n\ndef extract_features_and_store(transcriptions):\n    \"\"\"Extract features for each transcription and store them.\"\"\"\n    deep_features_list = []\n    handcrafted_features_list = []\n    filenames = []\n\n    for filename, text in transcriptions.items():\n        # Extract deep and hand-crafted features\n        deep_features = extract_bert_features(text)\n        handcrafted_features = extract_liwc_features(text)\n\n        # Store features and filenames\n        deep_features_list.append(deep_features)\n        handcrafted_features_list.append(handcrafted_features)\n        filenames.append(filename)\n\n    # Convert to DataFrames for easier export to CSV\n    df_deep_features = pd.DataFrame(deep_features_list)\n    df_handcrafted_features = pd.DataFrame(handcrafted_features_list)\n\n    # Add filenames to the DataFrames\n    df_deep_features['Filename'] = filenames\n    df_handcrafted_features['Filename'] = filenames\n\n    # Export to CSV\n    df_deep_features.to_csv('text_deep_features.csv', index=False)\n    df_handcrafted_features.to_csv('text_handcrafted_features.csv', index=False)\n\n    print(\"Feature extraction complete and saved to CSV files.\")\n\n# Call the function to extract features and store them\nextract_features_and_store(transcriptions)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T04:32:08.347379Z","iopub.execute_input":"2024-12-22T04:32:08.347665Z","iopub.status.idle":"2024-12-22T04:41:24.284363Z","shell.execute_reply.started":"2024-12-22T04:32:08.347641Z","shell.execute_reply":"2024-12-22T04:41:24.283273Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49d4f95432334be4bd198769c03d4785"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a2874b6eaf548eba0cbd8b2a6dbb4e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4982c2ecd991430f9b83522ca561ca5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05f28a98b889447fb1ac096c592da68c"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2414a0ba4a4948a8b334edc2e7ba111d"}},"metadata":{}},{"name":"stdout","text":"Feature extraction complete and saved to CSV files.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport pickle\nfrom transformers import BertTokenizer, BertModel\nimport torch\nimport re\n\n# Load transcription data\nwith open('/kaggle/input/first-impression-v2-train-dataset/train-transcription/transcription_training.pkl', 'rb') as f:\n    transcriptions = pickle.load(f)\n\n# Initialize BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\nmodel = BertModel.from_pretrained('bert-base-multilingual-cased')\n\n# Load the LIWC dictionary from the provided file path\nliwc_dict_path = '/kaggle/input/liwc2007/LIWC2007.txt'\n\ndef load_liwc_dict(file_path):\n    \"\"\"Parse the LIWC dictionary and return a mapping from words to categories.\"\"\"\n    liwc_dict = {}\n    with open(file_path, 'r') as file:\n        for line in file:\n            if not line.startswith('%'):  # Skip comment lines\n                parts = line.strip().split('\\t')\n                word = parts[0].lower()\n                categories = parts[1:]  # All the categories for the word\n                liwc_dict[word] = categories\n    return liwc_dict\n\nliwc_dict = load_liwc_dict(liwc_dict_path)\n\ndef extract_bert_features(text):\n    \"\"\"Extract deep features using the multilingual BERT model.\"\"\"\n    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=104)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    sentence_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n    return sentence_embedding\n\ndef extract_liwc_features(text):\n    \"\"\"Extract hand-crafted features using the LIWC dictionary.\"\"\"\n    words = re.findall(r'\\b\\w+\\b', text.lower())  # Normalize to lowercase and split into words\n    feature_vector = [0] * 64  # LIWC categories have 64 features\n    for word in words:\n        if word in liwc_dict:\n            categories = liwc_dict[word]\n            for category in categories:\n                try:\n                    category_index = int(category) - 1  # LIWC categories are 1-indexed\n                    if 0 <= category_index < 64:\n                        feature_vector[category_index] += 1\n                except ValueError:\n                    continue  # Skip if the category isn't a valid number\n    return feature_vector\n\ndef extract_features_and_store(transcriptions):\n    \"\"\"Extract features for each transcription and store them.\"\"\"\n    deep_features_list = []\n    handcrafted_features_list = []\n    filenames = []\n\n    for filename, text in transcriptions.items():\n        # Extract deep and hand-crafted features\n        deep_features = extract_bert_features(text)\n        handcrafted_features = extract_liwc_features(text)\n\n        # Store features and filenames\n        deep_features_list.append(deep_features)\n        handcrafted_features_list.append(handcrafted_features)\n        filenames.append(filename)\n\n    # Convert to DataFrames for easier export to CSV\n    df_deep_features = pd.DataFrame(deep_features_list)\n    df_handcrafted_features = pd.DataFrame(handcrafted_features_list)\n\n    # Add filenames to the DataFrames as the first column\n    df_deep_features.insert(0, 'Filename', filenames)\n    df_handcrafted_features.insert(0, 'Filename', filenames)\n\n    # Export to CSV\n    df_deep_features.to_csv('text_deep_features.csv', index=False)\n    df_handcrafted_features.to_csv('text_handcrafted_features.csv', index=False)\n\n    print(\"Feature extraction complete and saved to CSV files.\")\n\n# Call the function to extract features and store them\nextract_features_and_store(transcriptions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T04:51:42.944532Z","iopub.execute_input":"2024-12-22T04:51:42.944863Z","iopub.status.idle":"2024-12-22T05:00:53.728592Z","shell.execute_reply.started":"2024-12-22T04:51:42.944818Z","shell.execute_reply":"2024-12-22T05:00:53.727723Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Feature extraction complete and saved to CSV files.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(\"working done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T05:00:53.729989Z","iopub.execute_input":"2024-12-22T05:00:53.730221Z","iopub.status.idle":"2024-12-22T05:00:53.734247Z","shell.execute_reply.started":"2024-12-22T05:00:53.730202Z","shell.execute_reply":"2024-12-22T05:00:53.733518Z"}},"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"##############\n\nimport pandas as pd\nimport pickle\nimport numpy as np\n# import liwc\nimport torch\nimport re\nfrom transformers import BertTokenizer, BertModel\n\n# Load the transcription data (adjust the path if necessary)\nwith open('/kaggle/input/first-impression-v2-train-dataset/train-transcription/transcription_training.pkl', 'rb') as f:\n    transcriptions = pickle.load(f)\n\n# Initialize BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\nmodel = BertModel.from_pretrained('bert-base-multilingual-cased')\n\n# Define the LIWC categories and translation feature extraction function\nclass FeatureExtractor:\n    def __init__(self, liwc_dict_path):\n        self.__lang_traslate = [\"en\", \"es\"]  # Example languages (adjust accordingly)\n        self.__contractions_dict = {}  # Add actual contractions dictionary as required\n        self.__category_text_features = self.load_liwc_dict(liwc_dict_path)\n\n    def load_liwc_dict(self, liwc_dict_path):\n        \"\"\"Load and parse the LIWC2007 dictionary file.\"\"\"\n        liwc_dict = {}\n        with open(liwc_dict_path, 'r') as file:\n            lines = file.readlines()\n        \n        # Parse the LIWC dictionary file line by line\n        for line in lines:\n            parts = line.strip().split(\"\\t\")\n            if len(parts) > 1:\n                category = parts[0]  # LIWC category\n                words = parts[1].split()  # List of words associated with the category\n                liwc_dict[category] = words\n        return liwc_dict\n\n    def __parse_text_features(self, word):\n        \"\"\"Parse the word and return the associated LIWC categories.\"\"\"\n        features = []\n        for category, words in self.__category_text_features.items():\n            if word.lower() in [w.lower() for w in words]:\n                features.append(category)\n        return features\n\n    def __translate_and_extract_features(self, text, lang, show_text=False, last=False, out=True):\n        \"\"\"Extract LIWC and BERT features from text.\"\"\"\n        contractions_re = re.compile(\"(%s)\" % \"|\".join(self.__contractions_dict.keys()))\n        expand_contractions = lambda s: contractions_re.sub(lambda match: self.__contractions_dict[match.group(0)], s)\n\n        get_norm_text = lambda text: re.sub(\n            r\"(?<=[.,])(?=[^\\s])\", \" \", re.sub(r\"\\[[^\\[\\]]+\\]\", \"\", expand_contractions(re.sub(r'[.,\"\\'?:!/;]', \"\", text.lower().strip()))))\n\n        norm_features = lambda feature, length: np.pad(\n            feature[:length, :], ((0, max(0, length - feature.shape[0])), (0, 0)), \"constant\"\n        )\n\n        # Normalize text and get features\n        text = get_norm_text(text)\n\n        # BERT feature extraction\n        encoded_input = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        with torch.no_grad():\n            outputs = model(**encoded_input)\n        features_bert = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n\n        # LIWC feature extraction\n        features_liwc = np.zeros((len(self.__category_text_features),))\n        for word in text.split(\" \"):\n            categories = self.__parse_text_features(word)\n            for cat in categories:\n                idx = self.__category_text_features.get(cat, [])\n                if idx:\n                    features_liwc[self.__category_text_features.keys().index(cat)] += 1\n\n        # Normalize features\n        features_bert = norm_features(features_bert, 414)\n        features_liwc = norm_features(features_liwc, 365)\n\n        return features_liwc, features_bert\n\n# Initialize FeatureExtractor with the path to LIWC dictionary\nliwc_dict_path = '/kaggle/input/liwc2007/LIWC2007.txt'\nextractor = FeatureExtractor(liwc_dict_path)\n\ndef extract_features_and_store(transcriptions):\n    \"\"\"Extract features for each transcription and store them.\"\"\"\n    deep_features_list = []\n    handcrafted_features_list = []\n    filenames = []\n\n    # Loop through each transcription in the pkl file\n    for filename, text in transcriptions.items():\n        # Extract both LIWC and BERT features\n        features_liwc, features_bert = extractor.__translate_and_extract_features(text, \"en\")\n\n        # Store features and filenames\n        handcrafted_features_list.append(features_liwc)\n        deep_features_list.append(features_bert)\n        filenames.append(filename)\n\n    # Convert lists to DataFrames for easier export to CSV\n    df_deep_features = pd.DataFrame(deep_features_list)\n    df_handcrafted_features = pd.DataFrame(handcrafted_features_list)\n\n    # Add filenames as the first column in both DataFrames\n    df_deep_features.insert(0, 'Filename', filenames)\n    df_handcrafted_features.insert(0, 'Filename', filenames)\n\n    # Export DataFrames to CSV\n    df_deep_features.to_csv('deep_features_with_filenames.csv', index=False)\n    df_handcrafted_features.to_csv('handcrafted_features_with_filenames.csv', index=False)\n\n    print(\"Feature extraction complete and saved to CSV files.\")\n\n# Call the function to extract features and store them\nextract_features_and_store(transcriptions)\nprint(\"done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T05:07:56.546469Z","iopub.execute_input":"2024-12-22T05:07:56.546791Z","iopub.status.idle":"2024-12-22T05:07:57.699586Z","shell.execute_reply.started":"2024-12-22T05:07:56.546754Z","shell.execute_reply":"2024-12-22T05:07:57.698518Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-352e16c5594d>\u001b[0m in \u001b[0;36m<cell line: 120>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;31m# Call the function to extract features and store them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mextract_features_and_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscriptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-352e16c5594d>\u001b[0m in \u001b[0;36mextract_features_and_store\u001b[0;34m(transcriptions)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranscriptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Extract both LIWC and BERT features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mfeatures_liwc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_bert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__translate_and_extract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Store features and filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'FeatureExtractor' object has no attribute '__translate_and_extract_features'"],"ename":"AttributeError","evalue":"'FeatureExtractor' object has no attribute '__translate_and_extract_features'","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T05:04:37.426029Z","iopub.execute_input":"2024-12-22T05:04:37.426327Z","iopub.status.idle":"2024-12-22T05:04:37.430166Z","shell.execute_reply.started":"2024-12-22T05:04:37.426304Z","shell.execute_reply":"2024-12-22T05:04:37.429202Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/working/text_deep_features.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T05:07:09.803563Z","iopub.execute_input":"2024-12-22T05:07:09.803856Z","iopub.status.idle":"2024-12-22T05:07:10.608750Z","shell.execute_reply.started":"2024-12-22T05:07:09.803833Z","shell.execute_reply":"2024-12-22T05:07:10.608115Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T05:07:11.824581Z","iopub.execute_input":"2024-12-22T05:07:11.824864Z","iopub.status.idle":"2024-12-22T05:07:11.851890Z","shell.execute_reply.started":"2024-12-22T05:07:11.824843Z","shell.execute_reply":"2024-12-22T05:07:11.851222Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                 Filename         0         1         2         3         4  \\\n0     J4GQm9j0JZ0.003.mp4 -0.242928 -0.339531 -0.025601  0.244540  0.892297   \n1     zEyRyTnIw5I.005.mp4 -0.069200 -0.434665  0.073010 -0.173166  0.602467   \n2     nskJh7v6v1U.004.mp4  0.043944 -0.367641 -0.114857  0.099605  0.565259   \n3     6wHQsN5g2RM.000.mp4 -0.439144 -0.092683  0.282453  0.116274  0.824320   \n4     dQOeQYWIgm8.000.mp4 -0.171071 -0.237357 -0.067170  0.171221  0.589509   \n...                   ...       ...       ...       ...       ...       ...   \n5995  mhF4kYTlVUE.001.mp4 -0.207325 -0.727157 -0.574352  0.312974  0.782626   \n5996  2q8orkMs2Jg.003.mp4 -0.468130 -0.482583  0.096771  0.292015  0.733364   \n5997  F1lAPYh4t3U.000.mp4 -0.277300 -0.429958  0.136949  0.067262  0.895780   \n5998  cxJ0u6r0-pU.001.mp4 -0.225750 -0.326381  0.120616  0.143940  0.329312   \n5999  hfUH9Am-Izs.000.mp4 -0.400870 -0.221660  0.156524  0.430838  0.572290   \n\n             5         6         7         8  ...       758       759  \\\n0     0.147015 -0.313380  0.809669 -0.370543  ... -0.226408  0.032308   \n1    -0.232156 -0.256193  0.220219 -0.522540  ...  0.090561 -0.015783   \n2     0.055890 -0.370536  0.483487 -0.522987  ...  0.027890 -0.073298   \n3    -0.048884 -0.357818  0.408998 -0.100275  ... -0.501510 -0.320901   \n4     0.148646 -0.310589  0.400486 -0.428959  ... -0.031038 -0.073519   \n...        ...       ...       ...       ...  ...       ...       ...   \n5995  0.416122 -0.146443  0.527809 -0.679955  ... -0.239749 -0.178334   \n5996  0.404647 -0.344417  0.406257 -0.031403  ... -0.077539  0.211370   \n5997  0.126993 -0.182677  0.415356 -0.016152  ...  0.169418 -0.366907   \n5998  0.214944 -0.267022  0.581226 -0.007218  ... -0.276070  0.045374   \n5999 -0.028923 -0.263673  0.611297 -0.433325  ... -0.306262 -0.252556   \n\n           760       761       762       763       764       765       766  \\\n0    -0.379697  0.127955  0.015482 -0.714135  0.967615  0.191498 -0.306697   \n1    -0.123446 -0.782116 -0.165112 -0.754044  0.533481  0.594238 -0.516909   \n2    -0.901172 -0.156638 -0.123582 -0.825829  0.455202  0.932887 -0.204750   \n3    -0.611902 -0.306970  0.170360 -0.208912  0.569401  0.160111 -0.503446   \n4    -0.280926 -0.544391 -0.094637 -0.647683  0.089279  0.205052 -0.541694   \n...        ...       ...       ...       ...       ...       ...       ...   \n5995 -0.372753 -0.079485 -0.145676 -0.337447  0.702685  0.566176 -0.400116   \n5996 -0.664456  0.001076 -0.169727 -1.204941  0.683210  0.321280 -0.442748   \n5997 -0.741146 -0.578648  0.226593 -0.783851  0.411136  0.449866  0.037044   \n5998  0.198921 -0.568740 -0.006747 -0.503992  0.475720  0.794023 -0.221327   \n5999 -0.343733 -0.159225 -0.117304 -0.827602  0.655991  0.408713 -0.450603   \n\n           767  \n0    -0.206918  \n1    -0.126553  \n2     0.140392  \n3     0.189523  \n4     0.195269  \n...        ...  \n5995  0.125432  \n5996  0.229803  \n5997 -0.061017  \n5998  0.168648  \n5999  0.008037  \n\n[6000 rows x 769 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>758</th>\n      <th>759</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>J4GQm9j0JZ0.003.mp4</td>\n      <td>-0.242928</td>\n      <td>-0.339531</td>\n      <td>-0.025601</td>\n      <td>0.244540</td>\n      <td>0.892297</td>\n      <td>0.147015</td>\n      <td>-0.313380</td>\n      <td>0.809669</td>\n      <td>-0.370543</td>\n      <td>...</td>\n      <td>-0.226408</td>\n      <td>0.032308</td>\n      <td>-0.379697</td>\n      <td>0.127955</td>\n      <td>0.015482</td>\n      <td>-0.714135</td>\n      <td>0.967615</td>\n      <td>0.191498</td>\n      <td>-0.306697</td>\n      <td>-0.206918</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>zEyRyTnIw5I.005.mp4</td>\n      <td>-0.069200</td>\n      <td>-0.434665</td>\n      <td>0.073010</td>\n      <td>-0.173166</td>\n      <td>0.602467</td>\n      <td>-0.232156</td>\n      <td>-0.256193</td>\n      <td>0.220219</td>\n      <td>-0.522540</td>\n      <td>...</td>\n      <td>0.090561</td>\n      <td>-0.015783</td>\n      <td>-0.123446</td>\n      <td>-0.782116</td>\n      <td>-0.165112</td>\n      <td>-0.754044</td>\n      <td>0.533481</td>\n      <td>0.594238</td>\n      <td>-0.516909</td>\n      <td>-0.126553</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>nskJh7v6v1U.004.mp4</td>\n      <td>0.043944</td>\n      <td>-0.367641</td>\n      <td>-0.114857</td>\n      <td>0.099605</td>\n      <td>0.565259</td>\n      <td>0.055890</td>\n      <td>-0.370536</td>\n      <td>0.483487</td>\n      <td>-0.522987</td>\n      <td>...</td>\n      <td>0.027890</td>\n      <td>-0.073298</td>\n      <td>-0.901172</td>\n      <td>-0.156638</td>\n      <td>-0.123582</td>\n      <td>-0.825829</td>\n      <td>0.455202</td>\n      <td>0.932887</td>\n      <td>-0.204750</td>\n      <td>0.140392</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6wHQsN5g2RM.000.mp4</td>\n      <td>-0.439144</td>\n      <td>-0.092683</td>\n      <td>0.282453</td>\n      <td>0.116274</td>\n      <td>0.824320</td>\n      <td>-0.048884</td>\n      <td>-0.357818</td>\n      <td>0.408998</td>\n      <td>-0.100275</td>\n      <td>...</td>\n      <td>-0.501510</td>\n      <td>-0.320901</td>\n      <td>-0.611902</td>\n      <td>-0.306970</td>\n      <td>0.170360</td>\n      <td>-0.208912</td>\n      <td>0.569401</td>\n      <td>0.160111</td>\n      <td>-0.503446</td>\n      <td>0.189523</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dQOeQYWIgm8.000.mp4</td>\n      <td>-0.171071</td>\n      <td>-0.237357</td>\n      <td>-0.067170</td>\n      <td>0.171221</td>\n      <td>0.589509</td>\n      <td>0.148646</td>\n      <td>-0.310589</td>\n      <td>0.400486</td>\n      <td>-0.428959</td>\n      <td>...</td>\n      <td>-0.031038</td>\n      <td>-0.073519</td>\n      <td>-0.280926</td>\n      <td>-0.544391</td>\n      <td>-0.094637</td>\n      <td>-0.647683</td>\n      <td>0.089279</td>\n      <td>0.205052</td>\n      <td>-0.541694</td>\n      <td>0.195269</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5995</th>\n      <td>mhF4kYTlVUE.001.mp4</td>\n      <td>-0.207325</td>\n      <td>-0.727157</td>\n      <td>-0.574352</td>\n      <td>0.312974</td>\n      <td>0.782626</td>\n      <td>0.416122</td>\n      <td>-0.146443</td>\n      <td>0.527809</td>\n      <td>-0.679955</td>\n      <td>...</td>\n      <td>-0.239749</td>\n      <td>-0.178334</td>\n      <td>-0.372753</td>\n      <td>-0.079485</td>\n      <td>-0.145676</td>\n      <td>-0.337447</td>\n      <td>0.702685</td>\n      <td>0.566176</td>\n      <td>-0.400116</td>\n      <td>0.125432</td>\n    </tr>\n    <tr>\n      <th>5996</th>\n      <td>2q8orkMs2Jg.003.mp4</td>\n      <td>-0.468130</td>\n      <td>-0.482583</td>\n      <td>0.096771</td>\n      <td>0.292015</td>\n      <td>0.733364</td>\n      <td>0.404647</td>\n      <td>-0.344417</td>\n      <td>0.406257</td>\n      <td>-0.031403</td>\n      <td>...</td>\n      <td>-0.077539</td>\n      <td>0.211370</td>\n      <td>-0.664456</td>\n      <td>0.001076</td>\n      <td>-0.169727</td>\n      <td>-1.204941</td>\n      <td>0.683210</td>\n      <td>0.321280</td>\n      <td>-0.442748</td>\n      <td>0.229803</td>\n    </tr>\n    <tr>\n      <th>5997</th>\n      <td>F1lAPYh4t3U.000.mp4</td>\n      <td>-0.277300</td>\n      <td>-0.429958</td>\n      <td>0.136949</td>\n      <td>0.067262</td>\n      <td>0.895780</td>\n      <td>0.126993</td>\n      <td>-0.182677</td>\n      <td>0.415356</td>\n      <td>-0.016152</td>\n      <td>...</td>\n      <td>0.169418</td>\n      <td>-0.366907</td>\n      <td>-0.741146</td>\n      <td>-0.578648</td>\n      <td>0.226593</td>\n      <td>-0.783851</td>\n      <td>0.411136</td>\n      <td>0.449866</td>\n      <td>0.037044</td>\n      <td>-0.061017</td>\n    </tr>\n    <tr>\n      <th>5998</th>\n      <td>cxJ0u6r0-pU.001.mp4</td>\n      <td>-0.225750</td>\n      <td>-0.326381</td>\n      <td>0.120616</td>\n      <td>0.143940</td>\n      <td>0.329312</td>\n      <td>0.214944</td>\n      <td>-0.267022</td>\n      <td>0.581226</td>\n      <td>-0.007218</td>\n      <td>...</td>\n      <td>-0.276070</td>\n      <td>0.045374</td>\n      <td>0.198921</td>\n      <td>-0.568740</td>\n      <td>-0.006747</td>\n      <td>-0.503992</td>\n      <td>0.475720</td>\n      <td>0.794023</td>\n      <td>-0.221327</td>\n      <td>0.168648</td>\n    </tr>\n    <tr>\n      <th>5999</th>\n      <td>hfUH9Am-Izs.000.mp4</td>\n      <td>-0.400870</td>\n      <td>-0.221660</td>\n      <td>0.156524</td>\n      <td>0.430838</td>\n      <td>0.572290</td>\n      <td>-0.028923</td>\n      <td>-0.263673</td>\n      <td>0.611297</td>\n      <td>-0.433325</td>\n      <td>...</td>\n      <td>-0.306262</td>\n      <td>-0.252556</td>\n      <td>-0.343733</td>\n      <td>-0.159225</td>\n      <td>-0.117304</td>\n      <td>-0.827602</td>\n      <td>0.655991</td>\n      <td>0.408713</td>\n      <td>-0.450603</td>\n      <td>0.008037</td>\n    </tr>\n  </tbody>\n</table>\n<p>6000 rows Ã— 769 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}