{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11793742,"sourceType":"datasetVersion","datasetId":7264479}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.preprocessing import StandardScaler\nimport gc\n\n# Configure matplotlib to reduce memory usage\n# plt.ioff()  # Turn off interactive mode\nplt.rcParams['figure.max_open_warning'] = 0  # Disable figure limit warning\n\n# Dataset configuration - adjust paths to your dataset\nDATASETS = {\n    'audio_deep': '/kaggle/input/fi-v2-test-val-data/Feature Dataset 2/audio_deep_features.csv',\n    'audio_hc': '/kaggle/input/fi-v2-test-val-data/Feature Dataset 2/audio_hc_features.csv',\n    'video_deep': '/kaggle/input/fi-v2-test-val-data/Feature Dataset 2/video_deep_features.csv',\n    'video_hc': '/kaggle/input/fi-v2-test-val-data/Feature Dataset 2/video_hc_features.csv',\n    'text_deep': '/kaggle/input/fi-v2-test-val-data/Feature Dataset 2/text_deep_features.csv',\n    'text_hc': '/kaggle/input/fi-v2-test-val-data/text_hc_features.csv'\n}\n\nTRAIT_COLUMNS = ['openness', 'conscientiousness', 'extraversion',\n                 'agreeableness', 'neuroticism', 'interview']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T09:36:41.092192Z","iopub.execute_input":"2025-05-13T09:36:41.092472Z","iopub.status.idle":"2025-05-13T09:36:42.191652Z","shell.execute_reply.started":"2025-05-13T09:36:41.092450Z","shell.execute_reply":"2025-05-13T09:36:42.190849Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### V 1","metadata":{}},{"cell_type":"code","source":"\n# def process_dataset(name, path):\n#     \"\"\"Process a single dataset with memory optimization and sorted clustering\"\"\"\n#     print(f\"\\nüîÅ Processing {name.replace('_', ' ').title()} dataset...\")\n\n#     # Load data with optimized types\n#     df = pd.read_csv(path)\n#     df = df.fillna(0)\n#     for col in TRAIT_COLUMNS:\n#         if col in df.columns:\n#             df[col] = df[col].astype(np.float32)\n\n#     # Process one trait at a time\n#     for trait in TRAIT_COLUMNS:\n#         if trait in df.columns:\n#             print(f\"  ‚öôÔ∏è Clustering {trait}...\")\n\n#             # Extract and standardize feature\n#             X = df[[trait]].values\n#             X_scaled = StandardScaler().fit_transform(X)\n\n#             # Fit GMM and predict clusters\n#             gmm = GaussianMixture(n_components=3, random_state=42)\n#             df[f'{trait}_cluster'] = gmm.fit_predict(X_scaled)\n\n#             # Reorder clusters based on mean trait score\n#             cluster_means = df.groupby(f'{trait}_cluster')[trait].mean().sort_values()\n#             cluster_mapping = {old: new for new, old in enumerate(cluster_means.index)}\n#             df[f'{trait}_cluster'] = df[f'{trait}_cluster'].map(cluster_mapping)\n\n#             # Clean up intermediate variables\n#             del X, X_scaled, cluster_means, cluster_mapping\n#             gc.collect()\n\n#     # Save results\n#     output_path = f'/kaggle/working/{name}_clustered.csv'\n#     df.to_csv(output_path, index=False)\n#     print(f\"‚úÖ Saved clustered data to {output_path}\")\n\n#     # Visualize each trait separately using original values\n#     for trait in TRAIT_COLUMNS:\n#         if trait in df.columns:\n#             fig, ax = plt.subplots(figsize=(12, 6))\n\n#             scatter = ax.scatter(df.index, df[trait],\n#                                  c=df[f'{trait}_cluster'], cmap='viridis',\n#                                  s=30, alpha=0.7, edgecolors='black')\n\n#             ax.set_title(f\"{name.title()} - {trait.title()} Clustering (Original Trait Values)\", fontsize=14)\n#             ax.set_xlabel(\"Sample Index\", fontsize=12)\n#             ax.set_ylabel(f\"{trait.title()} Score\", fontsize=12)  # Show original trait name\n#             ax.grid(True, alpha=0.3)\n\n#             plt.colorbar(scatter, ax=ax, label=\"Cluster Label\")\n#             plt.tight_layout()\n#             plt.show()\n#             plt.close(fig)\n\n#             # Memory cleanup\n#             del fig, ax, scatter\n#             gc.collect()\n\n#     # Final cleanup\n#     del df\n#     gc.collect()\n#     print(\"=\"*80 + \"\\n\")\n\n# # Process datasets sequentially\n# for name, path in DATASETS.items():\n#     process_dataset(name, path)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T09:36:42.192800Z","iopub.execute_input":"2025-05-13T09:36:42.193147Z","iopub.status.idle":"2025-05-13T09:36:42.198874Z","shell.execute_reply.started":"2025-05-13T09:36:42.193128Z","shell.execute_reply":"2025-05-13T09:36:42.198191Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### V 2","metadata":{}},{"cell_type":"code","source":"def process_dataset(name, path):\n    \"\"\"Process a single dataset with memory optimization and sorted clustering\"\"\"\n    print(f\"\\nüîÅ Processing {name.replace('_', ' ').title()} dataset...\")\n\n    # Load data with optimized types (preserve all original columns)\n    df = pd.read_csv(path)\n    df = df.fillna(0)\n    \n    # Only modify trait columns (keep other columns as-is)\n    for col in TRAIT_COLUMNS:\n        if col in df.columns:\n            df[col] = df[col].astype(np.float32)\n\n    # Process one trait at a time\n    for trait in TRAIT_COLUMNS:\n        if trait in df.columns:\n            print(f\"  ‚öôÔ∏è Clustering {trait}...\")\n\n            # Preserve original trait column\n            original_trait = df[trait].copy()\n            \n            # Extract and standardize feature\n            X = df[[trait]].values\n            X_scaled = StandardScaler().fit_transform(X)\n\n            # Fit GMM and predict clusters\n            gmm = GaussianMixture(n_components=3, random_state=42)\n            df[f'{trait}_cluster'] = gmm.fit_predict(X_scaled)\n\n            # Reorder clusters based on mean trait score\n            cluster_means = df.groupby(f'{trait}_cluster')[trait].mean().sort_values()\n            cluster_mapping = {old: new for new, old in enumerate(cluster_means.index)}\n            df[f'{trait}_cluster'] = df[f'{trait}_cluster'].map(cluster_mapping)\n\n            # Restore original trait values (in case scaling affected them)\n            df[trait] = original_trait\n\n            # Clean up intermediate variables\n            del X, X_scaled, cluster_means, cluster_mapping, original_trait\n            gc.collect()\n\n    # Save results with all original + cluster columns\n    output_path = f'/kaggle/working/{name}_clustered.csv'\n    df.to_csv(output_path, index=False)\n    print(f\"‚úÖ Saved clustered data to {output_path}\")\n\n    # Visualization remains unchanged\n    for trait in TRAIT_COLUMNS:\n        if trait in df.columns:\n            fig, ax = plt.subplots(figsize=(12, 6))\n\n            scatter = ax.scatter(df.index, df[trait],\n                                 c=df[f'{trait}_cluster'], cmap='viridis',\n                                 s=30, alpha=0.7, edgecolors='black')\n\n            ax.set_title(f\"{name.title()} - {trait.title()} Clustering (Original Trait Values)\", fontsize=14)\n            ax.set_xlabel(\"Sample Index\", fontsize=12)\n            ax.set_ylabel(f\"{trait.title()} Score\", fontsize=12)\n            ax.grid(True, alpha=0.3)\n\n            plt.colorbar(scatter, ax=ax, label=\"Cluster Label\")\n            plt.tight_layout()\n            plt.show()\n            plt.close(fig)\n\n            del fig, ax, scatter\n            gc.collect()\n\n    # Final cleanup\n    del df\n    gc.collect()\n    print(\"=\"*80 + \"\\n\")\n\n\n\n    # Process datasets sequentially\nfor name, path in DATASETS.items():\n    process_dataset(name, path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T09:36:44.562581Z","iopub.execute_input":"2025-05-13T09:36:44.563271Z","iopub.status.idle":"2025-05-13T09:36:44.572032Z","shell.execute_reply.started":"2025-05-13T09:36:44.563237Z","shell.execute_reply":"2025-05-13T09:36:44.571335Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import shutil\n# import os\n\n# # List of files to move\n# files_to_move = ['file1.txt', 'file2.txt', 'file3.txt']\n# destination_folder = 'path/to/destination/'\n\n# # Create destination folder if needed\n# os.makedirs(destination_folder, exist_ok=True)\n\n# # Move each file\n# for file in files_to_move:\n#     shutil.move(file, destination_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T10:32:52.596866Z","iopub.execute_input":"2025-05-13T10:32:52.597163Z","iopub.status.idle":"2025-05-13T10:32:52.600671Z","shell.execute_reply.started":"2025-05-13T10:32:52.597141Z","shell.execute_reply":"2025-05-13T10:32:52.599885Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import shutil\n\n# Create a ZIP archive\nshutil.make_archive(\n    base_name='Features_dataset_clustered',  # Name without extension\n    format='zip',                  # Can be 'zip', 'tar', 'gztar', 'bztar', 'xztar'\n    root_dir='/kaggle/working/Features_dataset_clustered',      # Folder to compress\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T10:36:51.418485Z","iopub.execute_input":"2025-05-13T10:36:51.418754Z","iopub.status.idle":"2025-05-13T10:38:37.555904Z","shell.execute_reply.started":"2025-05-13T10:36:51.418735Z","shell.execute_reply":"2025-05-13T10:38:37.555129Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/Features_dataset_clustered.zip'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}