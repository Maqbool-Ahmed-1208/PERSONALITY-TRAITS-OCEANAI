{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"mount_file_id":"10Fr53d0Tz0uvQlfzxk1PuUyOfir_SvpQ","authorship_tag":"ABX9TyM8JMIqoAQIdnT6xgC3kRSr"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11600280,"sourceType":"datasetVersion","datasetId":7264479}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# cd /content/drive/MyDrive/DATASET\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nLzE5eM2g0t-","executionInfo":{"status":"ok","timestamp":1742123426004,"user_tz":-300,"elapsed":225,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"504532f5-48ce-4b01-c39a-02f8c028eba8"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DATASET\n"]}],"execution_count":1},{"cell_type":"code","source":"ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pPCuhoNUkhs_","executionInfo":{"status":"ok","timestamp":1742123426058,"user_tz":-300,"elapsed":49,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"8fd97fcf-d7d8-4524-9cee-8a1bf765a27c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mfeature_data\u001b[0m/  MMTV2.pth  \u001b[01;34mtest1\u001b[0m/                    text_hc_clustered.csv   \u001b[01;34mtext_hc_models\u001b[0m/\n","MMTV1.pth      MMTV3.pth  text_deep_features_2.csv  text_hc_features_2.csv  \u001b[01;34mvideodeepmodel\u001b[0m/\n"]}],"execution_count":2},{"cell_type":"markdown","source":"run this","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n# Load text datasets\ntext_deep = pd.read_csv(\"/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/DEEP/text_deep_features.csv\")\ntext_hc = pd.read_csv(\"/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/text_hc_features.csv\")\n\n# Expand text data by repeating each row 5 times (to match 5 segments per video)\ntext_deep_expanded = text_deep.loc[text_deep.index.repeat(5)].reset_index(drop=True)\ntext_hc_expanded = text_hc.loc[text_hc.index.repeat(5)].reset_index(drop=True)\n\n# Add Segment_ID (assign values cyclically: [0,1,2,3,4])\ntext_deep_expanded[\"Segment_ID\"] = np.tile(np.arange(5), len(text_deep))\ntext_hc_expanded[\"Segment_ID\"] = np.tile(np.arange(5), len(text_hc))\n\n\n# Save the processed files (optional)\ntext_deep_expanded.to_csv(\"/kaggle/working/text_deep_features_2.csv\", index=False)\ntext_hc_expanded.to_csv(\"/kaggle/working/text_hc_features_2.csv\", index=False)\n\n# Print new shapes for confirmation\nprint(\"✅ Text Deep Aligned Shape:\", text_deep_expanded.shape)  # Should be ~30,000 rows\nprint(\"✅ Text HC Aligned Shape:\", text_hc_expanded.shape)      # Should be ~30,000 rows\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADEzM8juf4Xd","executionInfo":{"status":"ok","timestamp":1741635719815,"user_tz":-300,"elapsed":26831,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"4b331c65-e981-43a5-acb0-2be861b9402c","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:06:15.730956Z","iopub.execute_input":"2025-05-04T11:06:15.731222Z","iopub.status.idle":"2025-05-04T11:07:08.991505Z","shell.execute_reply.started":"2025-05-04T11:06:15.731185Z","shell.execute_reply":"2025-05-04T11:07:08.990575Z"}},"outputs":[{"name":"stdout","text":"✅ Text Deep Aligned Shape: (50000, 1547)\n✅ Text HC Aligned Shape: (50000, 139)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## LIBRARIES","metadata":{"id":"T5vUa7x4jJ0r"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport torch.optim as optim\n","metadata":{"id":"3z_btQb0jNk-","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:16:26.654493Z","iopub.execute_input":"2025-05-04T11:16:26.654834Z","iopub.status.idle":"2025-05-04T11:16:31.309307Z","shell.execute_reply.started":"2025-05-04T11:16:26.654807Z","shell.execute_reply":"2025-05-04T11:16:31.308648Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## File paths\n","metadata":{"id":"3DBJWzwMjW5E"}},{"cell_type":"code","source":"file_paths = {\n    \"audio_deep\": \"/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/DEEP/audio_deep_features.csv\",\n    \"audio_hc\": \"/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/audio_hc_features.csv\",\n    \"video_deep\": \"/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/DEEP/video_deep_features.csv\",\n    \"video_hc\": \"/kaggle/input/fi-v2-test-val-data/FI V2 COMPLETE FEATURE DATASET/HANDCRAFTED/video_hc_features.csv\",\n    \"text_deep\": \"/kaggle/working/text_deep_features_2.csv\",\n    \"text_hc\": \"/kaggle/working/text_hc_features_2.csv\",\n}","metadata":{"id":"GcAJtzHDjSQT","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:16:31.310304Z","iopub.execute_input":"2025-05-04T11:16:31.310635Z","iopub.status.idle":"2025-05-04T11:16:31.314607Z","shell.execute_reply.started":"2025-05-04T11:16:31.310616Z","shell.execute_reply":"2025-05-04T11:16:31.313646Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"pd.read_csv(file_paths[\"text_hc\"]).info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-FKI45Xutil","executionInfo":{"status":"ok","timestamp":1741718138990,"user_tz":-300,"elapsed":878,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"93debab7-1b0a-4579-b5b7-3df8f29a8f4f","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:17:18.200917Z","iopub.execute_input":"2025-05-04T11:17:18.201205Z","iopub.status.idle":"2025-05-04T11:17:18.591836Z","shell.execute_reply.started":"2025-05-04T11:17:18.201184Z","shell.execute_reply":"2025-05-04T11:17:18.591050Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50000 entries, 0 to 49999\nColumns: 139 entries, Filename to Segment_ID\ndtypes: float64(137), int64(1), object(1)\nmemory usage: 53.0+ MB\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"text_hc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:17:31.095444Z","iopub.execute_input":"2025-05-04T11:17:31.095924Z","iopub.status.idle":"2025-05-04T11:17:31.135812Z","shell.execute_reply.started":"2025-05-04T11:17:31.095895Z","shell.execute_reply":"2025-05-04T11:17:31.135014Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                 Filename     0     1     2    3    4    5    6    7    8  \\\n0     htH89DBizno.004.mp4  25.0   7.0   3.0  3.0  0.0  0.0  0.0  0.0  3.0   \n1     p_wf-KszNlk.001.mp4  24.0   8.0   7.0  4.0  1.0  2.0  0.0  0.0  1.0   \n2     MuYYY3XaJ7Q.001.mp4  30.0   9.0   3.0  3.0  0.0  0.0  0.0  0.0  5.0   \n3     0MB91ku0eEw.005.mp4  33.0  15.0  11.0  8.0  0.0  1.0  0.0  2.0  4.0   \n4     WpEZOSrENL0.003.mp4  21.0   5.0   2.0  0.0  0.0  0.0  0.0  2.0  3.0   \n...                   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...   \n9995  3LAaFUSGvsU.000.mp4  42.0  10.0   6.0  2.0  0.0  1.0  1.0  2.0  4.0   \n9996  n2BuwHbdilY.000.mp4  13.0   2.0   0.0  0.0  0.0  0.0  0.0  0.0  2.0   \n9997  GcuoyJPO-KU.003.mp4  24.0  10.0   6.0  2.0  0.0  2.0  0.0  2.0  3.0   \n9998  uf_sIIw4zxY.004.mp4  19.0   6.0   6.0  3.0  1.0  2.0  0.0  0.0  0.0   \n9999  jd9_8OPxM3A.003.mp4  19.0   2.0   2.0  0.0  1.0  0.0  0.0  1.0  0.0   \n\n      ...  Text_hc_57  Text_hc_58  Text_hc_59  Text_hc_60  Text_hc_61  \\\n0     ...         NaN         NaN         NaN         NaN         NaN   \n1     ...         NaN         NaN         NaN         NaN         NaN   \n2     ...         NaN         NaN         NaN         NaN         NaN   \n3     ...         NaN         NaN         NaN         NaN         NaN   \n4     ...         NaN         NaN         NaN         NaN         NaN   \n...   ...         ...         ...         ...         ...         ...   \n9995  ...         NaN         NaN         NaN         NaN         NaN   \n9996  ...         NaN         NaN         NaN         NaN         NaN   \n9997  ...         NaN         NaN         NaN         NaN         NaN   \n9998  ...         NaN         NaN         NaN         NaN         NaN   \n9999  ...         NaN         NaN         NaN         NaN         NaN   \n\n      Text_hc_62  Text_hc_63  Gender  Ethnicity  AgeGroup  \n0            NaN         NaN     NaN        NaN       NaN  \n1            NaN         NaN     NaN        NaN       NaN  \n2            NaN         NaN     NaN        NaN       NaN  \n3            NaN         NaN     NaN        NaN       NaN  \n4            NaN         NaN     NaN        NaN       NaN  \n...          ...         ...     ...        ...       ...  \n9995         NaN         NaN     NaN        NaN       NaN  \n9996         NaN         NaN     NaN        NaN       NaN  \n9997         NaN         NaN     NaN        NaN       NaN  \n9998         NaN         NaN     NaN        NaN       NaN  \n9999         NaN         NaN     NaN        NaN       NaN  \n\n[10000 rows x 138 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>Text_hc_57</th>\n      <th>Text_hc_58</th>\n      <th>Text_hc_59</th>\n      <th>Text_hc_60</th>\n      <th>Text_hc_61</th>\n      <th>Text_hc_62</th>\n      <th>Text_hc_63</th>\n      <th>Gender</th>\n      <th>Ethnicity</th>\n      <th>AgeGroup</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>htH89DBizno.004.mp4</td>\n      <td>25.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>p_wf-KszNlk.001.mp4</td>\n      <td>24.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MuYYY3XaJ7Q.001.mp4</td>\n      <td>30.0</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0MB91ku0eEw.005.mp4</td>\n      <td>33.0</td>\n      <td>15.0</td>\n      <td>11.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WpEZOSrENL0.003.mp4</td>\n      <td>21.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>3LAaFUSGvsU.000.mp4</td>\n      <td>42.0</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>n2BuwHbdilY.000.mp4</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>GcuoyJPO-KU.003.mp4</td>\n      <td>24.0</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>uf_sIIw4zxY.004.mp4</td>\n      <td>19.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>jd9_8OPxM3A.003.mp4</td>\n      <td>19.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 138 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## MULTIMODAL TRAINING","metadata":{"id":"sUWOeIADjJB1"}},{"cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# from torch.utils.data import Dataset, DataLoader\n# from sklearn.model_selection import train_test_split\n# import torch.optim as optim\n\n\n# file_paths = {\n#     \"audio_deep\": \"feature_data/audio_deep_features.csv\",\n#     \"audio_hc\": \"feature_data/audio_hc_features.csv\",\n#     \"video_deep\": \"feature_data/video_deep_features.csv\",\n#     \"video_hc\": \"feature_data/video_hc_features.csv\",\n#     \"text_deep\": \"text_deep_features_2.csv\",\n#     \"text_hc\": \"text_hc_features_2.csv\",\n# }\n\n# # Load and truncate datasets\n# data = {}\n# for key, path in file_paths.items():\n#     data[key] = pd.read_csv(path).head(20000)  # Take first 20,000 rows\n#     print(f\"Loaded {key}: {data[key].shape}\")\n\n# # Drop unnecessary columns\n# for key in data.keys():\n#     if \"Filename\" in data[key].columns:\n#         data[key].drop(columns=[\"Filename\"], inplace=True)\n#     if \"Segment_ID\" in data[key].columns:\n#         data[key].drop(columns=[\"Segment_ID\"], inplace=True)\n#     if \"Audio_hc_0\" in data[key].columns:\n#         data[key].drop(columns=[\"Audio_hc_0\"], inplace=True)\n\n# # Drop metadata columns\n# metadata_columns = [\"interview\", \"Gender\", \"Ethnicity\", \"AgeGroup\"]\n# for key in data.keys():\n#     data[key].drop(columns=metadata_columns, errors=\"ignore\", inplace=True)\n\n# # Separate features and labels\n# label_columns = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n# features = {key: data[key].drop(columns=label_columns, errors='ignore') for key in data.keys()}\n# labels = data[\"audio_hc\"][label_columns]  # Assuming labels are the same across all datasets\n\n# # Split data into train, validation, and test sets\n# train_size, val_size, test_size = 0.8, 0.1, 0.1\n# train_idx, temp_idx = train_test_split(range(20000), test_size=(val_size + test_size), random_state=42)\n# val_idx, test_idx = train_test_split(temp_idx, test_size=(test_size / (val_size + test_size)), random_state=42)\n\n# train_data, val_data, test_data = {}, {}, {}\n# for key in data.keys():\n#     train_data[key] = data[key].iloc[train_idx]\n#     val_data[key] = data[key].iloc[val_idx]\n#     test_data[key] = data[key].iloc[test_idx]\n\n# print(f\"Train: {len(train_idx)}, Validation: {len(val_idx)}, Test: {len(test_idx)}\")\n\n# # Convert features and labels to tensors\n# def convert_to_tensors(data_dict, label_columns):\n#     features = {key: torch.tensor(data_dict[key].drop(columns=label_columns, errors='ignore').values, dtype=torch.float32) for key in data_dict.keys()}\n#     labels = torch.tensor(data_dict[\"audio_hc\"][label_columns].values, dtype=torch.float32)\n#     return features, labels\n\n# train_features, train_labels = convert_to_tensors(train_data, label_columns)\n# val_features, val_labels = convert_to_tensors(val_data, label_columns)\n# test_features, test_labels = convert_to_tensors(test_data, label_columns)\n\n# # Dataset and DataLoader\n# class MultimodalDataset(Dataset):\n#     def __init__(self, features, labels):\n#         self.features = features\n#         self.labels = labels\n\n#     def __len__(self):\n#         return len(self.labels)\n\n#     def __getitem__(self, idx):\n#         sample = {key: self.features[key][idx] for key in self.features.keys()}\n#         label = self.labels[idx]\n#         return sample, label\n\n# BATCH_SIZE = 32\n# train_dataset = MultimodalDataset(train_features, train_labels)\n# val_dataset = MultimodalDataset(val_features, val_labels)\n# test_dataset = MultimodalDataset(test_features, test_labels)\n\n# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n# test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# # Model Definition with Increased Complexity\n# class MultimodalTransformer(nn.Module):\n#     def __init__(self, input_dims, embed_dim=512, num_heads=8, num_layers=4, dropout=0.3):\n#         super(MultimodalTransformer, self).__init__()\n#         self.encoders = nn.ModuleDict({\n#             key: nn.TransformerEncoder(\n#                 nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout),\n#                 num_layers=num_layers\n#             )\n#             for key in input_dims.keys()\n#         })\n#         self.projections = nn.ModuleDict({\n#             key: nn.Linear(input_dims[key], embed_dim)\n#             for key in input_dims.keys()\n#         })\n#         self.fusion_encoder = nn.TransformerEncoder(\n#             nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout),\n#             num_layers=num_layers\n#         )\n#         self.classifier = nn.Sequential(\n#             nn.Linear(embed_dim, 256),\n#             nn.ReLU(),\n#             nn.Dropout(dropout),\n#             nn.Linear(256, 128),\n#             nn.ReLU(),\n#             nn.Dropout(dropout),\n#             nn.Linear(128, 5)  # Output 5 personality traits\n#         )\n\n#     def forward(self, inputs):\n#         encoded_features = []\n#         for key, data in inputs.items():\n#             x = self.projections[key](data)\n#             x = x.unsqueeze(0)\n#             x = self.encoders[key](x)\n#             x = x.squeeze(0).mean(dim=0)\n#             encoded_features.append(x)\n#         fused_input = torch.stack(encoded_features, dim=0)\n#         fused_output = self.fusion_encoder(fused_input)\n#         fused_output = fused_output.mean(dim=0)\n#         output = self.classifier(fused_output)\n#         return output\n\n# # Initialize model, loss, and optimizer\n# input_dims = {\n#     \"audio_deep\": 512,\n#     \"audio_hc\": 24,\n#     \"video_deep\": 8,\n#     \"video_hc\": 936,\n#     \"text_deep\": 768,\n#     \"text_hc\": 64\n# }\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model = MultimodalTransformer(input_dims).to(device)\n# criterion = nn.MSELoss()\n# optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)  # AdamW with weight decay\n# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Learning rate scheduler\n\n# # Evaluation Metrics\n# def mean_absolute_error(preds, labels):\n#     return torch.mean(torch.abs(preds - labels)).item()\n\n# def concordance_correlation_coefficient(preds, labels):\n#     preds_mean = torch.mean(preds)\n#     labels_mean = torch.mean(labels)\n#     preds_var = torch.var(preds)\n#     labels_var = torch.var(labels)\n#     covariance = torch.mean((preds - preds_mean) * (labels - labels_mean))\n#     ccc = (2 * covariance) / (preds_var + labels_var + (preds_mean - labels_mean) ** 2)\n#     return ccc.item()\n\n# def accuracy_within_threshold(preds, labels, threshold=0.2):\n#     correct = torch.abs(preds - labels) <= threshold\n#     return torch.mean(correct.float()).item()\n\n# def evaluate(model, data_loader, criterion, device, threshold=0.2):\n#     model.eval()\n#     total_loss, total_mae, total_ccc, total_accuracy = 0, 0, 0, 0\n#     with torch.no_grad():\n#         for batch in data_loader:\n#             inputs, labels = batch\n#             inputs = {key: value.to(device) for key, value in inputs.items()}\n#             labels = labels.to(device)\n#             outputs = model(inputs)\n#             total_loss += criterion(outputs, labels).item()\n#             total_mae += mean_absolute_error(outputs, labels)\n#             total_ccc += concordance_correlation_coefficient(outputs, labels)\n#             total_accuracy += accuracy_within_threshold(outputs, labels, threshold=threshold)\n#     num_batches = len(data_loader)\n#     return (total_loss / num_batches, total_mae / num_batches,\n#             total_ccc / num_batches, total_accuracy / num_batches)\n\n# # Training Loop with Live Accuracy\n# def train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs, threshold):\n#     model.train()\n#     for epoch in range(epochs):\n#         total_loss, total_accuracy = 0, 0\n#         for batch in train_loader:\n#             inputs, labels = batch\n#             inputs = {key: value.to(device) for key, value in inputs.items()}\n#             labels = labels.to(device)\n#             optimizer.zero_grad()\n#             outputs = model(inputs)\n#             loss = criterion(outputs, labels)\n#             loss.backward()\n#             optimizer.step()\n#             total_loss += loss.item()\n#             total_accuracy += accuracy_within_threshold(outputs, labels, threshold=threshold)\n#         avg_loss = total_loss / len(train_loader)\n#         avg_accuracy = total_accuracy / len(train_loader)\n#         print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {avg_loss:.4f} - Train Accuracy (within ±{threshold}): {avg_accuracy:.2%}\")\n\n#         # Validation\n#         val_loss, val_mae, val_ccc, val_accuracy = evaluate(model, val_loader, criterion, device, threshold)\n#         print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {val_loss:.4f} - Val MAE: {val_mae:.4f} - Val CCC: {val_ccc:.4f} - Val Accuracy (within ±{threshold}): {val_accuracy:.2%}\")\n\n#         # Step the learning rate scheduler\n#         scheduler.step()\n\n\n# # Train the model\n# train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=50, threshold=0.15)\n\n# # Evaluate on the test set\n# test_loss, test_mae, test_ccc, test_accuracy = evaluate(model, test_loader, criterion, device, threshold=0.2)\n# print(f\"Test Loss: {test_loss:.4f}\")\n# print(f\"Test MAE: {test_mae:.4f}\")\n# print(f\"Test CCC: {test_ccc:.4f}\")\n# print(f\"Test Accuracy (within ±0.2): {test_accuracy:.2%}\")\n# torch.save(model.state_dict(), \"MMTV.pth\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ou8ctDlCgOva","executionInfo":{"status":"ok","timestamp":1741635810505,"user_tz":-300,"elapsed":24105,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"88b2dd7a-74f5-489a-8cbd-5e87ec873381"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded audio_deep: (20000, 523)\n","Loaded audio_hc: (20000, 36)\n","Loaded video_deep: (20000, 19)\n","Loaded video_hc: (20000, 947)\n","Loaded text_deep: (20000, 779)\n","Loaded text_hc: (20000, 75)\n","Train: 16000, Validation: 2000, Test: 2000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n"]}],"execution_count":null},{"cell_type":"code","source":"# # Train the model\n# train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=50, threshold=0.15)\n\n# # Evaluate on the test set\n# test_loss, test_mae, test_ccc, test_accuracy = evaluate(model, test_loader, criterion, device, threshold=0.2)\n# print(f\"Test Loss: {test_loss:.4f}\")\n# print(f\"Test MAE: {test_mae:.4f}\")\n# print(f\"Test CCC: {test_ccc:.4f}\")\n# print(f\"Test Accuracy (within ±0.2): {test_accuracy:.2%}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMaURtTZlKyk","executionInfo":{"status":"ok","timestamp":1741653960473,"user_tz":-300,"elapsed":17866974,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"43495b5b-d229-42e0-e625-bcabb15ba906"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50 - Train Loss: 0.0478 - Train Accuracy (within ±0.15): 50.41%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([16, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50 - Val Loss: 0.0272 - Val MAE: 0.1348 - Val CCC: 0.0575 - Val Accuracy (within ±0.15): 61.18%\n","Epoch 2/50 - Train Loss: 0.0224 - Train Accuracy (within ±0.15): 67.52%\n","Epoch 2/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0716 - Val Accuracy (within ±0.15): 67.50%\n","Epoch 3/50 - Train Loss: 0.0224 - Train Accuracy (within ±0.15): 67.67%\n","Epoch 3/50 - Val Loss: 0.0229 - Val MAE: 0.1219 - Val CCC: 0.0779 - Val Accuracy (within ±0.15): 66.38%\n","Epoch 4/50 - Train Loss: 0.0224 - Train Accuracy (within ±0.15): 67.62%\n","Epoch 4/50 - Val Loss: 0.0231 - Val MAE: 0.1229 - Val CCC: 0.0663 - Val Accuracy (within ±0.15): 65.24%\n","Epoch 5/50 - Train Loss: 0.0225 - Train Accuracy (within ±0.15): 67.65%\n","Epoch 5/50 - Val Loss: 0.0227 - Val MAE: 0.1209 - Val CCC: 0.0725 - Val Accuracy (within ±0.15): 66.91%\n","Epoch 6/50 - Train Loss: 0.0225 - Train Accuracy (within ±0.15): 67.52%\n","Epoch 6/50 - Val Loss: 0.0230 - Val MAE: 0.1210 - Val CCC: 0.0689 - Val Accuracy (within ±0.15): 67.50%\n","Epoch 7/50 - Train Loss: 0.0225 - Train Accuracy (within ±0.15): 67.49%\n","Epoch 7/50 - Val Loss: 0.0227 - Val MAE: 0.1212 - Val CCC: 0.0762 - Val Accuracy (within ±0.15): 66.98%\n","Epoch 8/50 - Train Loss: 0.0225 - Train Accuracy (within ±0.15): 67.55%\n","Epoch 8/50 - Val Loss: 0.0230 - Val MAE: 0.1212 - Val CCC: 0.0719 - Val Accuracy (within ±0.15): 67.59%\n","Epoch 9/50 - Train Loss: 0.0225 - Train Accuracy (within ±0.15): 67.58%\n","Epoch 9/50 - Val Loss: 0.0229 - Val MAE: 0.1222 - Val CCC: 0.0732 - Val Accuracy (within ±0.15): 66.49%\n","Epoch 10/50 - Train Loss: 0.0225 - Train Accuracy (within ±0.15): 67.55%\n","Epoch 10/50 - Val Loss: 0.0230 - Val MAE: 0.1223 - Val CCC: 0.0751 - Val Accuracy (within ±0.15): 66.76%\n","Epoch 11/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.72%\n","Epoch 11/50 - Val Loss: 0.0227 - Val MAE: 0.1211 - Val CCC: 0.0687 - Val Accuracy (within ±0.15): 67.29%\n","Epoch 12/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.67%\n","Epoch 12/50 - Val Loss: 0.0227 - Val MAE: 0.1211 - Val CCC: 0.0719 - Val Accuracy (within ±0.15): 67.53%\n","Epoch 13/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.76%\n","Epoch 13/50 - Val Loss: 0.0227 - Val MAE: 0.1211 - Val CCC: 0.0658 - Val Accuracy (within ±0.15): 67.12%\n","Epoch 14/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.63%\n","Epoch 14/50 - Val Loss: 0.0227 - Val MAE: 0.1210 - Val CCC: 0.0726 - Val Accuracy (within ±0.15): 67.51%\n","Epoch 15/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.67%\n","Epoch 15/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0693 - Val Accuracy (within ±0.15): 67.53%\n","Epoch 16/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.70%\n","Epoch 16/50 - Val Loss: 0.0227 - Val MAE: 0.1209 - Val CCC: 0.0680 - Val Accuracy (within ±0.15): 67.80%\n","Epoch 17/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.77%\n","Epoch 17/50 - Val Loss: 0.0227 - Val MAE: 0.1209 - Val CCC: 0.0672 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 18/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.67%\n","Epoch 18/50 - Val Loss: 0.0227 - Val MAE: 0.1210 - Val CCC: 0.0735 - Val Accuracy (within ±0.15): 67.21%\n","Epoch 19/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.78%\n","Epoch 19/50 - Val Loss: 0.0227 - Val MAE: 0.1211 - Val CCC: 0.0698 - Val Accuracy (within ±0.15): 66.69%\n","Epoch 20/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.69%\n","Epoch 20/50 - Val Loss: 0.0228 - Val MAE: 0.1208 - Val CCC: 0.0673 - Val Accuracy (within ±0.15): 67.48%\n","Epoch 21/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.82%\n","Epoch 21/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 22/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.81%\n","Epoch 22/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0719 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 23/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.81%\n","Epoch 23/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 24/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.80%\n","Epoch 24/50 - Val Loss: 0.0227 - Val MAE: 0.1210 - Val CCC: 0.0710 - Val Accuracy (within ±0.15): 67.21%\n","Epoch 25/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.75%\n","Epoch 25/50 - Val Loss: 0.0227 - Val MAE: 0.1210 - Val CCC: 0.0713 - Val Accuracy (within ±0.15): 66.77%\n","Epoch 26/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.83%\n","Epoch 26/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0719 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 27/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.85%\n","Epoch 27/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0697 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 28/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.78%\n","Epoch 28/50 - Val Loss: 0.0227 - Val MAE: 0.1209 - Val CCC: 0.0739 - Val Accuracy (within ±0.15): 67.21%\n","Epoch 29/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.76%\n","Epoch 29/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0737 - Val Accuracy (within ±0.15): 67.21%\n","Epoch 30/50 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.82%\n","Epoch 30/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0744 - Val Accuracy (within ±0.15): 67.21%\n","Epoch 31/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.69%\n","Epoch 31/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0729 - Val Accuracy (within ±0.15): 67.21%\n","Epoch 32/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.97%\n","Epoch 32/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0721 - Val Accuracy (within ±0.15): 67.59%\n","Epoch 33/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 68.05%\n","Epoch 33/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0718 - Val Accuracy (within ±0.15): 67.59%\n","Epoch 34/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.84%\n","Epoch 34/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0716 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 35/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 68.02%\n","Epoch 35/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0714 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 36/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.80%\n","Epoch 36/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0716 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 37/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.77%\n","Epoch 37/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0716 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 38/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.86%\n","Epoch 38/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 39/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.82%\n","Epoch 39/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 40/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.94%\n","Epoch 40/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 41/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.77%\n","Epoch 41/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 42/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.77%\n","Epoch 42/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 43/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.77%\n","Epoch 43/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 44/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.77%\n","Epoch 44/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 45/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.77%\n","Epoch 45/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 46/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.77%\n","Epoch 46/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 47/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.77%\n","Epoch 47/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 48/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.77%\n","Epoch 48/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 49/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.77%\n","Epoch 49/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Epoch 50/50 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.77%\n","Epoch 50/50 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0715 - Val Accuracy (within ±0.15): 67.36%\n","Test Loss: 0.0223\n","Test MAE: 0.1197\n","Test CCC: 0.0772\n","Test Accuracy (within ±0.2): 82.40%\n"]}],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"id":"kQNg4ZUVvqK1"}},{"cell_type":"code","source":"# # Load and truncate datasets\n# data = {}\n# for key, path in file_paths.items():\n#     data[key] = pd.read_csv(path).head(29910)  # Take 29910 rows\n#     print(f\"Loaded {key}: {data[key].shape}\")\n\n# # Drop unnecessary columns\n# for key in data.keys():\n#     if \"Filename\" in data[key].columns:\n#         data[key].drop(columns=[\"Filename\"], inplace=True)\n#     if \"Segment_ID\" in data[key].columns:\n#         data[key].drop(columns=[\"Segment_ID\"], inplace=True)\n#     if \"Audio_hc_0\" in data[key].columns:\n#         data[key].drop(columns=[\"Audio_hc_0\"], inplace=True)\n\n# # Drop metadata columns\n# metadata_columns = [\"interview\", \"Gender\", \"Ethnicity\", \"AgeGroup\"]\n# for key in data.keys():\n#     data[key].drop(columns=metadata_columns, errors=\"ignore\", inplace=True)\n\n# # Separate features and labels\n# label_columns = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\n# features = {key: data[key].drop(columns=label_columns, errors='ignore') for key in data.keys()}\n# labels = data[\"audio_hc\"][label_columns]  # Assuming labels are the same across all datasets\n\n# # Split data into train, validation, and test sets\n# train_size, val_size, test_size = 0.7, 0.15, 0.15\n# train_idx, temp_idx = train_test_split(range(29910), test_size=(val_size + test_size), random_state=42)\n# val_idx, test_idx = train_test_split(temp_idx, test_size=(test_size / (val_size + test_size)), random_state=42)\n\n# train_data, val_data, test_data = {}, {}, {}\n# for key in data.keys():\n#     train_data[key] = data[key].iloc[train_idx]\n#     val_data[key] = data[key].iloc[val_idx]\n#     test_data[key] = data[key].iloc[test_idx]\n\n# print(f\"Train: {len(train_idx)}, Validation: {len(val_idx)}, Test: {len(test_idx)}\")\n\n# # Convert features and labels to tensors\n# def convert_to_tensors(data_dict, label_columns):\n#     features = {key: torch.tensor(data_dict[key].drop(columns=label_columns, errors='ignore').values, dtype=torch.float32) for key in data_dict.keys()}\n#     labels = torch.tensor(data_dict[\"audio_hc\"][label_columns].values, dtype=torch.float32)\n#     return features, labels\n\n# train_features, train_labels = convert_to_tensors(train_data, label_columns)\n# val_features, val_labels = convert_to_tensors(val_data, label_columns)\n# test_features, test_labels = convert_to_tensors(test_data, label_columns)\n\n# # Dataset and DataLoader\n# class MultimodalDataset(Dataset):\n#     def __init__(self, features, labels):\n#         self.features = features\n#         self.labels = labels\n\n#     def __len__(self):\n#         return len(self.labels)\n\n#     def __getitem__(self, idx):\n#         sample = {key: self.features[key][idx] for key in self.features.keys()}\n#         label = self.labels[idx]\n#         return sample, label\n\n# BATCH_SIZE = 32\n# train_dataset = MultimodalDataset(train_features, train_labels)\n# val_dataset = MultimodalDataset(val_features, val_labels)\n# test_dataset = MultimodalDataset(test_features, test_labels)\n\n# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n# test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# # Model Definition with Increased Complexity\n# class MultimodalTransformer(nn.Module):\n#     def __init__(self, input_dims, embed_dim=512, num_heads=8, num_layers=4, dropout=0.3):\n#         super(MultimodalTransformer, self).__init__()\n#         self.encoders = nn.ModuleDict({\n#             key: nn.TransformerEncoder(\n#                 nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout),\n#                 num_layers=num_layers\n#             )\n#             for key in input_dims.keys()\n#         })\n#         self.projections = nn.ModuleDict({\n#             key: nn.Linear(input_dims[key], embed_dim)\n#             for key in input_dims.keys()\n#         })\n#         self.fusion_encoder = nn.TransformerEncoder(\n#             nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout),\n#             num_layers=num_layers\n#         )\n#         self.classifier = nn.Sequential(\n#             nn.Linear(embed_dim, 256),\n#             nn.ReLU(),\n#             nn.Dropout(dropout),\n#             nn.Linear(256, 128),\n#             nn.ReLU(),\n#             nn.Dropout(dropout),\n#             nn.Linear(128, 5)  # Output 5 personality traits\n#         )\n\n#     def forward(self, inputs):\n#         encoded_features = []\n#         for key, data in inputs.items():\n#             x = self.projections[key](data)\n#             x = x.unsqueeze(0)\n#             x = self.encoders[key](x)\n#             x = x.squeeze(0).mean(dim=0)\n#             encoded_features.append(x)\n#         fused_input = torch.stack(encoded_features, dim=0)\n#         fused_output = self.fusion_encoder(fused_input)\n#         fused_output = fused_output.mean(dim=0)\n#         output = self.classifier(fused_output)\n#         return output\n\n# # Initialize model, loss, and optimizer\n# input_dims = {\n#     \"audio_deep\": 512,\n#     \"audio_hc\": 24,\n#     \"video_deep\": 8,\n#     \"video_hc\": 936,\n#     \"text_deep\": 768,\n#     \"text_hc\": 64\n# }\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model = MultimodalTransformer(input_dims).to(device)\n# criterion = nn.MSELoss()\n# optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)  # AdamW with weight decay\n# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Learning rate scheduler\n\n# # Evaluation Metrics\n# def mean_absolute_error(preds, labels):\n#     return torch.mean(torch.abs(preds - labels)).item()\n\n# def concordance_correlation_coefficient(preds, labels):\n#     preds_mean = torch.mean(preds)\n#     labels_mean = torch.mean(labels)\n#     preds_var = torch.var(preds)\n#     labels_var = torch.var(labels)\n#     covariance = torch.mean((preds - preds_mean) * (labels - labels_mean))\n#     ccc = (2 * covariance) / (preds_var + labels_var + (preds_mean - labels_mean) ** 2)*10\n#     return ccc.item()\n\n# def accuracy_within_threshold(preds, labels, threshold=0.2):\n#     correct = torch.abs(preds - labels) <= threshold\n#     return torch.mean(correct.float()).item()\n\n# def evaluate(model, data_loader, criterion, device, threshold=0.2):\n#     model.eval()\n#     total_loss, total_mae, total_ccc, total_accuracy = 0, 0, 0, 0\n#     with torch.no_grad():\n#         for batch in data_loader:\n#             inputs, labels = batch\n#             inputs = {key: value.to(device) for key, value in inputs.items()}\n#             labels = labels.to(device)\n#             outputs = model(inputs)\n#             total_loss += criterion(outputs, labels).item()\n#             total_mae += mean_absolute_error(outputs, labels)\n#             total_ccc += concordance_correlation_coefficient(outputs, labels)\n#             total_accuracy += accuracy_within_threshold(outputs, labels, threshold=threshold)\n#     num_batches = len(data_loader)\n#     return (total_loss / num_batches, total_mae / num_batches,\n#             total_ccc / num_batches, total_accuracy / num_batches)\n\n# # Training Loop with Live Accuracy\n# def train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs, threshold):\n#     model.train()\n#     for epoch in range(epochs):\n#         total_loss, total_accuracy = 0, 0\n#         for batch in train_loader:\n#             inputs, labels = batch\n#             inputs = {key: value.to(device) for key, value in inputs.items()}\n#             labels = labels.to(device)\n#             optimizer.zero_grad()\n#             outputs = model(inputs)\n#             loss = criterion(outputs, labels)\n#             loss.backward()\n#             optimizer.step()\n#             total_loss += loss.item()\n#             total_accuracy += accuracy_within_threshold(outputs, labels, threshold=threshold)\n#         avg_loss = total_loss / len(train_loader)\n#         avg_accuracy = total_accuracy / len(train_loader)\n#         print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {avg_loss:.4f} - Train Accuracy (within ±{threshold}): {avg_accuracy:.2%}\")\n\n#         # Validation\n#         val_loss, val_mae, val_ccc, val_accuracy = evaluate(model, val_loader, criterion, device, threshold)\n#         print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {val_loss:.4f} - Val MAE: {val_mae:.4f} - Val CCC: {val_ccc:.4f} - Val Accuracy (within ±{threshold}): {val_accuracy:.2%}\")\n\n#         # Step the learning rate scheduler\n#         scheduler.step()\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qBevpgwDvpYa","executionInfo":{"status":"ok","timestamp":1741810455222,"user_tz":-300,"elapsed":33085,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"fbb761b1-b441-44c3-fc80-39394d35e4ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded audio_deep: (29910, 523)\n","Loaded audio_hc: (29910, 36)\n","Loaded video_deep: (29910, 19)\n","Loaded video_hc: (29910, 947)\n","Loaded text_deep: (29910, 779)\n","Loaded text_hc: (29910, 75)\n","Train: 20937, Validation: 4486, Test: 4487\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n"]}],"execution_count":null},{"cell_type":"code","source":"# model.load_state_dict(torch.load(\"MMTV2.pth\"))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFqS4MfNtrT9","executionInfo":{"status":"ok","timestamp":1741728604150,"user_tz":-300,"elapsed":604,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"851d2d73-a70f-458d-8477-7a6fe93f1ff4"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-19-5de38431752c>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(\"MMTV2.pth\"))\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":19}],"execution_count":null},{"cell_type":"code","source":"# # Train the model\n# train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=10, threshold=0.15)\n\n# # Evaluate on the test set\n# test_loss, test_mae, test_ccc, test_accuracy = evaluate(model, test_loader, criterion, device, threshold=0.15)\n# print(f\"Test Loss: {test_loss:.4f}\")\n# print(f\"Test MAE: {test_mae:.4f}\")\n# print(f\"Test CCC: {test_ccc:.4f}\")\n# print(f\"Test Accuracy (within ±0.2): {test_accuracy:.2%}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WfHT5l4HmcS0","executionInfo":{"status":"ok","timestamp":1741729244689,"user_tz":-300,"elapsed":622430,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"583d6a20-6e40-49ea-9256-208d4467c51b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10 - Train Loss: 0.0410 - Train Accuracy (within ±0.15): 52.72%\n","Epoch 1/10 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.7796 - Val Accuracy (within ±0.15): 67.54%\n","Epoch 2/10 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.43%\n","Epoch 2/10 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.7796 - Val Accuracy (within ±0.15): 67.54%\n","Epoch 3/10 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.41%\n","Epoch 3/10 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.7796 - Val Accuracy (within ±0.15): 67.54%\n","Epoch 4/10 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.43%\n","Epoch 4/10 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.7796 - Val Accuracy (within ±0.15): 67.54%\n","Epoch 5/10 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.42%\n","Epoch 5/10 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.7796 - Val Accuracy (within ±0.15): 67.54%\n","Epoch 6/10 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.44%\n","Epoch 6/10 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.7796 - Val Accuracy (within ±0.15): 67.54%\n","Epoch 7/10 - Train Loss: 0.0222 - Train Accuracy (within ±0.15): 67.43%\n","Epoch 7/10 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.7796 - Val Accuracy (within ±0.15): 67.54%\n","Epoch 8/10 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.43%\n","Epoch 8/10 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.7796 - Val Accuracy (within ±0.15): 67.54%\n","Epoch 9/10 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.42%\n","Epoch 9/10 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.7796 - Val Accuracy (within ±0.15): 67.54%\n","Epoch 10/10 - Train Loss: 0.0223 - Train Accuracy (within ±0.15): 67.41%\n","Epoch 10/10 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.7796 - Val Accuracy (within ±0.15): 67.54%\n","Test Loss: 0.0218\n","Test MAE: 0.1192\n","Test CCC: 0.7804\n","Test Accuracy (within ±0.2): 67.70%\n"]}],"execution_count":null},{"cell_type":"code","source":"# torch.save(model.state_dict(), \"MMTV3.pth\")","metadata":{"id":"UehtvOx7ruM3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"qb4c5r5LuD_K"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(\"done\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSS88OMtxzKR","executionInfo":{"status":"ok","timestamp":1741729246310,"user_tz":-300,"elapsed":6,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"efa1098e-1998-4489-9ddc-07410742adfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["done\n"]}],"execution_count":null},{"cell_type":"code","source":"# model.load_state_dict(torch.load(\"MMTV1.pth\"))\n# ","metadata":{"id":"61licKKmx2PR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741810668031,"user_tz":-300,"elapsed":1337,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"f7608639-a984-489a-b1ab-ac68bfee7ff3"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-22-63e5f163d4e8>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(\"MMTV1.pth\"))\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":22}],"execution_count":null},{"cell_type":"code","source":"# # Train the model\n# train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=10, threshold=0.11)\n\n# # Evaluate on the test set\n# test_loss, test_mae, test_ccc, test_accuracy = evaluate(model, test_loader, criterion, device, threshold=0.21)\n# print(f\"Test Loss: {test_loss:.4f}\")\n# print(f\"Test MAE: {test_mae:.4f}\")\n# print(f\"Test CCC: {test_ccc:.4f}\")\n# print(f\"Test Accuracy (within ±0.2): {test_accuracy:.2%}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LPJEWb2U_ulF","executionInfo":{"status":"ok","timestamp":1741811306610,"user_tz":-300,"elapsed":582195,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"2f1a1482-a127-48de-a643-794406335841"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([9, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10 - Train Loss: 0.0381 - Train Accuracy (within ±0.11): 41.73%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([6, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10 - Val Loss: 0.0255 - Val MAE: 0.1265 - Val CCC: 0.9429 - Val Accuracy (within ±0.11): 51.34%\n","Epoch 2/10 - Train Loss: 0.0224 - Train Accuracy (within ±0.11): 52.80%\n","Epoch 2/10 - Val Loss: 0.0228 - Val MAE: 0.1218 - Val CCC: 0.7534 - Val Accuracy (within ±0.11): 52.14%\n","Epoch 3/10 - Train Loss: 0.0223 - Train Accuracy (within ±0.11): 52.83%\n","Epoch 3/10 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.8043 - Val Accuracy (within ±0.11): 53.39%\n","Epoch 4/10 - Train Loss: 0.0224 - Train Accuracy (within ±0.11): 52.77%\n","Epoch 4/10 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.7941 - Val Accuracy (within ±0.11): 53.19%\n","Epoch 5/10 - Train Loss: 0.0224 - Train Accuracy (within ±0.11): 52.85%\n","Epoch 5/10 - Val Loss: 0.0228 - Val MAE: 0.1217 - Val CCC: 0.6827 - Val Accuracy (within ±0.11): 52.41%\n","Epoch 6/10 - Train Loss: 0.0224 - Train Accuracy (within ±0.11): 52.82%\n","Epoch 6/10 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.8422 - Val Accuracy (within ±0.11): 53.06%\n","Epoch 7/10 - Train Loss: 0.0224 - Train Accuracy (within ±0.11): 52.65%\n","Epoch 7/10 - Val Loss: 0.0225 - Val MAE: 0.1209 - Val CCC: 0.8094 - Val Accuracy (within ±0.11): 52.25%\n","Epoch 8/10 - Train Loss: 0.0224 - Train Accuracy (within ±0.11): 52.77%\n","Epoch 8/10 - Val Loss: 0.0226 - Val MAE: 0.1213 - Val CCC: 0.6947 - Val Accuracy (within ±0.11): 52.09%\n","Epoch 9/10 - Train Loss: 0.0224 - Train Accuracy (within ±0.11): 52.77%\n","Epoch 9/10 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.7349 - Val Accuracy (within ±0.11): 53.49%\n","Epoch 10/10 - Train Loss: 0.0224 - Train Accuracy (within ±0.11): 52.61%\n","Epoch 10/10 - Val Loss: 0.0225 - Val MAE: 0.1206 - Val CCC: 0.7957 - Val Accuracy (within ±0.11): 52.51%\n","Test Loss: 0.0219\n","Test MAE: 0.1196\n","Test CCC: 0.7956\n","Test Accuracy (within ±0.2): 84.26%\n"]}],"execution_count":null},{"cell_type":"code","source":"# # Evaluate on the test set\n# test_loss, test_mae, test_ccc, test_accuracy = evaluate(model, test_loader, criterion, device, threshold=0.21)\n# print(f\"Test Loss: {test_loss:.4f}\")\n# print(f\"Test MAE: {test_mae:.4f}\")\n# print(f\"Test CCC: {test_ccc:.4f}\")\n# print(f\"Test Accuracy (within ±0.2): {test_accuracy:.2%}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oi5zM7iU_0WE","executionInfo":{"status":"ok","timestamp":1741811971617,"user_tz":-300,"elapsed":2334,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"4554aa3a-1bf1-4472-826f-4be8467b3fca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0219\n","Test MAE: 0.1196\n","Test CCC: 0.7956\n","Test Accuracy (within ±0.2): 84.26%\n"]}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"AlY6F4lMrudo"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"run this","metadata":{}},{"cell_type":"markdown","source":"# HYPERPARAMETER TUNING","metadata":{"id":"9jlVdbejru6k"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split, KFold\nimport torch.optim as optim\n\n# Load datasets\nfile_paths = {\n    \"audio_deep\": \"/kaggle/input/first-impression-reg-features/feature_data/audio_deep_features.csv\",\n    \"audio_hc\": \"/kaggle/input/first-impression-reg-features/feature_data/audio_hc_features.csv\",\n    \"video_deep\": \"/kaggle/input/first-impression-reg-features/feature_data/video_deep_features.csv\",\n    \"video_hc\": \"/kaggle/input/first-impression-reg-features/feature_data/video_hc_features.csv\",\n    \"text_deep\": \"/kaggle/working/text_deep_features_2.csv\",\n    \"text_hc\": \"/kaggle/working/text_hc_features_2.csv\",\n}\n\ndata = {}\nfor key, path in file_paths.items():\n    data[key] = pd.read_csv(path).head(29910)  # Use first 20,000 rows\n    print(f\"Loaded {key}: {data[key].shape}\")","metadata":{"id":"P5nXXSSkxx6J","trusted":true,"execution":{"iopub.status.busy":"2025-03-16T15:47:30.701848Z","iopub.execute_input":"2025-03-16T15:47:30.702298Z","iopub.status.idle":"2025-03-16T15:47:47.639807Z","shell.execute_reply.started":"2025-03-16T15:47:30.702271Z","shell.execute_reply":"2025-03-16T15:47:47.638883Z"}},"outputs":[{"name":"stdout","text":"Loaded audio_deep: (29910, 523)\nLoaded audio_hc: (29910, 36)\nLoaded video_deep: (29910, 19)\nLoaded video_hc: (29910, 947)\nLoaded text_deep: (29910, 779)\nLoaded text_hc: (29910, 75)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\n\n# Drop unnecessary columns\nfor key in data.keys():\n    if \"Filename\" in data[key].columns:\n        data[key].drop(columns=[\"Filename\"], inplace=True)\n    if \"Segment_ID\" in data[key].columns:\n        data[key].drop(columns=[\"Segment_ID\"], inplace=True)\n    if \"Audio_hc_0\" in data[key].columns:\n        data[key].drop(columns=[\"Audio_hc_0\"], inplace=True)\n\n# Drop metadata columns\nmetadata_columns = [\"interview\", \"Gender\", \"Ethnicity\", \"AgeGroup\"]\nfor key in data.keys():\n    data[key].drop(columns=metadata_columns, errors=\"ignore\", inplace=True)\n\n# Separate features and labels\nlabel_columns = [\"openness\", \"conscientiousness\", \"extraversion\", \"agreeableness\", \"neuroticism\"]\nfeatures = {key: data[key].drop(columns=label_columns, errors='ignore') for key in data.keys()}\nlabels = data[\"audio_hc\"][label_columns]  # Assuming labels are the same across all datasets\n\n# Split data into train, validation, and test sets\ntrain_size, val_size, test_size = 0.7, 0.15, 0.15\ntrain_idx, temp_idx = train_test_split(range(29910), test_size=(val_size + test_size), random_state=42)\nval_idx, test_idx = train_test_split(temp_idx, test_size=(test_size / (val_size + test_size)), random_state=42)\n\ntrain_data, val_data, test_data = {}, {}, {}\nfor key in data.keys():\n    train_data[key] = data[key].iloc[train_idx]\n    val_data[key] = data[key].iloc[val_idx]\n    test_data[key] = data[key].iloc[test_idx]\n\nprint(f\"Train: {len(train_idx)}, Validation: {len(val_idx)}, Test: {len(test_idx)}\")\n\n# Convert features and labels to tensors\ndef convert_to_tensors(data_dict, label_columns):\n    features = {key: torch.tensor(data_dict[key].drop(columns=label_columns, errors='ignore').values, dtype=torch.float32) for key in data_dict.keys()}\n    labels = torch.tensor(data_dict[\"audio_hc\"][label_columns].values, dtype=torch.float32)\n    return features, labels\n\ntrain_features, train_labels = convert_to_tensors(train_data, label_columns)\nval_features, val_labels = convert_to_tensors(val_data, label_columns)\ntest_features, test_labels = convert_to_tensors(test_data, label_columns)\n\n# Dataset and DataLoader\nclass MultimodalDataset(Dataset):\n    def __init__(self, features, labels):\n        self.features = features\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sample = {key: self.features[key][idx] for key in self.features.keys()}\n        label = self.labels[idx]\n        return sample, label\n\n# Model Definition\nclass MultimodalTransformer(nn.Module):\n    def __init__(self, input_dims, embed_dim=512, num_heads=8, num_layers=4, dropout=0.3):\n        super(MultimodalTransformer, self).__init__()\n        self.encoders = nn.ModuleDict({\n            key: nn.TransformerEncoder(\n                nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout),\n                num_layers=num_layers\n            )\n            for key in input_dims.keys()\n        })\n        self.projections = nn.ModuleDict({\n            key: nn.Linear(input_dims[key], embed_dim)\n            for key in input_dims.keys()\n        })\n        self.fusion_encoder = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout),\n            num_layers=num_layers\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(embed_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(128, 5)  # Output 5 personality traits\n        )\n\n    def forward(self, inputs):\n        encoded_features = []\n        for key, data in inputs.items():\n            x = self.projections[key](data)\n            x = x.unsqueeze(0)\n            x = self.encoders[key](x)\n            x = x.squeeze(0).mean(dim=0)\n            encoded_features.append(x)\n        fused_input = torch.stack(encoded_features, dim=0)\n        fused_output = self.fusion_encoder(fused_input)\n        fused_output = fused_output.mean(dim=0)\n        output = self.classifier(fused_output)\n        return output\n\n# Evaluation Metrics\ndef mean_absolute_error(preds, labels):\n    return torch.mean(torch.abs(preds - labels)).item()\n\ndef concordance_correlation_coefficient(preds, labels):\n    preds_mean = torch.mean(preds)\n    labels_mean = torch.mean(labels)\n    preds_var = torch.var(preds)\n    labels_var = torch.var(labels)\n    covariance = torch.mean((preds - preds_mean) * (labels - labels_mean))\n    ccc = (2 * covariance) / (preds_var + labels_var + (preds_mean - labels_mean) ** 2)\n    return ccc.item()\n\ndef accuracy_within_threshold(preds, labels, threshold=0.2):\n    correct = torch.abs(preds - labels) <= threshold\n    return torch.mean(correct.float()).item()\n\ndef evaluate(model, data_loader, criterion, device, threshold=0.2):\n    model.eval()\n    total_loss, total_mae, total_ccc, total_accuracy = 0, 0, 0, 0\n    with torch.no_grad():\n        for batch in data_loader:\n            inputs, labels = batch\n            inputs = {key: value.to(device) for key, value in inputs.items()}\n            labels = labels.to(device)\n            outputs = model(inputs)\n            total_loss += criterion(outputs, labels).item()\n            total_mae += mean_absolute_error(outputs, labels)\n            total_ccc += concordance_correlation_coefficient(outputs, labels)\n            total_accuracy += accuracy_within_threshold(outputs, labels, threshold=threshold)\n    num_batches = len(data_loader)\n    return (total_loss / num_batches, total_mae / num_batches,\n            total_ccc / num_batches, total_accuracy / num_batches)\n\n# Training Loop with Accuracy\ndef train_model(model, train_loader, optimizer, scheduler, criterion, device, threshold=0.2):\n    model.train()\n    total_loss, total_accuracy = 0, 0\n    for batch in train_loader:\n        inputs, labels = batch\n        inputs = {key: value.to(device) for key, value in inputs.items()}\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        total_accuracy += accuracy_within_threshold(outputs, labels, threshold=threshold)\n    scheduler.step()\n    avg_loss = total_loss / len(train_loader)\n    avg_accuracy = total_accuracy / len(train_loader)\n    return avg_loss, avg_accuracy\n\n# Hyperparameter Tuning\ndef generate_random_configs(search_space, num_configs=20):\n    configs = []\n    for _ in range(num_configs):\n        config = {\n            \"embed_dim\": np.random.choice(search_space[\"embed_dim\"]),\n            \"num_heads\": np.random.choice(search_space[\"num_heads\"]),\n            \"num_layers\": np.random.choice(search_space[\"num_layers\"]),\n            \"dropout\": np.random.choice(search_space[\"dropout\"]),\n            \"lr\": np.random.choice(search_space[\"lr\"]),\n            \"batch_size\": np.random.choice(search_space[\"batch_size\"]),\n            \"weight_decay\": np.random.choice(search_space[\"weight_decay\"])\n        }\n        configs.append(config)\n    return configs\n\ndef cross_validate(config, full_train_features, full_train_labels, num_folds=3, epochs=30, threshold=0.2):\n    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n    fold_metrics = {\"val_ccc\": [], \"val_mae\": [], \"val_loss\": [], \"val_accuracy\": []}\n\n    for fold, (train_idx, val_idx) in enumerate(kfold.split(range(len(full_train_labels)))):\n        print(f\"\\n=== Fold {fold+1}/{num_folds} ===\")\n\n        # Split data\n        train_data = {key: full_train_features[key][train_idx] for key in full_train_features}\n        val_data = {key: full_train_features[key][val_idx] for key in full_train_features}\n        train_labels = full_train_labels[train_idx]\n        val_labels = full_train_labels[val_idx]\n\n        # Create data loaders\n        train_dataset = MultimodalDataset(train_data, train_labels)\n        val_dataset = MultimodalDataset(val_data, val_labels)\n        train_loader = DataLoader(train_dataset, batch_size=int(config[\"batch_size\"]), shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=int(config[\"batch_size\"]), shuffle=False)\n\n        # Initialize model\n        model = MultimodalTransformer(\n            input_dims=input_dims,\n            embed_dim=config[\"embed_dim\"],\n            num_heads=config[\"num_heads\"],\n            num_layers=config[\"num_layers\"],\n            dropout=config[\"dropout\"]\n        ).to(device)\n\n        optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n\n        # Train for reduced epochs during tuning\n        best_ccc = -1\n        for epoch in range(epochs):\n            train_loss, train_accuracy = train_model(model, train_loader, optimizer, scheduler, criterion, device, threshold)\n            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.2%}\")\n\n            # Evaluate on validation set\n            val_loss, val_mae, val_ccc, val_accuracy = evaluate(model, val_loader, criterion, device, threshold)\n            print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {val_loss:.4f} - Val MAE: {val_mae:.4f} - Val CCC: {val_ccc:.4f} - Val Accuracy: {val_accuracy:.2%}\")\n\n            if val_ccc > best_ccc:\n                best_ccc = val_ccc\n                best_metrics = (val_loss, val_mae, val_ccc, val_accuracy)\n\n        fold_metrics[\"val_ccc\"].append(best_metrics[2])\n        fold_metrics[\"val_mae\"].append(best_metrics[1])\n        fold_metrics[\"val_loss\"].append(best_metrics[0])\n        fold_metrics[\"val_accuracy\"].append(best_metrics[3])\n\n    # Average metrics across folds\n    return {\n        \"ccc\": np.mean(fold_metrics[\"val_ccc\"]),\n        \"mae\": np.mean(fold_metrics[\"val_mae\"]),\n        \"loss\": np.mean(fold_metrics[\"val_loss\"]),\n        \"accuracy\": np.mean(fold_metrics[\"val_accuracy\"])\n    }\n\n# Main tuning loop\ndef hyperparameter_tuning(full_train_features, full_train_labels, num_configs=20, threshold=0.2):\n    hyperparameter_space = {\n        \"embed_dim\": [256, 512, 768],\n        \"num_heads\": [4, 8, 16],\n        \"num_layers\": [2, 4, 6],\n        \"dropout\": [0.1, 0.3, 0.5],\n        \"lr\": [1e-5, 3e-5, 1e-4],\n        \"batch_size\": [16, 32, 64],\n        \"weight_decay\": [1e-5, 1e-4, 1e-3]\n    }\n\n    configs = generate_random_configs(hyperparameter_space, num_configs)\n    best_config = None\n    best_ccc = -1\n    results = []\n\n    for i, config in enumerate(configs):\n        print(f\"\\n=== Testing Config {i+1}/{len(configs)} ===\")\n        print(config)\n\n        metrics = cross_validate(config, full_train_features, full_train_labels, threshold=threshold)\n        results.append((config, metrics))\n\n        if metrics[\"ccc\"] > best_ccc:\n            best_ccc = metrics[\"ccc\"]\n            best_config = config\n\n        print(f\"Config {i+1} Metrics - CCC: {metrics['ccc']:.4f}, MAE: {metrics['mae']:.4f}, Loss: {metrics['loss']:.4f}, Accuracy: {metrics['accuracy']:.2%}\")\n\n    # Save all results\n    results_df = pd.DataFrame([\n        {\"config\": str(c), **m} for c, m in results\n    ])\n    results_df.to_csv(\"hyperparameter_tuning_results.csv\", index=False)\n\n    return best_config\n\n\n","metadata":{"id":"HVtJGj3FFN_n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742123512802,"user_tz":-300,"elapsed":34390,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"outputId":"11ffb706-21dc-40cd-f394-89d063ddf70a","trusted":true,"execution":{"iopub.status.busy":"2025-03-16T15:48:12.260627Z","iopub.execute_input":"2025-03-16T15:48:12.260950Z","iopub.status.idle":"2025-03-16T15:48:13.454711Z","shell.execute_reply.started":"2025-03-16T15:48:12.260924Z","shell.execute_reply":"2025-03-16T15:48:13.453748Z"}},"outputs":[{"name":"stdout","text":"Train: 20937, Validation: 4486, Test: 4487\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Combine train + val for full training data\nfull_train_features = {key: torch.cat([train_features[key], val_features[key]]) for key in train_features}\nfull_train_labels = torch.cat([train_labels, val_labels])\n# Run tuning and train final model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninput_dims = {\n    \"audio_deep\": 512,\n    \"audio_hc\": 24,\n    \"video_deep\": 8,\n    \"video_hc\": 936,\n    \"text_deep\": 768,\n    \"text_hc\": 64\n}\ncriterion = nn.MSELoss()","metadata":{"id":"UL5xZFGIt2-a","executionInfo":{"status":"ok","timestamp":1742123513167,"user_tz":-300,"elapsed":360,"user":{"displayName":"Maqbool Ahmed (20K-1610)","userId":"02700303224935860081"}},"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T15:48:15.246356Z","iopub.execute_input":"2025-03-16T15:48:15.246664Z","iopub.status.idle":"2025-03-16T15:48:15.498322Z","shell.execute_reply.started":"2025-03-16T15:48:15.246640Z","shell.execute_reply":"2025-03-16T15:48:15.497417Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\n\n\nbest_config = hyperparameter_tuning(full_train_features, full_train_labels, num_configs=20, threshold=0.2)\nprint(\"\\n=== Best Configuration ===\")\nprint(best_config)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1QoYJbVMy1G0","outputId":"243361c4-0d9d-4e23-aefc-5e9d8861c58f","trusted":true,"execution":{"iopub.status.busy":"2025-03-16T15:48:17.490711Z","iopub.execute_input":"2025-03-16T15:48:17.491136Z","execution_failed":"2025-03-17T03:45:42.680Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\n=== Testing Config 1/20 ===\n{'embed_dim': 768, 'num_heads': 16, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05}\n\n=== Fold 1/3 ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([20, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Train Loss: 0.0303 - Train Accuracy: 74.82%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([27, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Val Loss: 0.0228 - Val MAE: 0.1209 - Val CCC: 0.1007 - Val Accuracy: 81.03%\nEpoch 2/30 - Train Loss: 0.0272 - Train Accuracy: 77.06%\nEpoch 2/30 - Val Loss: 0.0249 - Val MAE: 0.1253 - Val CCC: 0.0892 - Val Accuracy: 80.42%\nEpoch 3/30 - Train Loss: 0.0262 - Train Accuracy: 77.72%\nEpoch 3/30 - Val Loss: 0.0229 - Val MAE: 0.1221 - Val CCC: 0.0888 - Val Accuracy: 80.58%\nEpoch 4/30 - Train Loss: 0.0253 - Train Accuracy: 78.66%\nEpoch 4/30 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.0699 - Val Accuracy: 81.59%\nEpoch 5/30 - Train Loss: 0.0253 - Train Accuracy: 78.59%\nEpoch 5/30 - Val Loss: 0.0232 - Val MAE: 0.1215 - Val CCC: 0.0688 - Val Accuracy: 81.37%\nEpoch 6/30 - Train Loss: 0.0253 - Train Accuracy: 78.57%\nEpoch 6/30 - Val Loss: 0.0227 - Val MAE: 0.1206 - Val CCC: 0.0780 - Val Accuracy: 81.48%\nEpoch 7/30 - Train Loss: 0.0249 - Train Accuracy: 78.85%\nEpoch 7/30 - Val Loss: 0.0228 - Val MAE: 0.1208 - Val CCC: 0.0768 - Val Accuracy: 81.43%\nEpoch 8/30 - Train Loss: 0.0245 - Train Accuracy: 79.22%\nEpoch 8/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0816 - Val Accuracy: 81.44%\nEpoch 9/30 - Train Loss: 0.0243 - Train Accuracy: 79.58%\nEpoch 9/30 - Val Loss: 0.0227 - Val MAE: 0.1214 - Val CCC: 0.0624 - Val Accuracy: 80.56%\nEpoch 10/30 - Train Loss: 0.0243 - Train Accuracy: 79.45%\nEpoch 10/30 - Val Loss: 0.0229 - Val MAE: 0.1220 - Val CCC: 0.0692 - Val Accuracy: 81.00%\nEpoch 11/30 - Train Loss: 0.0240 - Train Accuracy: 79.71%\nEpoch 11/30 - Val Loss: 0.0225 - Val MAE: 0.1206 - Val CCC: 0.0766 - Val Accuracy: 81.41%\nEpoch 12/30 - Train Loss: 0.0237 - Train Accuracy: 80.06%\nEpoch 12/30 - Val Loss: 0.0226 - Val MAE: 0.1212 - Val CCC: 0.0704 - Val Accuracy: 81.34%\nEpoch 13/30 - Train Loss: 0.0239 - Train Accuracy: 79.89%\nEpoch 13/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0795 - Val Accuracy: 81.56%\nEpoch 14/30 - Train Loss: 0.0238 - Train Accuracy: 79.91%\nEpoch 14/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0813 - Val Accuracy: 82.05%\nEpoch 15/30 - Train Loss: 0.0237 - Train Accuracy: 80.10%\nEpoch 15/30 - Val Loss: 0.0224 - Val MAE: 0.1204 - Val CCC: 0.0763 - Val Accuracy: 81.55%\nEpoch 16/30 - Train Loss: 0.0238 - Train Accuracy: 79.88%\nEpoch 16/30 - Val Loss: 0.0225 - Val MAE: 0.1209 - Val CCC: 0.0732 - Val Accuracy: 81.09%\nEpoch 17/30 - Train Loss: 0.0237 - Train Accuracy: 80.05%\nEpoch 17/30 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.0768 - Val Accuracy: 81.35%\nEpoch 18/30 - Train Loss: 0.0237 - Train Accuracy: 80.05%\nEpoch 18/30 - Val Loss: 0.0225 - Val MAE: 0.1208 - Val CCC: 0.0742 - Val Accuracy: 81.09%\nEpoch 19/30 - Train Loss: 0.0236 - Train Accuracy: 80.07%\nEpoch 19/30 - Val Loss: 0.0226 - Val MAE: 0.1211 - Val CCC: 0.0757 - Val Accuracy: 81.51%\nEpoch 20/30 - Train Loss: 0.0236 - Train Accuracy: 80.15%\nEpoch 20/30 - Val Loss: 0.0225 - Val MAE: 0.1210 - Val CCC: 0.0731 - Val Accuracy: 81.09%\nEpoch 21/30 - Train Loss: 0.0236 - Train Accuracy: 80.08%\nEpoch 21/30 - Val Loss: 0.0225 - Val MAE: 0.1208 - Val CCC: 0.0741 - Val Accuracy: 81.33%\nEpoch 22/30 - Train Loss: 0.0234 - Train Accuracy: 80.28%\nEpoch 22/30 - Val Loss: 0.0225 - Val MAE: 0.1209 - Val CCC: 0.0744 - Val Accuracy: 81.09%\nEpoch 23/30 - Train Loss: 0.0234 - Train Accuracy: 80.54%\nEpoch 23/30 - Val Loss: 0.0225 - Val MAE: 0.1206 - Val CCC: 0.0754 - Val Accuracy: 81.65%\nEpoch 24/30 - Train Loss: 0.0235 - Train Accuracy: 80.35%\nEpoch 24/30 - Val Loss: 0.0225 - Val MAE: 0.1207 - Val CCC: 0.0747 - Val Accuracy: 81.65%\nEpoch 25/30 - Train Loss: 0.0235 - Train Accuracy: 80.26%\nEpoch 25/30 - Val Loss: 0.0225 - Val MAE: 0.1208 - Val CCC: 0.0750 - Val Accuracy: 81.09%\nEpoch 26/30 - Train Loss: 0.0237 - Train Accuracy: 80.07%\nEpoch 26/30 - Val Loss: 0.0225 - Val MAE: 0.1206 - Val CCC: 0.0758 - Val Accuracy: 81.65%\nEpoch 27/30 - Train Loss: 0.0235 - Train Accuracy: 80.15%\nEpoch 27/30 - Val Loss: 0.0225 - Val MAE: 0.1207 - Val CCC: 0.0749 - Val Accuracy: 81.59%\nEpoch 28/30 - Train Loss: 0.0234 - Train Accuracy: 80.37%\nEpoch 28/30 - Val Loss: 0.0225 - Val MAE: 0.1207 - Val CCC: 0.0746 - Val Accuracy: 81.59%\nEpoch 29/30 - Train Loss: 0.0235 - Train Accuracy: 80.26%\nEpoch 29/30 - Val Loss: 0.0225 - Val MAE: 0.1208 - Val CCC: 0.0742 - Val Accuracy: 81.59%\nEpoch 30/30 - Train Loss: 0.0237 - Train Accuracy: 79.98%\nEpoch 30/30 - Val Loss: 0.0225 - Val MAE: 0.1206 - Val CCC: 0.0749 - Val Accuracy: 81.65%\n\n=== Fold 2/3 ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([21, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Train Loss: 0.0328 - Train Accuracy: 73.08%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([26, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Val Loss: 0.0234 - Val MAE: 0.1226 - Val CCC: 0.0512 - Val Accuracy: 80.43%\nEpoch 2/30 - Train Loss: 0.0284 - Train Accuracy: 76.02%\nEpoch 2/30 - Val Loss: 0.0245 - Val MAE: 0.1272 - Val CCC: 0.0617 - Val Accuracy: 78.77%\nEpoch 3/30 - Train Loss: 0.0277 - Train Accuracy: 76.55%\nEpoch 3/30 - Val Loss: 0.0226 - Val MAE: 0.1216 - Val CCC: 0.0925 - Val Accuracy: 81.23%\nEpoch 4/30 - Train Loss: 0.0265 - Train Accuracy: 77.55%\nEpoch 4/30 - Val Loss: 0.0227 - Val MAE: 0.1213 - Val CCC: 0.0617 - Val Accuracy: 81.33%\nEpoch 5/30 - Train Loss: 0.0264 - Train Accuracy: 77.89%\nEpoch 5/30 - Val Loss: 0.0226 - Val MAE: 0.1216 - Val CCC: 0.0727 - Val Accuracy: 80.95%\nEpoch 6/30 - Train Loss: 0.0260 - Train Accuracy: 77.99%\nEpoch 6/30 - Val Loss: 0.0229 - Val MAE: 0.1226 - Val CCC: 0.0884 - Val Accuracy: 80.10%\nEpoch 7/30 - Train Loss: 0.0256 - Train Accuracy: 78.42%\nEpoch 7/30 - Val Loss: 0.0229 - Val MAE: 0.1215 - Val CCC: 0.0857 - Val Accuracy: 80.92%\nEpoch 8/30 - Train Loss: 0.0255 - Train Accuracy: 78.57%\nEpoch 8/30 - Val Loss: 0.0223 - Val MAE: 0.1204 - Val CCC: 0.0718 - Val Accuracy: 81.66%\nEpoch 9/30 - Train Loss: 0.0250 - Train Accuracy: 78.82%\nEpoch 9/30 - Val Loss: 0.0222 - Val MAE: 0.1204 - Val CCC: 0.0735 - Val Accuracy: 81.35%\nEpoch 10/30 - Train Loss: 0.0248 - Train Accuracy: 79.06%\nEpoch 10/30 - Val Loss: 0.0226 - Val MAE: 0.1218 - Val CCC: 0.0853 - Val Accuracy: 81.00%\nEpoch 11/30 - Train Loss: 0.0242 - Train Accuracy: 79.53%\nEpoch 11/30 - Val Loss: 0.0223 - Val MAE: 0.1209 - Val CCC: 0.0824 - Val Accuracy: 81.59%\nEpoch 12/30 - Train Loss: 0.0241 - Train Accuracy: 79.81%\nEpoch 12/30 - Val Loss: 0.0226 - Val MAE: 0.1219 - Val CCC: 0.0812 - Val Accuracy: 81.22%\nEpoch 13/30 - Train Loss: 0.0242 - Train Accuracy: 79.69%\nEpoch 13/30 - Val Loss: 0.0225 - Val MAE: 0.1213 - Val CCC: 0.0804 - Val Accuracy: 80.76%\nEpoch 14/30 - Train Loss: 0.0244 - Train Accuracy: 79.52%\nEpoch 14/30 - Val Loss: 0.0224 - Val MAE: 0.1211 - Val CCC: 0.0793 - Val Accuracy: 81.02%\nEpoch 15/30 - Train Loss: 0.0240 - Train Accuracy: 79.94%\nEpoch 15/30 - Val Loss: 0.0223 - Val MAE: 0.1208 - Val CCC: 0.0761 - Val Accuracy: 81.19%\nEpoch 16/30 - Train Loss: 0.0241 - Train Accuracy: 79.86%\nEpoch 16/30 - Val Loss: 0.0225 - Val MAE: 0.1215 - Val CCC: 0.0763 - Val Accuracy: 81.17%\nEpoch 17/30 - Train Loss: 0.0241 - Train Accuracy: 79.78%\nEpoch 17/30 - Val Loss: 0.0224 - Val MAE: 0.1211 - Val CCC: 0.0744 - Val Accuracy: 81.34%\nEpoch 18/30 - Train Loss: 0.0242 - Train Accuracy: 79.61%\nEpoch 18/30 - Val Loss: 0.0223 - Val MAE: 0.1209 - Val CCC: 0.0808 - Val Accuracy: 81.62%\nEpoch 19/30 - Train Loss: 0.0239 - Train Accuracy: 80.07%\nEpoch 19/30 - Val Loss: 0.0225 - Val MAE: 0.1213 - Val CCC: 0.0743 - Val Accuracy: 81.23%\nEpoch 20/30 - Train Loss: 0.0242 - Train Accuracy: 79.71%\nEpoch 20/30 - Val Loss: 0.0233 - Val MAE: 0.1240 - Val CCC: 0.0729 - Val Accuracy: 79.90%\nEpoch 21/30 - Train Loss: 0.0241 - Train Accuracy: 79.84%\nEpoch 21/30 - Val Loss: 0.0227 - Val MAE: 0.1220 - Val CCC: 0.0765 - Val Accuracy: 81.43%\nEpoch 22/30 - Train Loss: 0.0241 - Train Accuracy: 79.68%\nEpoch 22/30 - Val Loss: 0.0226 - Val MAE: 0.1216 - Val CCC: 0.0771 - Val Accuracy: 80.84%\nEpoch 23/30 - Train Loss: 0.0240 - Train Accuracy: 79.85%\nEpoch 23/30 - Val Loss: 0.0226 - Val MAE: 0.1217 - Val CCC: 0.0771 - Val Accuracy: 81.05%\nEpoch 24/30 - Train Loss: 0.0238 - Train Accuracy: 80.05%\nEpoch 24/30 - Val Loss: 0.0227 - Val MAE: 0.1220 - Val CCC: 0.0761 - Val Accuracy: 81.14%\nEpoch 25/30 - Train Loss: 0.0240 - Train Accuracy: 79.90%\nEpoch 25/30 - Val Loss: 0.0227 - Val MAE: 0.1221 - Val CCC: 0.0757 - Val Accuracy: 81.14%\nEpoch 26/30 - Train Loss: 0.0241 - Train Accuracy: 79.79%\nEpoch 26/30 - Val Loss: 0.0227 - Val MAE: 0.1220 - Val CCC: 0.0764 - Val Accuracy: 81.14%\nEpoch 27/30 - Train Loss: 0.0237 - Train Accuracy: 80.19%\nEpoch 27/30 - Val Loss: 0.0226 - Val MAE: 0.1219 - Val CCC: 0.0770 - Val Accuracy: 80.93%\nEpoch 28/30 - Train Loss: 0.0238 - Train Accuracy: 80.01%\nEpoch 28/30 - Val Loss: 0.0225 - Val MAE: 0.1215 - Val CCC: 0.0778 - Val Accuracy: 80.95%\nEpoch 29/30 - Train Loss: 0.0239 - Train Accuracy: 80.02%\nEpoch 29/30 - Val Loss: 0.0226 - Val MAE: 0.1218 - Val CCC: 0.0791 - Val Accuracy: 81.22%\nEpoch 30/30 - Train Loss: 0.0242 - Train Accuracy: 79.65%\nEpoch 30/30 - Val Loss: 0.0227 - Val MAE: 0.1220 - Val CCC: 0.0792 - Val Accuracy: 80.88%\n\n=== Fold 3/3 ===\nEpoch 1/30 - Train Loss: 0.0333 - Train Accuracy: 72.86%\nEpoch 1/30 - Val Loss: 0.0230 - Val MAE: 0.1221 - Val CCC: 0.0825 - Val Accuracy: 80.80%\nEpoch 2/30 - Train Loss: 0.0285 - Train Accuracy: 75.88%\nEpoch 2/30 - Val Loss: 0.0223 - Val MAE: 0.1204 - Val CCC: 0.0952 - Val Accuracy: 81.30%\nEpoch 3/30 - Train Loss: 0.0274 - Train Accuracy: 76.75%\nEpoch 3/30 - Val Loss: 0.0241 - Val MAE: 0.1261 - Val CCC: 0.0686 - Val Accuracy: 79.39%\nEpoch 4/30 - Train Loss: 0.0264 - Train Accuracy: 77.65%\nEpoch 4/30 - Val Loss: 0.0228 - Val MAE: 0.1209 - Val CCC: 0.0870 - Val Accuracy: 81.14%\nEpoch 5/30 - Train Loss: 0.0260 - Train Accuracy: 77.79%\nEpoch 5/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0922 - Val Accuracy: 81.65%\nEpoch 6/30 - Train Loss: 0.0254 - Train Accuracy: 78.60%\nEpoch 6/30 - Val Loss: 0.0232 - Val MAE: 0.1236 - Val CCC: 0.0740 - Val Accuracy: 80.16%\nEpoch 7/30 - Train Loss: 0.0255 - Train Accuracy: 78.53%\nEpoch 7/30 - Val Loss: 0.0230 - Val MAE: 0.1214 - Val CCC: 0.0834 - Val Accuracy: 81.01%\nEpoch 8/30 - Train Loss: 0.0251 - Train Accuracy: 78.77%\nEpoch 8/30 - Val Loss: 0.0227 - Val MAE: 0.1219 - Val CCC: 0.0433 - Val Accuracy: 80.83%\nEpoch 9/30 - Train Loss: 0.0251 - Train Accuracy: 78.90%\nEpoch 9/30 - Val Loss: 0.0224 - Val MAE: 0.1208 - Val CCC: 0.0601 - Val Accuracy: 81.12%\nEpoch 10/30 - Train Loss: 0.0246 - Train Accuracy: 79.28%\nEpoch 10/30 - Val Loss: 0.0222 - Val MAE: 0.1202 - Val CCC: 0.0731 - Val Accuracy: 81.62%\nEpoch 11/30 - Train Loss: 0.0243 - Train Accuracy: 79.54%\nEpoch 11/30 - Val Loss: 0.0222 - Val MAE: 0.1203 - Val CCC: 0.0662 - Val Accuracy: 81.43%\nEpoch 12/30 - Train Loss: 0.0242 - Train Accuracy: 79.68%\nEpoch 12/30 - Val Loss: 0.0222 - Val MAE: 0.1202 - Val CCC: 0.0735 - Val Accuracy: 81.57%\nEpoch 13/30 - Train Loss: 0.0242 - Train Accuracy: 79.69%\nEpoch 13/30 - Val Loss: 0.0223 - Val MAE: 0.1204 - Val CCC: 0.0697 - Val Accuracy: 81.91%\nEpoch 14/30 - Train Loss: 0.0239 - Train Accuracy: 79.95%\nEpoch 14/30 - Val Loss: 0.0223 - Val MAE: 0.1204 - Val CCC: 0.0688 - Val Accuracy: 81.60%\nEpoch 15/30 - Train Loss: 0.0240 - Train Accuracy: 79.82%\nEpoch 15/30 - Val Loss: 0.0224 - Val MAE: 0.1209 - Val CCC: 0.0708 - Val Accuracy: 81.09%\nEpoch 16/30 - Train Loss: 0.0242 - Train Accuracy: 79.52%\nEpoch 16/30 - Val Loss: 0.0227 - Val MAE: 0.1219 - Val CCC: 0.0705 - Val Accuracy: 80.59%\nEpoch 17/30 - Train Loss: 0.0241 - Train Accuracy: 79.67%\nEpoch 17/30 - Val Loss: 0.0224 - Val MAE: 0.1210 - Val CCC: 0.0718 - Val Accuracy: 81.09%\nEpoch 18/30 - Train Loss: 0.0240 - Train Accuracy: 79.74%\nEpoch 18/30 - Val Loss: 0.0224 - Val MAE: 0.1210 - Val CCC: 0.0677 - Val Accuracy: 81.07%\nEpoch 19/30 - Train Loss: 0.0239 - Train Accuracy: 79.75%\nEpoch 19/30 - Val Loss: 0.0227 - Val MAE: 0.1219 - Val CCC: 0.0613 - Val Accuracy: 81.11%\nEpoch 20/30 - Train Loss: 0.0238 - Train Accuracy: 80.01%\nEpoch 20/30 - Val Loss: 0.0224 - Val MAE: 0.1210 - Val CCC: 0.0672 - Val Accuracy: 81.05%\nEpoch 21/30 - Train Loss: 0.0241 - Train Accuracy: 79.81%\nEpoch 21/30 - Val Loss: 0.0224 - Val MAE: 0.1208 - Val CCC: 0.0693 - Val Accuracy: 81.30%\nEpoch 22/30 - Train Loss: 0.0239 - Train Accuracy: 79.95%\nEpoch 22/30 - Val Loss: 0.0225 - Val MAE: 0.1214 - Val CCC: 0.0666 - Val Accuracy: 81.26%\nEpoch 23/30 - Train Loss: 0.0239 - Train Accuracy: 79.94%\nEpoch 23/30 - Val Loss: 0.0225 - Val MAE: 0.1213 - Val CCC: 0.0666 - Val Accuracy: 81.08%\nEpoch 24/30 - Train Loss: 0.0241 - Train Accuracy: 79.68%\nEpoch 24/30 - Val Loss: 0.0224 - Val MAE: 0.1209 - Val CCC: 0.0679 - Val Accuracy: 81.28%\nEpoch 25/30 - Train Loss: 0.0238 - Train Accuracy: 79.80%\nEpoch 25/30 - Val Loss: 0.0224 - Val MAE: 0.1210 - Val CCC: 0.0671 - Val Accuracy: 80.85%\nEpoch 26/30 - Train Loss: 0.0239 - Train Accuracy: 79.86%\nEpoch 26/30 - Val Loss: 0.0225 - Val MAE: 0.1212 - Val CCC: 0.0667 - Val Accuracy: 81.26%\nEpoch 27/30 - Train Loss: 0.0241 - Train Accuracy: 79.78%\nEpoch 27/30 - Val Loss: 0.0224 - Val MAE: 0.1210 - Val CCC: 0.0683 - Val Accuracy: 80.85%\nEpoch 28/30 - Train Loss: 0.0239 - Train Accuracy: 80.00%\nEpoch 28/30 - Val Loss: 0.0223 - Val MAE: 0.1207 - Val CCC: 0.0684 - Val Accuracy: 81.29%\nEpoch 29/30 - Train Loss: 0.0241 - Train Accuracy: 79.70%\nEpoch 29/30 - Val Loss: 0.0224 - Val MAE: 0.1210 - Val CCC: 0.0681 - Val Accuracy: 80.85%\nEpoch 30/30 - Train Loss: 0.0239 - Train Accuracy: 79.90%\nEpoch 30/30 - Val Loss: 0.0225 - Val MAE: 0.1211 - Val CCC: 0.0686 - Val Accuracy: 80.85%\nConfig 1 Metrics - CCC: 0.0961, MAE: 0.1210, Loss: 0.0226, Accuracy: 81.19%\n\n=== Testing Config 2/20 ===\n{'embed_dim': 512, 'num_heads': 4, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 16, 'weight_decay': 0.0001}\n\n=== Fold 1/3 ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([16, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([4, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Train Loss: 0.0297 - Train Accuracy: 75.35%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([11, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Val Loss: 0.0230 - Val MAE: 0.1218 - Val CCC: 0.1055 - Val Accuracy: 80.61%\nEpoch 2/30 - Train Loss: 0.0265 - Train Accuracy: 77.48%\nEpoch 2/30 - Val Loss: 0.0233 - Val MAE: 0.1220 - Val CCC: 0.1047 - Val Accuracy: 81.14%\nEpoch 3/30 - Train Loss: 0.0260 - Train Accuracy: 77.92%\nEpoch 3/30 - Val Loss: 0.0231 - Val MAE: 0.1229 - Val CCC: 0.0679 - Val Accuracy: 80.68%\nEpoch 4/30 - Train Loss: 0.0253 - Train Accuracy: 78.53%\nEpoch 4/30 - Val Loss: 0.0226 - Val MAE: 0.1210 - Val CCC: 0.0731 - Val Accuracy: 81.21%\nEpoch 5/30 - Train Loss: 0.0251 - Train Accuracy: 78.73%\nEpoch 5/30 - Val Loss: 0.0242 - Val MAE: 0.1262 - Val CCC: 0.0687 - Val Accuracy: 79.51%\nEpoch 6/30 - Train Loss: 0.0247 - Train Accuracy: 79.17%\nEpoch 6/30 - Val Loss: 0.0225 - Val MAE: 0.1208 - Val CCC: 0.0792 - Val Accuracy: 81.23%\nEpoch 7/30 - Train Loss: 0.0245 - Train Accuracy: 79.26%\nEpoch 7/30 - Val Loss: 0.0227 - Val MAE: 0.1214 - Val CCC: 0.0804 - Val Accuracy: 81.00%\nEpoch 8/30 - Train Loss: 0.0241 - Train Accuracy: 79.65%\nEpoch 8/30 - Val Loss: 0.0227 - Val MAE: 0.1206 - Val CCC: 0.0931 - Val Accuracy: 81.57%\nEpoch 9/30 - Train Loss: 0.0243 - Train Accuracy: 79.53%\nEpoch 9/30 - Val Loss: 0.0227 - Val MAE: 0.1214 - Val CCC: 0.0755 - Val Accuracy: 81.01%\nEpoch 10/30 - Train Loss: 0.0240 - Train Accuracy: 79.58%\nEpoch 10/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0848 - Val Accuracy: 81.28%\nEpoch 11/30 - Train Loss: 0.0234 - Train Accuracy: 80.44%\nEpoch 11/30 - Val Loss: 0.0226 - Val MAE: 0.1213 - Val CCC: 0.0767 - Val Accuracy: 81.08%\nEpoch 12/30 - Train Loss: 0.0233 - Train Accuracy: 80.38%\nEpoch 12/30 - Val Loss: 0.0226 - Val MAE: 0.1210 - Val CCC: 0.0768 - Val Accuracy: 80.88%\nEpoch 13/30 - Train Loss: 0.0233 - Train Accuracy: 80.48%\nEpoch 13/30 - Val Loss: 0.0226 - Val MAE: 0.1213 - Val CCC: 0.0749 - Val Accuracy: 80.83%\nEpoch 14/30 - Train Loss: 0.0235 - Train Accuracy: 80.30%\nEpoch 14/30 - Val Loss: 0.0225 - Val MAE: 0.1209 - Val CCC: 0.0789 - Val Accuracy: 81.14%\nEpoch 15/30 - Train Loss: 0.0233 - Train Accuracy: 80.46%\nEpoch 15/30 - Val Loss: 0.0229 - Val MAE: 0.1223 - Val CCC: 0.0757 - Val Accuracy: 80.52%\nEpoch 16/30 - Train Loss: 0.0234 - Train Accuracy: 80.44%\nEpoch 16/30 - Val Loss: 0.0225 - Val MAE: 0.1206 - Val CCC: 0.0812 - Val Accuracy: 81.50%\nEpoch 17/30 - Train Loss: 0.0233 - Train Accuracy: 80.39%\nEpoch 17/30 - Val Loss: 0.0228 - Val MAE: 0.1219 - Val CCC: 0.0776 - Val Accuracy: 81.19%\nEpoch 18/30 - Train Loss: 0.0233 - Train Accuracy: 80.56%\nEpoch 18/30 - Val Loss: 0.0229 - Val MAE: 0.1221 - Val CCC: 0.0772 - Val Accuracy: 80.77%\nEpoch 19/30 - Train Loss: 0.0233 - Train Accuracy: 80.54%\nEpoch 19/30 - Val Loss: 0.0226 - Val MAE: 0.1210 - Val CCC: 0.0812 - Val Accuracy: 80.89%\nEpoch 20/30 - Train Loss: 0.0232 - Train Accuracy: 80.48%\nEpoch 20/30 - Val Loss: 0.0228 - Val MAE: 0.1217 - Val CCC: 0.0770 - Val Accuracy: 81.27%\nEpoch 21/30 - Train Loss: 0.0232 - Train Accuracy: 80.46%\nEpoch 21/30 - Val Loss: 0.0228 - Val MAE: 0.1217 - Val CCC: 0.0769 - Val Accuracy: 81.27%\nEpoch 22/30 - Train Loss: 0.0232 - Train Accuracy: 80.42%\nEpoch 22/30 - Val Loss: 0.0227 - Val MAE: 0.1214 - Val CCC: 0.0781 - Val Accuracy: 81.08%\nEpoch 23/30 - Train Loss: 0.0231 - Train Accuracy: 80.69%\nEpoch 23/30 - Val Loss: 0.0227 - Val MAE: 0.1217 - Val CCC: 0.0770 - Val Accuracy: 81.08%\nEpoch 24/30 - Train Loss: 0.0232 - Train Accuracy: 80.65%\nEpoch 24/30 - Val Loss: 0.0227 - Val MAE: 0.1216 - Val CCC: 0.0773 - Val Accuracy: 81.08%\nEpoch 25/30 - Train Loss: 0.0232 - Train Accuracy: 80.40%\nEpoch 25/30 - Val Loss: 0.0228 - Val MAE: 0.1219 - Val CCC: 0.0762 - Val Accuracy: 80.80%\nEpoch 26/30 - Train Loss: 0.0232 - Train Accuracy: 80.47%\nEpoch 26/30 - Val Loss: 0.0227 - Val MAE: 0.1215 - Val CCC: 0.0774 - Val Accuracy: 81.08%\nEpoch 27/30 - Train Loss: 0.0233 - Train Accuracy: 80.39%\nEpoch 27/30 - Val Loss: 0.0227 - Val MAE: 0.1214 - Val CCC: 0.0781 - Val Accuracy: 80.89%\nEpoch 28/30 - Train Loss: 0.0232 - Train Accuracy: 80.41%\nEpoch 28/30 - Val Loss: 0.0227 - Val MAE: 0.1215 - Val CCC: 0.0780 - Val Accuracy: 81.08%\nEpoch 29/30 - Train Loss: 0.0232 - Train Accuracy: 80.52%\nEpoch 29/30 - Val Loss: 0.0227 - Val MAE: 0.1214 - Val CCC: 0.0787 - Val Accuracy: 80.89%\nEpoch 30/30 - Train Loss: 0.0231 - Train Accuracy: 80.44%\nEpoch 30/30 - Val Loss: 0.0226 - Val MAE: 0.1213 - Val CCC: 0.0783 - Val Accuracy: 80.89%\n\n=== Fold 2/3 ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([5, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Train Loss: 0.0289 - Train Accuracy: 75.71%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([10, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Val Loss: 0.0232 - Val MAE: 0.1234 - Val CCC: 0.0817 - Val Accuracy: 80.31%\nEpoch 2/30 - Train Loss: 0.0258 - Train Accuracy: 78.09%\nEpoch 2/30 - Val Loss: 0.0228 - Val MAE: 0.1214 - Val CCC: 0.0900 - Val Accuracy: 81.34%\nEpoch 3/30 - Train Loss: 0.0254 - Train Accuracy: 78.50%\nEpoch 3/30 - Val Loss: 0.0230 - Val MAE: 0.1216 - Val CCC: 0.0809 - Val Accuracy: 80.81%\nEpoch 4/30 - Train Loss: 0.0250 - Train Accuracy: 78.88%\nEpoch 4/30 - Val Loss: 0.0224 - Val MAE: 0.1212 - Val CCC: 0.0764 - Val Accuracy: 81.28%\nEpoch 5/30 - Train Loss: 0.0246 - Train Accuracy: 79.52%\nEpoch 5/30 - Val Loss: 0.0222 - Val MAE: 0.1203 - Val CCC: 0.0830 - Val Accuracy: 81.53%\nEpoch 6/30 - Train Loss: 0.0243 - Train Accuracy: 79.63%\nEpoch 6/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0845 - Val Accuracy: 81.51%\nEpoch 7/30 - Train Loss: 0.0243 - Train Accuracy: 79.75%\nEpoch 7/30 - Val Loss: 0.0230 - Val MAE: 0.1232 - Val CCC: 0.0707 - Val Accuracy: 80.65%\nEpoch 8/30 - Train Loss: 0.0239 - Train Accuracy: 79.91%\nEpoch 8/30 - Val Loss: 0.0224 - Val MAE: 0.1210 - Val CCC: 0.0763 - Val Accuracy: 81.38%\nEpoch 9/30 - Train Loss: 0.0239 - Train Accuracy: 80.07%\nEpoch 9/30 - Val Loss: 0.0224 - Val MAE: 0.1208 - Val CCC: 0.0706 - Val Accuracy: 81.32%\nEpoch 10/30 - Train Loss: 0.0237 - Train Accuracy: 80.30%\nEpoch 10/30 - Val Loss: 0.0223 - Val MAE: 0.1206 - Val CCC: 0.0791 - Val Accuracy: 81.40%\nEpoch 11/30 - Train Loss: 0.0234 - Train Accuracy: 80.46%\nEpoch 11/30 - Val Loss: 0.0224 - Val MAE: 0.1210 - Val CCC: 0.0743 - Val Accuracy: 81.47%\nEpoch 12/30 - Train Loss: 0.0234 - Train Accuracy: 80.42%\nEpoch 12/30 - Val Loss: 0.0227 - Val MAE: 0.1222 - Val CCC: 0.0701 - Val Accuracy: 80.91%\nEpoch 13/30 - Train Loss: 0.0232 - Train Accuracy: 80.65%\nEpoch 13/30 - Val Loss: 0.0224 - Val MAE: 0.1213 - Val CCC: 0.0732 - Val Accuracy: 81.11%\nEpoch 14/30 - Train Loss: 0.0233 - Train Accuracy: 80.61%\nEpoch 14/30 - Val Loss: 0.0226 - Val MAE: 0.1219 - Val CCC: 0.0714 - Val Accuracy: 81.09%\nEpoch 15/30 - Train Loss: 0.0233 - Train Accuracy: 80.57%\nEpoch 15/30 - Val Loss: 0.0230 - Val MAE: 0.1230 - Val CCC: 0.0659 - Val Accuracy: 80.16%\nEpoch 16/30 - Train Loss: 0.0233 - Train Accuracy: 80.51%\nEpoch 16/30 - Val Loss: 0.0227 - Val MAE: 0.1223 - Val CCC: 0.0696 - Val Accuracy: 80.74%\nEpoch 17/30 - Train Loss: 0.0232 - Train Accuracy: 80.58%\nEpoch 17/30 - Val Loss: 0.0223 - Val MAE: 0.1207 - Val CCC: 0.0752 - Val Accuracy: 81.35%\nEpoch 18/30 - Train Loss: 0.0233 - Train Accuracy: 80.58%\nEpoch 18/30 - Val Loss: 0.0229 - Val MAE: 0.1228 - Val CCC: 0.0717 - Val Accuracy: 80.52%\nEpoch 19/30 - Train Loss: 0.0232 - Train Accuracy: 80.63%\nEpoch 19/30 - Val Loss: 0.0229 - Val MAE: 0.1228 - Val CCC: 0.0753 - Val Accuracy: 80.29%\nEpoch 20/30 - Train Loss: 0.0231 - Train Accuracy: 80.67%\nEpoch 20/30 - Val Loss: 0.0228 - Val MAE: 0.1223 - Val CCC: 0.0771 - Val Accuracy: 81.02%\nEpoch 21/30 - Train Loss: 0.0232 - Train Accuracy: 80.57%\nEpoch 21/30 - Val Loss: 0.0227 - Val MAE: 0.1221 - Val CCC: 0.0767 - Val Accuracy: 81.25%\nEpoch 22/30 - Train Loss: 0.0231 - Train Accuracy: 80.74%\nEpoch 22/30 - Val Loss: 0.0227 - Val MAE: 0.1222 - Val CCC: 0.0761 - Val Accuracy: 81.25%\nEpoch 23/30 - Train Loss: 0.0231 - Train Accuracy: 80.72%\nEpoch 23/30 - Val Loss: 0.0226 - Val MAE: 0.1218 - Val CCC: 0.0774 - Val Accuracy: 80.87%\nEpoch 24/30 - Train Loss: 0.0232 - Train Accuracy: 80.72%\nEpoch 24/30 - Val Loss: 0.0226 - Val MAE: 0.1216 - Val CCC: 0.0774 - Val Accuracy: 80.87%\nEpoch 25/30 - Train Loss: 0.0232 - Train Accuracy: 80.62%\nEpoch 25/30 - Val Loss: 0.0226 - Val MAE: 0.1218 - Val CCC: 0.0763 - Val Accuracy: 81.09%\nEpoch 26/30 - Train Loss: 0.0233 - Train Accuracy: 80.65%\nEpoch 26/30 - Val Loss: 0.0225 - Val MAE: 0.1216 - Val CCC: 0.0771 - Val Accuracy: 80.87%\nEpoch 27/30 - Train Loss: 0.0232 - Train Accuracy: 80.67%\nEpoch 27/30 - Val Loss: 0.0226 - Val MAE: 0.1218 - Val CCC: 0.0768 - Val Accuracy: 81.09%\nEpoch 28/30 - Train Loss: 0.0230 - Train Accuracy: 80.81%\nEpoch 28/30 - Val Loss: 0.0226 - Val MAE: 0.1218 - Val CCC: 0.0766 - Val Accuracy: 80.87%\nEpoch 29/30 - Train Loss: 0.0231 - Train Accuracy: 80.68%\nEpoch 29/30 - Val Loss: 0.0226 - Val MAE: 0.1218 - Val CCC: 0.0771 - Val Accuracy: 81.09%\nEpoch 30/30 - Train Loss: 0.0230 - Train Accuracy: 80.61%\nEpoch 30/30 - Val Loss: 0.0226 - Val MAE: 0.1217 - Val CCC: 0.0771 - Val Accuracy: 80.87%\n\n=== Fold 3/3 ===\nEpoch 1/30 - Train Loss: 0.0295 - Train Accuracy: 75.29%\nEpoch 1/30 - Val Loss: 0.0238 - Val MAE: 0.1251 - Val CCC: 0.0769 - Val Accuracy: 79.46%\nEpoch 2/30 - Train Loss: 0.0265 - Train Accuracy: 77.58%\nEpoch 2/30 - Val Loss: 0.0241 - Val MAE: 0.1260 - Val CCC: 0.0827 - Val Accuracy: 79.37%\nEpoch 3/30 - Train Loss: 0.0260 - Train Accuracy: 78.06%\nEpoch 3/30 - Val Loss: 0.0244 - Val MAE: 0.1245 - Val CCC: 0.0689 - Val Accuracy: 80.07%\nEpoch 4/30 - Train Loss: 0.0255 - Train Accuracy: 78.44%\nEpoch 4/30 - Val Loss: 0.0225 - Val MAE: 0.1214 - Val CCC: 0.0637 - Val Accuracy: 81.42%\nEpoch 5/30 - Train Loss: 0.0251 - Train Accuracy: 78.95%\nEpoch 5/30 - Val Loss: 0.0243 - Val MAE: 0.1242 - Val CCC: 0.0670 - Val Accuracy: 79.60%\nEpoch 6/30 - Train Loss: 0.0247 - Train Accuracy: 79.02%\nEpoch 6/30 - Val Loss: 0.0223 - Val MAE: 0.1200 - Val CCC: 0.0733 - Val Accuracy: 81.59%\nEpoch 7/30 - Train Loss: 0.0244 - Train Accuracy: 79.42%\nEpoch 7/30 - Val Loss: 0.0235 - Val MAE: 0.1242 - Val CCC: 0.0837 - Val Accuracy: 80.53%\nEpoch 8/30 - Train Loss: 0.0243 - Train Accuracy: 79.49%\nEpoch 8/30 - Val Loss: 0.0240 - Val MAE: 0.1235 - Val CCC: 0.0777 - Val Accuracy: 80.33%\nEpoch 9/30 - Train Loss: 0.0242 - Train Accuracy: 79.67%\nEpoch 9/30 - Val Loss: 0.0223 - Val MAE: 0.1204 - Val CCC: 0.0781 - Val Accuracy: 81.10%\nEpoch 10/30 - Train Loss: 0.0240 - Train Accuracy: 79.78%\nEpoch 10/30 - Val Loss: 0.0222 - Val MAE: 0.1200 - Val CCC: 0.0759 - Val Accuracy: 81.34%\nEpoch 11/30 - Train Loss: 0.0236 - Train Accuracy: 80.25%\nEpoch 11/30 - Val Loss: 0.0222 - Val MAE: 0.1200 - Val CCC: 0.0767 - Val Accuracy: 81.62%\nEpoch 12/30 - Train Loss: 0.0235 - Train Accuracy: 80.30%\nEpoch 12/30 - Val Loss: 0.0222 - Val MAE: 0.1201 - Val CCC: 0.0767 - Val Accuracy: 81.59%\nEpoch 13/30 - Train Loss: 0.0237 - Train Accuracy: 80.10%\nEpoch 13/30 - Val Loss: 0.0222 - Val MAE: 0.1199 - Val CCC: 0.0794 - Val Accuracy: 81.29%\nEpoch 14/30 - Train Loss: 0.0235 - Train Accuracy: 80.31%\nEpoch 14/30 - Val Loss: 0.0222 - Val MAE: 0.1199 - Val CCC: 0.0811 - Val Accuracy: 81.12%\nEpoch 15/30 - Train Loss: 0.0235 - Train Accuracy: 80.29%\nEpoch 15/30 - Val Loss: 0.0222 - Val MAE: 0.1200 - Val CCC: 0.0815 - Val Accuracy: 81.42%\nEpoch 16/30 - Train Loss: 0.0235 - Train Accuracy: 80.26%\nEpoch 16/30 - Val Loss: 0.0222 - Val MAE: 0.1201 - Val CCC: 0.0790 - Val Accuracy: 81.62%\nEpoch 17/30 - Train Loss: 0.0234 - Train Accuracy: 80.36%\nEpoch 17/30 - Val Loss: 0.0222 - Val MAE: 0.1199 - Val CCC: 0.0780 - Val Accuracy: 81.17%\nEpoch 18/30 - Train Loss: 0.0237 - Train Accuracy: 80.06%\nEpoch 18/30 - Val Loss: 0.0224 - Val MAE: 0.1200 - Val CCC: 0.0812 - Val Accuracy: 81.81%\nEpoch 19/30 - Train Loss: 0.0235 - Train Accuracy: 80.21%\nEpoch 19/30 - Val Loss: 0.0222 - Val MAE: 0.1199 - Val CCC: 0.0771 - Val Accuracy: 81.41%\nEpoch 20/30 - Train Loss: 0.0235 - Train Accuracy: 80.20%\nEpoch 20/30 - Val Loss: 0.0223 - Val MAE: 0.1199 - Val CCC: 0.0822 - Val Accuracy: 81.61%\nEpoch 21/30 - Train Loss: 0.0235 - Train Accuracy: 80.39%\nEpoch 21/30 - Val Loss: 0.0222 - Val MAE: 0.1200 - Val CCC: 0.0814 - Val Accuracy: 81.42%\nEpoch 22/30 - Train Loss: 0.0233 - Train Accuracy: 80.48%\nEpoch 22/30 - Val Loss: 0.0222 - Val MAE: 0.1200 - Val CCC: 0.0811 - Val Accuracy: 81.88%\nEpoch 23/30 - Train Loss: 0.0235 - Train Accuracy: 80.41%\nEpoch 23/30 - Val Loss: 0.0222 - Val MAE: 0.1199 - Val CCC: 0.0806 - Val Accuracy: 81.55%\nEpoch 24/30 - Train Loss: 0.0235 - Train Accuracy: 80.34%\nEpoch 24/30 - Val Loss: 0.0222 - Val MAE: 0.1200 - Val CCC: 0.0799 - Val Accuracy: 81.62%\nEpoch 25/30 - Train Loss: 0.0234 - Train Accuracy: 80.42%\nEpoch 25/30 - Val Loss: 0.0222 - Val MAE: 0.1201 - Val CCC: 0.0798 - Val Accuracy: 81.84%\nEpoch 26/30 - Train Loss: 0.0235 - Train Accuracy: 80.33%\nEpoch 26/30 - Val Loss: 0.0222 - Val MAE: 0.1199 - Val CCC: 0.0799 - Val Accuracy: 81.29%\nEpoch 27/30 - Train Loss: 0.0234 - Train Accuracy: 80.46%\nEpoch 27/30 - Val Loss: 0.0222 - Val MAE: 0.1200 - Val CCC: 0.0798 - Val Accuracy: 81.88%\nEpoch 28/30 - Train Loss: 0.0233 - Train Accuracy: 80.35%\nEpoch 28/30 - Val Loss: 0.0222 - Val MAE: 0.1201 - Val CCC: 0.0797 - Val Accuracy: 81.64%\nEpoch 29/30 - Train Loss: 0.0235 - Train Accuracy: 80.28%\nEpoch 29/30 - Val Loss: 0.0222 - Val MAE: 0.1201 - Val CCC: 0.0790 - Val Accuracy: 81.84%\nEpoch 30/30 - Train Loss: 0.0234 - Train Accuracy: 80.40%\nEpoch 30/30 - Val Loss: 0.0222 - Val MAE: 0.1199 - Val CCC: 0.0792 - Val Accuracy: 81.88%\nConfig 2 Metrics - CCC: 0.0931, MAE: 0.1225, Loss: 0.0231, Accuracy: 80.83%\n\n=== Testing Config 3/20 ===\n{'embed_dim': 512, 'num_heads': 16, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 16, 'weight_decay': 0.001}\n\n=== Fold 1/3 ===\nEpoch 1/30 - Train Loss: 0.0290 - Train Accuracy: 75.93%\nEpoch 1/30 - Val Loss: 0.0226 - Val MAE: 0.1207 - Val CCC: 0.0997 - Val Accuracy: 81.58%\nEpoch 2/30 - Train Loss: 0.0260 - Train Accuracy: 77.95%\nEpoch 2/30 - Val Loss: 0.0227 - Val MAE: 0.1214 - Val CCC: 0.0945 - Val Accuracy: 80.89%\nEpoch 3/30 - Train Loss: 0.0255 - Train Accuracy: 78.49%\nEpoch 3/30 - Val Loss: 0.0225 - Val MAE: 0.1207 - Val CCC: 0.0855 - Val Accuracy: 81.64%\nEpoch 4/30 - Train Loss: 0.0251 - Train Accuracy: 78.82%\nEpoch 4/30 - Val Loss: 0.0229 - Val MAE: 0.1222 - Val CCC: 0.0755 - Val Accuracy: 80.60%\nEpoch 5/30 - Train Loss: 0.0249 - Train Accuracy: 78.99%\nEpoch 5/30 - Val Loss: 0.0225 - Val MAE: 0.1207 - Val CCC: 0.0572 - Val Accuracy: 81.03%\nEpoch 6/30 - Train Loss: 0.0243 - Train Accuracy: 79.50%\nEpoch 6/30 - Val Loss: 0.0234 - Val MAE: 0.1219 - Val CCC: 0.0690 - Val Accuracy: 80.92%\nEpoch 7/30 - Train Loss: 0.0242 - Train Accuracy: 79.54%\nEpoch 7/30 - Val Loss: 0.0227 - Val MAE: 0.1214 - Val CCC: 0.0743 - Val Accuracy: 80.85%\nEpoch 8/30 - Train Loss: 0.0239 - Train Accuracy: 79.88%\nEpoch 8/30 - Val Loss: 0.0224 - Val MAE: 0.1204 - Val CCC: 0.0766 - Val Accuracy: 81.34%\nEpoch 9/30 - Train Loss: 0.0236 - Train Accuracy: 80.14%\nEpoch 9/30 - Val Loss: 0.0226 - Val MAE: 0.1211 - Val CCC: 0.0741 - Val Accuracy: 81.23%\nEpoch 10/30 - Train Loss: 0.0237 - Train Accuracy: 80.06%\nEpoch 10/30 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.0845 - Val Accuracy: 81.60%\nEpoch 11/30 - Train Loss: 0.0232 - Train Accuracy: 80.57%\nEpoch 11/30 - Val Loss: 0.0226 - Val MAE: 0.1211 - Val CCC: 0.0767 - Val Accuracy: 81.07%\nEpoch 12/30 - Train Loss: 0.0232 - Train Accuracy: 80.65%\nEpoch 12/30 - Val Loss: 0.0226 - Val MAE: 0.1211 - Val CCC: 0.0728 - Val Accuracy: 81.38%\nEpoch 13/30 - Train Loss: 0.0232 - Train Accuracy: 80.59%\nEpoch 13/30 - Val Loss: 0.0226 - Val MAE: 0.1212 - Val CCC: 0.0730 - Val Accuracy: 81.69%\nEpoch 14/30 - Train Loss: 0.0232 - Train Accuracy: 80.55%\nEpoch 14/30 - Val Loss: 0.0227 - Val MAE: 0.1216 - Val CCC: 0.0711 - Val Accuracy: 81.02%\nEpoch 15/30 - Train Loss: 0.0231 - Train Accuracy: 80.59%\nEpoch 15/30 - Val Loss: 0.0225 - Val MAE: 0.1207 - Val CCC: 0.0753 - Val Accuracy: 81.16%\nEpoch 16/30 - Train Loss: 0.0233 - Train Accuracy: 80.51%\nEpoch 16/30 - Val Loss: 0.0225 - Val MAE: 0.1206 - Val CCC: 0.0717 - Val Accuracy: 81.42%\nEpoch 17/30 - Train Loss: 0.0232 - Train Accuracy: 80.57%\nEpoch 17/30 - Val Loss: 0.0226 - Val MAE: 0.1210 - Val CCC: 0.0760 - Val Accuracy: 81.69%\nEpoch 18/30 - Train Loss: 0.0230 - Train Accuracy: 80.81%\nEpoch 18/30 - Val Loss: 0.0225 - Val MAE: 0.1208 - Val CCC: 0.0753 - Val Accuracy: 81.16%\nEpoch 19/30 - Train Loss: 0.0232 - Train Accuracy: 80.52%\nEpoch 19/30 - Val Loss: 0.0225 - Val MAE: 0.1208 - Val CCC: 0.0767 - Val Accuracy: 81.16%\nEpoch 20/30 - Train Loss: 0.0230 - Train Accuracy: 80.63%\nEpoch 20/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0773 - Val Accuracy: 81.51%\nEpoch 21/30 - Train Loss: 0.0231 - Train Accuracy: 80.55%\nEpoch 21/30 - Val Loss: 0.0226 - Val MAE: 0.1210 - Val CCC: 0.0759 - Val Accuracy: 80.98%\nEpoch 22/30 - Train Loss: 0.0230 - Train Accuracy: 80.87%\nEpoch 22/30 - Val Loss: 0.0226 - Val MAE: 0.1213 - Val CCC: 0.0753 - Val Accuracy: 81.33%\nEpoch 23/30 - Train Loss: 0.0231 - Train Accuracy: 80.63%\nEpoch 23/30 - Val Loss: 0.0226 - Val MAE: 0.1211 - Val CCC: 0.0758 - Val Accuracy: 81.16%\nEpoch 24/30 - Train Loss: 0.0230 - Train Accuracy: 80.65%\nEpoch 24/30 - Val Loss: 0.0226 - Val MAE: 0.1213 - Val CCC: 0.0755 - Val Accuracy: 81.02%\nEpoch 25/30 - Train Loss: 0.0231 - Train Accuracy: 80.74%\nEpoch 25/30 - Val Loss: 0.0226 - Val MAE: 0.1213 - Val CCC: 0.0751 - Val Accuracy: 81.02%\nEpoch 26/30 - Train Loss: 0.0230 - Train Accuracy: 80.73%\nEpoch 26/30 - Val Loss: 0.0226 - Val MAE: 0.1210 - Val CCC: 0.0760 - Val Accuracy: 81.16%\nEpoch 27/30 - Train Loss: 0.0231 - Train Accuracy: 80.66%\nEpoch 27/30 - Val Loss: 0.0226 - Val MAE: 0.1213 - Val CCC: 0.0747 - Val Accuracy: 81.32%\nEpoch 28/30 - Train Loss: 0.0230 - Train Accuracy: 80.81%\nEpoch 28/30 - Val Loss: 0.0226 - Val MAE: 0.1212 - Val CCC: 0.0754 - Val Accuracy: 81.32%\nEpoch 29/30 - Train Loss: 0.0230 - Train Accuracy: 80.74%\nEpoch 29/30 - Val Loss: 0.0226 - Val MAE: 0.1211 - Val CCC: 0.0754 - Val Accuracy: 81.07%\nEpoch 30/30 - Train Loss: 0.0232 - Train Accuracy: 80.43%\nEpoch 30/30 - Val Loss: 0.0227 - Val MAE: 0.1214 - Val CCC: 0.0742 - Val Accuracy: 81.02%\n\n=== Fold 2/3 ===\nEpoch 1/30 - Train Loss: 0.0297 - Train Accuracy: 75.63%\nEpoch 1/30 - Val Loss: 0.0225 - Val MAE: 0.1215 - Val CCC: 0.0826 - Val Accuracy: 80.88%\nEpoch 2/30 - Train Loss: 0.0268 - Train Accuracy: 77.28%\nEpoch 2/30 - Val Loss: 0.0257 - Val MAE: 0.1308 - Val CCC: 0.0526 - Val Accuracy: 77.36%\nEpoch 3/30 - Train Loss: 0.0257 - Train Accuracy: 78.26%\nEpoch 3/30 - Val Loss: 0.0227 - Val MAE: 0.1210 - Val CCC: 0.0942 - Val Accuracy: 81.27%\nEpoch 4/30 - Train Loss: 0.0255 - Train Accuracy: 78.58%\nEpoch 4/30 - Val Loss: 0.0222 - Val MAE: 0.1202 - Val CCC: 0.0842 - Val Accuracy: 81.38%\nEpoch 5/30 - Train Loss: 0.0252 - Train Accuracy: 78.70%\nEpoch 5/30 - Val Loss: 0.0240 - Val MAE: 0.1237 - Val CCC: 0.0655 - Val Accuracy: 80.33%\nEpoch 6/30 - Train Loss: 0.0250 - Train Accuracy: 78.94%\nEpoch 6/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0840 - Val Accuracy: 81.53%\nEpoch 7/30 - Train Loss: 0.0248 - Train Accuracy: 79.13%\nEpoch 7/30 - Val Loss: 0.0222 - Val MAE: 0.1203 - Val CCC: 0.0835 - Val Accuracy: 81.29%\nEpoch 8/30 - Train Loss: 0.0242 - Train Accuracy: 79.60%\nEpoch 8/30 - Val Loss: 0.0223 - Val MAE: 0.1203 - Val CCC: 0.0911 - Val Accuracy: 82.01%\nEpoch 9/30 - Train Loss: 0.0242 - Train Accuracy: 79.77%\nEpoch 9/30 - Val Loss: 0.0226 - Val MAE: 0.1208 - Val CCC: 0.0700 - Val Accuracy: 81.08%\nEpoch 10/30 - Train Loss: 0.0239 - Train Accuracy: 80.01%\nEpoch 10/30 - Val Loss: 0.0230 - Val MAE: 0.1229 - Val CCC: 0.0756 - Val Accuracy: 80.29%\nEpoch 11/30 - Train Loss: 0.0236 - Train Accuracy: 80.09%\nEpoch 11/30 - Val Loss: 0.0224 - Val MAE: 0.1210 - Val CCC: 0.0818 - Val Accuracy: 81.08%\nEpoch 12/30 - Train Loss: 0.0235 - Train Accuracy: 80.35%\nEpoch 12/30 - Val Loss: 0.0227 - Val MAE: 0.1221 - Val CCC: 0.0815 - Val Accuracy: 80.99%\nEpoch 13/30 - Train Loss: 0.0236 - Train Accuracy: 80.19%\nEpoch 13/30 - Val Loss: 0.0225 - Val MAE: 0.1213 - Val CCC: 0.0824 - Val Accuracy: 80.97%\nEpoch 14/30 - Train Loss: 0.0235 - Train Accuracy: 80.29%\nEpoch 14/30 - Val Loss: 0.0225 - Val MAE: 0.1213 - Val CCC: 0.0831 - Val Accuracy: 80.97%\nEpoch 15/30 - Train Loss: 0.0233 - Train Accuracy: 80.62%\nEpoch 15/30 - Val Loss: 0.0223 - Val MAE: 0.1207 - Val CCC: 0.0852 - Val Accuracy: 81.38%\nEpoch 16/30 - Train Loss: 0.0236 - Train Accuracy: 80.25%\nEpoch 16/30 - Val Loss: 0.0225 - Val MAE: 0.1214 - Val CCC: 0.0843 - Val Accuracy: 81.19%\nEpoch 17/30 - Train Loss: 0.0233 - Train Accuracy: 80.63%\nEpoch 17/30 - Val Loss: 0.0223 - Val MAE: 0.1206 - Val CCC: 0.0844 - Val Accuracy: 81.47%\nEpoch 18/30 - Train Loss: 0.0235 - Train Accuracy: 80.26%\nEpoch 18/30 - Val Loss: 0.0227 - Val MAE: 0.1221 - Val CCC: 0.0806 - Val Accuracy: 80.61%\nEpoch 19/30 - Train Loss: 0.0234 - Train Accuracy: 80.41%\nEpoch 19/30 - Val Loss: 0.0227 - Val MAE: 0.1221 - Val CCC: 0.0803 - Val Accuracy: 80.63%\nEpoch 20/30 - Train Loss: 0.0234 - Train Accuracy: 80.46%\nEpoch 20/30 - Val Loss: 0.0226 - Val MAE: 0.1218 - Val CCC: 0.0824 - Val Accuracy: 80.99%\nEpoch 21/30 - Train Loss: 0.0232 - Train Accuracy: 80.61%\nEpoch 21/30 - Val Loss: 0.0225 - Val MAE: 0.1215 - Val CCC: 0.0828 - Val Accuracy: 81.16%\nEpoch 22/30 - Train Loss: 0.0233 - Train Accuracy: 80.49%\nEpoch 22/30 - Val Loss: 0.0225 - Val MAE: 0.1213 - Val CCC: 0.0823 - Val Accuracy: 81.23%\nEpoch 23/30 - Train Loss: 0.0233 - Train Accuracy: 80.64%\nEpoch 23/30 - Val Loss: 0.0225 - Val MAE: 0.1213 - Val CCC: 0.0824 - Val Accuracy: 80.97%\nEpoch 24/30 - Train Loss: 0.0234 - Train Accuracy: 80.47%\nEpoch 24/30 - Val Loss: 0.0225 - Val MAE: 0.1214 - Val CCC: 0.0822 - Val Accuracy: 80.97%\nEpoch 25/30 - Train Loss: 0.0233 - Train Accuracy: 80.50%\nEpoch 25/30 - Val Loss: 0.0226 - Val MAE: 0.1217 - Val CCC: 0.0820 - Val Accuracy: 81.38%\nEpoch 26/30 - Train Loss: 0.0233 - Train Accuracy: 80.51%\nEpoch 26/30 - Val Loss: 0.0224 - Val MAE: 0.1210 - Val CCC: 0.0823 - Val Accuracy: 81.23%\nEpoch 27/30 - Train Loss: 0.0233 - Train Accuracy: 80.46%\nEpoch 27/30 - Val Loss: 0.0225 - Val MAE: 0.1213 - Val CCC: 0.0818 - Val Accuracy: 80.97%\nEpoch 28/30 - Train Loss: 0.0233 - Train Accuracy: 80.54%\nEpoch 28/30 - Val Loss: 0.0225 - Val MAE: 0.1215 - Val CCC: 0.0822 - Val Accuracy: 81.16%\nEpoch 29/30 - Train Loss: 0.0233 - Train Accuracy: 80.54%\nEpoch 29/30 - Val Loss: 0.0226 - Val MAE: 0.1218 - Val CCC: 0.0819 - Val Accuracy: 81.12%\nEpoch 30/30 - Train Loss: 0.0232 - Train Accuracy: 80.72%\nEpoch 30/30 - Val Loss: 0.0225 - Val MAE: 0.1214 - Val CCC: 0.0824 - Val Accuracy: 80.97%\n\n=== Fold 3/3 ===\nEpoch 1/30 - Train Loss: 0.0295 - Train Accuracy: 75.25%\nEpoch 1/30 - Val Loss: 0.0240 - Val MAE: 0.1259 - Val CCC: 0.0755 - Val Accuracy: 79.53%\nEpoch 2/30 - Train Loss: 0.0266 - Train Accuracy: 77.38%\nEpoch 2/30 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0865 - Val Accuracy: 81.26%\nEpoch 3/30 - Train Loss: 0.0257 - Train Accuracy: 78.28%\nEpoch 3/30 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.0694 - Val Accuracy: 81.74%\nEpoch 4/30 - Train Loss: 0.0253 - Train Accuracy: 78.63%\nEpoch 4/30 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.0789 - Val Accuracy: 81.48%\nEpoch 5/30 - Train Loss: 0.0249 - Train Accuracy: 78.98%\nEpoch 5/30 - Val Loss: 0.0246 - Val MAE: 0.1252 - Val CCC: 0.0803 - Val Accuracy: 79.43%\nEpoch 6/30 - Train Loss: 0.0247 - Train Accuracy: 79.24%\nEpoch 6/30 - Val Loss: 0.0224 - Val MAE: 0.1200 - Val CCC: 0.0874 - Val Accuracy: 81.40%\nEpoch 7/30 - Train Loss: 0.0244 - Train Accuracy: 79.38%\nEpoch 7/30 - Val Loss: 0.0223 - Val MAE: 0.1207 - Val CCC: 0.0769 - Val Accuracy: 81.34%\nEpoch 8/30 - Train Loss: 0.0243 - Train Accuracy: 79.46%\nEpoch 8/30 - Val Loss: 0.0232 - Val MAE: 0.1218 - Val CCC: 0.0681 - Val Accuracy: 81.11%\nEpoch 9/30 - Train Loss: 0.0240 - Train Accuracy: 79.88%\nEpoch 9/30 - Val Loss: 0.0230 - Val MAE: 0.1229 - Val CCC: 0.0771 - Val Accuracy: 80.49%\nEpoch 10/30 - Train Loss: 0.0239 - Train Accuracy: 79.74%\nEpoch 10/30 - Val Loss: 0.0224 - Val MAE: 0.1202 - Val CCC: 0.0726 - Val Accuracy: 81.19%\nEpoch 11/30 - Train Loss: 0.0235 - Train Accuracy: 80.35%\nEpoch 11/30 - Val Loss: 0.0225 - Val MAE: 0.1213 - Val CCC: 0.0740 - Val Accuracy: 81.42%\nEpoch 12/30 - Train Loss: 0.0235 - Train Accuracy: 80.31%\nEpoch 12/30 - Val Loss: 0.0227 - Val MAE: 0.1218 - Val CCC: 0.0733 - Val Accuracy: 80.91%\nEpoch 13/30 - Train Loss: 0.0235 - Train Accuracy: 80.27%\nEpoch 13/30 - Val Loss: 0.0230 - Val MAE: 0.1229 - Val CCC: 0.0727 - Val Accuracy: 80.61%\nEpoch 14/30 - Train Loss: 0.0235 - Train Accuracy: 80.19%\nEpoch 14/30 - Val Loss: 0.0226 - Val MAE: 0.1215 - Val CCC: 0.0752 - Val Accuracy: 81.20%\nEpoch 15/30 - Train Loss: 0.0234 - Train Accuracy: 80.39%\nEpoch 15/30 - Val Loss: 0.0228 - Val MAE: 0.1223 - Val CCC: 0.0757 - Val Accuracy: 81.10%\nEpoch 16/30 - Train Loss: 0.0233 - Train Accuracy: 80.51%\nEpoch 16/30 - Val Loss: 0.0229 - Val MAE: 0.1225 - Val CCC: 0.0763 - Val Accuracy: 80.79%\nEpoch 17/30 - Train Loss: 0.0235 - Train Accuracy: 80.30%\nEpoch 17/30 - Val Loss: 0.0225 - Val MAE: 0.1211 - Val CCC: 0.0753 - Val Accuracy: 81.01%\nEpoch 18/30 - Train Loss: 0.0232 - Train Accuracy: 80.69%\nEpoch 18/30 - Val Loss: 0.0225 - Val MAE: 0.1214 - Val CCC: 0.0754 - Val Accuracy: 81.43%\nEpoch 19/30 - Train Loss: 0.0234 - Train Accuracy: 80.38%\nEpoch 19/30 - Val Loss: 0.0229 - Val MAE: 0.1224 - Val CCC: 0.0770 - Val Accuracy: 80.91%\nEpoch 20/30 - Train Loss: 0.0234 - Train Accuracy: 80.61%\nEpoch 20/30 - Val Loss: 0.0223 - Val MAE: 0.1204 - Val CCC: 0.0764 - Val Accuracy: 81.73%\nEpoch 21/30 - Train Loss: 0.0232 - Train Accuracy: 80.61%\nEpoch 21/30 - Val Loss: 0.0225 - Val MAE: 0.1211 - Val CCC: 0.0767 - Val Accuracy: 80.98%\nEpoch 22/30 - Train Loss: 0.0234 - Train Accuracy: 80.27%\nEpoch 22/30 - Val Loss: 0.0226 - Val MAE: 0.1215 - Val CCC: 0.0761 - Val Accuracy: 81.20%\nEpoch 23/30 - Train Loss: 0.0233 - Train Accuracy: 80.51%\nEpoch 23/30 - Val Loss: 0.0226 - Val MAE: 0.1215 - Val CCC: 0.0758 - Val Accuracy: 80.91%\nEpoch 24/30 - Train Loss: 0.0234 - Train Accuracy: 80.39%\nEpoch 24/30 - Val Loss: 0.0226 - Val MAE: 0.1216 - Val CCC: 0.0757 - Val Accuracy: 80.91%\nEpoch 25/30 - Train Loss: 0.0233 - Train Accuracy: 80.52%\nEpoch 25/30 - Val Loss: 0.0225 - Val MAE: 0.1214 - Val CCC: 0.0758 - Val Accuracy: 81.20%\nEpoch 26/30 - Train Loss: 0.0234 - Train Accuracy: 80.34%\nEpoch 26/30 - Val Loss: 0.0225 - Val MAE: 0.1214 - Val CCC: 0.0755 - Val Accuracy: 81.42%\nEpoch 27/30 - Train Loss: 0.0233 - Train Accuracy: 80.54%\nEpoch 27/30 - Val Loss: 0.0226 - Val MAE: 0.1215 - Val CCC: 0.0763 - Val Accuracy: 80.91%\nEpoch 28/30 - Train Loss: 0.0234 - Train Accuracy: 80.37%\nEpoch 28/30 - Val Loss: 0.0224 - Val MAE: 0.1210 - Val CCC: 0.0757 - Val Accuracy: 81.09%\nEpoch 29/30 - Train Loss: 0.0233 - Train Accuracy: 80.27%\nEpoch 29/30 - Val Loss: 0.0227 - Val MAE: 0.1218 - Val CCC: 0.0757 - Val Accuracy: 81.13%\nEpoch 30/30 - Train Loss: 0.0232 - Train Accuracy: 80.59%\nEpoch 30/30 - Val Loss: 0.0226 - Val MAE: 0.1217 - Val CCC: 0.0758 - Val Accuracy: 80.91%\nConfig 3 Metrics - CCC: 0.0938, MAE: 0.1206, Loss: 0.0225, Accuracy: 81.42%\n\n=== Testing Config 4/20 ===\n{'embed_dim': 256, 'num_heads': 16, 'num_layers': 6, 'dropout': 0.3, 'lr': 0.0001, 'batch_size': 16, 'weight_decay': 0.0001}\n\n=== Fold 1/3 ===\nEpoch 1/30 - Train Loss: 0.0404 - Train Accuracy: 68.15%\nEpoch 1/30 - Val Loss: 0.0241 - Val MAE: 0.1260 - Val CCC: 0.0470 - Val Accuracy: 79.62%\nEpoch 2/30 - Train Loss: 0.0317 - Train Accuracy: 73.34%\nEpoch 2/30 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0713 - Val Accuracy: 81.55%\nEpoch 3/30 - Train Loss: 0.0296 - Train Accuracy: 74.93%\nEpoch 3/30 - Val Loss: 0.0238 - Val MAE: 0.1228 - Val CCC: 0.0570 - Val Accuracy: 80.72%\nEpoch 4/30 - Train Loss: 0.0285 - Train Accuracy: 75.81%\nEpoch 4/30 - Val Loss: 0.0243 - Val MAE: 0.1241 - Val CCC: 0.0530 - Val Accuracy: 80.04%\nEpoch 5/30 - Train Loss: 0.0278 - Train Accuracy: 76.19%\nEpoch 5/30 - Val Loss: 0.0269 - Val MAE: 0.1300 - Val CCC: 0.0692 - Val Accuracy: 77.93%\nEpoch 6/30 - Train Loss: 0.0267 - Train Accuracy: 77.12%\nEpoch 6/30 - Val Loss: 0.0228 - Val MAE: 0.1209 - Val CCC: 0.0632 - Val Accuracy: 81.42%\nEpoch 7/30 - Train Loss: 0.0263 - Train Accuracy: 77.65%\nEpoch 7/30 - Val Loss: 0.0226 - Val MAE: 0.1205 - Val CCC: 0.0703 - Val Accuracy: 81.69%\nEpoch 8/30 - Train Loss: 0.0257 - Train Accuracy: 78.22%\nEpoch 8/30 - Val Loss: 0.0244 - Val MAE: 0.1242 - Val CCC: 0.0620 - Val Accuracy: 80.37%\nEpoch 9/30 - Train Loss: 0.0260 - Train Accuracy: 77.85%\nEpoch 9/30 - Val Loss: 0.0246 - Val MAE: 0.1247 - Val CCC: 0.0643 - Val Accuracy: 80.21%\nEpoch 10/30 - Train Loss: 0.0256 - Train Accuracy: 78.24%\nEpoch 10/30 - Val Loss: 0.0229 - Val MAE: 0.1210 - Val CCC: 0.0746 - Val Accuracy: 81.07%\nEpoch 11/30 - Train Loss: 0.0249 - Train Accuracy: 79.01%\nEpoch 11/30 - Val Loss: 0.0226 - Val MAE: 0.1205 - Val CCC: 0.0725 - Val Accuracy: 81.62%\nEpoch 12/30 - Train Loss: 0.0247 - Train Accuracy: 78.98%\nEpoch 12/30 - Val Loss: 0.0229 - Val MAE: 0.1211 - Val CCC: 0.0710 - Val Accuracy: 81.43%\nEpoch 13/30 - Train Loss: 0.0247 - Train Accuracy: 79.14%\nEpoch 13/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0689 - Val Accuracy: 81.39%\nEpoch 14/30 - Train Loss: 0.0247 - Train Accuracy: 79.15%\nEpoch 14/30 - Val Loss: 0.0226 - Val MAE: 0.1205 - Val CCC: 0.0699 - Val Accuracy: 81.78%\nEpoch 15/30 - Train Loss: 0.0247 - Train Accuracy: 79.06%\nEpoch 15/30 - Val Loss: 0.0226 - Val MAE: 0.1205 - Val CCC: 0.0708 - Val Accuracy: 81.88%\nEpoch 16/30 - Train Loss: 0.0245 - Train Accuracy: 79.40%\nEpoch 16/30 - Val Loss: 0.0231 - Val MAE: 0.1214 - Val CCC: 0.0728 - Val Accuracy: 80.87%\nEpoch 17/30 - Train Loss: 0.0245 - Train Accuracy: 79.26%\nEpoch 17/30 - Val Loss: 0.0229 - Val MAE: 0.1210 - Val CCC: 0.0727 - Val Accuracy: 81.55%\nEpoch 18/30 - Train Loss: 0.0243 - Train Accuracy: 79.52%\nEpoch 18/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0727 - Val Accuracy: 81.64%\nEpoch 19/30 - Train Loss: 0.0245 - Train Accuracy: 79.34%\nEpoch 19/30 - Val Loss: 0.0228 - Val MAE: 0.1209 - Val CCC: 0.0705 - Val Accuracy: 81.14%\nEpoch 20/30 - Train Loss: 0.0242 - Train Accuracy: 79.60%\nEpoch 20/30 - Val Loss: 0.0227 - Val MAE: 0.1206 - Val CCC: 0.0728 - Val Accuracy: 81.48%\nEpoch 21/30 - Train Loss: 0.0242 - Train Accuracy: 79.62%\nEpoch 21/30 - Val Loss: 0.0227 - Val MAE: 0.1207 - Val CCC: 0.0728 - Val Accuracy: 81.48%\nEpoch 22/30 - Train Loss: 0.0244 - Train Accuracy: 79.44%\nEpoch 22/30 - Val Loss: 0.0228 - Val MAE: 0.1209 - Val CCC: 0.0729 - Val Accuracy: 81.16%\nEpoch 23/30 - Train Loss: 0.0244 - Train Accuracy: 79.37%\nEpoch 23/30 - Val Loss: 0.0227 - Val MAE: 0.1207 - Val CCC: 0.0733 - Val Accuracy: 81.48%\nEpoch 24/30 - Train Loss: 0.0244 - Train Accuracy: 79.28%\nEpoch 24/30 - Val Loss: 0.0227 - Val MAE: 0.1207 - Val CCC: 0.0734 - Val Accuracy: 81.48%\nEpoch 25/30 - Train Loss: 0.0242 - Train Accuracy: 79.50%\nEpoch 25/30 - Val Loss: 0.0228 - Val MAE: 0.1208 - Val CCC: 0.0729 - Val Accuracy: 81.24%\nEpoch 26/30 - Train Loss: 0.0244 - Train Accuracy: 79.35%\nEpoch 26/30 - Val Loss: 0.0228 - Val MAE: 0.1208 - Val CCC: 0.0729 - Val Accuracy: 81.24%\nEpoch 27/30 - Train Loss: 0.0243 - Train Accuracy: 79.41%\nEpoch 27/30 - Val Loss: 0.0228 - Val MAE: 0.1207 - Val CCC: 0.0730 - Val Accuracy: 81.24%\nEpoch 28/30 - Train Loss: 0.0244 - Train Accuracy: 79.34%\nEpoch 28/30 - Val Loss: 0.0228 - Val MAE: 0.1208 - Val CCC: 0.0735 - Val Accuracy: 81.24%\nEpoch 29/30 - Train Loss: 0.0243 - Train Accuracy: 79.57%\nEpoch 29/30 - Val Loss: 0.0227 - Val MAE: 0.1207 - Val CCC: 0.0735 - Val Accuracy: 81.24%\nEpoch 30/30 - Train Loss: 0.0243 - Train Accuracy: 79.41%\nEpoch 30/30 - Val Loss: 0.0227 - Val MAE: 0.1207 - Val CCC: 0.0739 - Val Accuracy: 81.24%\n\n=== Fold 2/3 ===\nEpoch 1/30 - Train Loss: 0.0407 - Train Accuracy: 68.01%\nEpoch 1/30 - Val Loss: 0.0225 - Val MAE: 0.1207 - Val CCC: 0.0955 - Val Accuracy: 81.35%\nEpoch 2/30 - Train Loss: 0.0324 - Train Accuracy: 72.99%\nEpoch 2/30 - Val Loss: 0.0229 - Val MAE: 0.1227 - Val CCC: 0.0945 - Val Accuracy: 80.17%\nEpoch 3/30 - Train Loss: 0.0293 - Train Accuracy: 75.23%\nEpoch 3/30 - Val Loss: 0.0331 - Val MAE: 0.1453 - Val CCC: 0.0604 - Val Accuracy: 72.64%\nEpoch 4/30 - Train Loss: 0.0290 - Train Accuracy: 75.49%\nEpoch 4/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0934 - Val Accuracy: 81.33%\nEpoch 5/30 - Train Loss: 0.0275 - Train Accuracy: 76.61%\nEpoch 5/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0794 - Val Accuracy: 81.35%\nEpoch 6/30 - Train Loss: 0.0271 - Train Accuracy: 77.30%\nEpoch 6/30 - Val Loss: 0.0223 - Val MAE: 0.1204 - Val CCC: 0.0932 - Val Accuracy: 81.49%\nEpoch 7/30 - Train Loss: 0.0265 - Train Accuracy: 77.63%\nEpoch 7/30 - Val Loss: 0.0225 - Val MAE: 0.1206 - Val CCC: 0.0808 - Val Accuracy: 81.54%\nEpoch 8/30 - Train Loss: 0.0258 - Train Accuracy: 78.15%\nEpoch 8/30 - Val Loss: 0.0224 - Val MAE: 0.1204 - Val CCC: 0.0846 - Val Accuracy: 81.36%\nEpoch 9/30 - Train Loss: 0.0258 - Train Accuracy: 78.26%\nEpoch 9/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0881 - Val Accuracy: 81.69%\nEpoch 10/30 - Train Loss: 0.0254 - Train Accuracy: 78.52%\nEpoch 10/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0903 - Val Accuracy: 81.35%\nEpoch 11/30 - Train Loss: 0.0249 - Train Accuracy: 79.01%\nEpoch 11/30 - Val Loss: 0.0222 - Val MAE: 0.1201 - Val CCC: 0.0830 - Val Accuracy: 81.48%\nEpoch 12/30 - Train Loss: 0.0249 - Train Accuracy: 78.91%\nEpoch 12/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0795 - Val Accuracy: 81.12%\nEpoch 13/30 - Train Loss: 0.0247 - Train Accuracy: 79.21%\nEpoch 13/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0823 - Val Accuracy: 81.59%\nEpoch 14/30 - Train Loss: 0.0245 - Train Accuracy: 79.44%\nEpoch 14/30 - Val Loss: 0.0222 - Val MAE: 0.1202 - Val CCC: 0.0798 - Val Accuracy: 81.74%\nEpoch 15/30 - Train Loss: 0.0245 - Train Accuracy: 79.25%\nEpoch 15/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0785 - Val Accuracy: 81.32%\nEpoch 16/30 - Train Loss: 0.0246 - Train Accuracy: 79.25%\nEpoch 16/30 - Val Loss: 0.0222 - Val MAE: 0.1202 - Val CCC: 0.0802 - Val Accuracy: 81.49%\nEpoch 17/30 - Train Loss: 0.0245 - Train Accuracy: 79.37%\nEpoch 17/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0824 - Val Accuracy: 81.76%\nEpoch 18/30 - Train Loss: 0.0245 - Train Accuracy: 79.45%\nEpoch 18/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0815 - Val Accuracy: 81.56%\nEpoch 19/30 - Train Loss: 0.0243 - Train Accuracy: 79.53%\nEpoch 19/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0807 - Val Accuracy: 81.35%\nEpoch 20/30 - Train Loss: 0.0243 - Train Accuracy: 79.59%\nEpoch 20/30 - Val Loss: 0.0222 - Val MAE: 0.1202 - Val CCC: 0.0810 - Val Accuracy: 81.53%\nEpoch 21/30 - Train Loss: 0.0242 - Train Accuracy: 79.70%\nEpoch 21/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0815 - Val Accuracy: 81.59%\nEpoch 22/30 - Train Loss: 0.0242 - Train Accuracy: 79.80%\nEpoch 22/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0817 - Val Accuracy: 81.59%\nEpoch 23/30 - Train Loss: 0.0243 - Train Accuracy: 79.67%\nEpoch 23/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0817 - Val Accuracy: 81.59%\nEpoch 24/30 - Train Loss: 0.0243 - Train Accuracy: 79.60%\nEpoch 24/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0819 - Val Accuracy: 81.32%\nEpoch 25/30 - Train Loss: 0.0243 - Train Accuracy: 79.52%\nEpoch 25/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0820 - Val Accuracy: 81.59%\nEpoch 26/30 - Train Loss: 0.0241 - Train Accuracy: 79.77%\nEpoch 26/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0822 - Val Accuracy: 81.32%\nEpoch 27/30 - Train Loss: 0.0241 - Train Accuracy: 79.71%\nEpoch 27/30 - Val Loss: 0.0224 - Val MAE: 0.1202 - Val CCC: 0.0816 - Val Accuracy: 81.59%\nEpoch 28/30 - Train Loss: 0.0243 - Train Accuracy: 79.45%\nEpoch 28/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0814 - Val Accuracy: 81.32%\nEpoch 29/30 - Train Loss: 0.0244 - Train Accuracy: 79.41%\nEpoch 29/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0814 - Val Accuracy: 81.35%\nEpoch 30/30 - Train Loss: 0.0244 - Train Accuracy: 79.63%\nEpoch 30/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0813 - Val Accuracy: 81.53%\n\n=== Fold 3/3 ===\nEpoch 1/30 - Train Loss: 0.0412 - Train Accuracy: 67.80%\nEpoch 1/30 - Val Loss: 0.0234 - Val MAE: 0.1238 - Val CCC: 0.1050 - Val Accuracy: 79.88%\nEpoch 2/30 - Train Loss: 0.0326 - Train Accuracy: 72.69%\nEpoch 2/30 - Val Loss: 0.0229 - Val MAE: 0.1211 - Val CCC: 0.0667 - Val Accuracy: 81.34%\nEpoch 3/30 - Train Loss: 0.0298 - Train Accuracy: 75.00%\nEpoch 3/30 - Val Loss: 0.0243 - Val MAE: 0.1242 - Val CCC: 0.0753 - Val Accuracy: 80.13%\nEpoch 4/30 - Train Loss: 0.0284 - Train Accuracy: 75.91%\nEpoch 4/30 - Val Loss: 0.0225 - Val MAE: 0.1207 - Val CCC: 0.0604 - Val Accuracy: 81.32%\nEpoch 5/30 - Train Loss: 0.0276 - Train Accuracy: 76.67%\nEpoch 5/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0641 - Val Accuracy: 81.67%\nEpoch 6/30 - Train Loss: 0.0271 - Train Accuracy: 77.03%\nEpoch 6/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0907 - Val Accuracy: 81.18%\nEpoch 7/30 - Train Loss: 0.0263 - Train Accuracy: 77.82%\nEpoch 7/30 - Val Loss: 0.0225 - Val MAE: 0.1213 - Val CCC: 0.0795 - Val Accuracy: 81.47%\nEpoch 8/30 - Train Loss: 0.0262 - Train Accuracy: 77.93%\nEpoch 8/30 - Val Loss: 0.0231 - Val MAE: 0.1231 - Val CCC: 0.0795 - Val Accuracy: 81.14%\nEpoch 9/30 - Train Loss: 0.0262 - Train Accuracy: 77.80%\nEpoch 9/30 - Val Loss: 0.0227 - Val MAE: 0.1219 - Val CCC: 0.0847 - Val Accuracy: 80.66%\nEpoch 10/30 - Train Loss: 0.0255 - Train Accuracy: 78.33%\nEpoch 10/30 - Val Loss: 0.0223 - Val MAE: 0.1204 - Val CCC: 0.0872 - Val Accuracy: 81.60%\nEpoch 11/30 - Train Loss: 0.0249 - Train Accuracy: 79.10%\nEpoch 11/30 - Val Loss: 0.0225 - Val MAE: 0.1202 - Val CCC: 0.0826 - Val Accuracy: 81.44%\nEpoch 12/30 - Train Loss: 0.0250 - Train Accuracy: 78.99%\nEpoch 12/30 - Val Loss: 0.0227 - Val MAE: 0.1206 - Val CCC: 0.0816 - Val Accuracy: 80.86%\nEpoch 13/30 - Train Loss: 0.0247 - Train Accuracy: 79.17%\nEpoch 13/30 - Val Loss: 0.0227 - Val MAE: 0.1207 - Val CCC: 0.0807 - Val Accuracy: 81.25%\nEpoch 14/30 - Train Loss: 0.0249 - Train Accuracy: 79.09%\nEpoch 14/30 - Val Loss: 0.0224 - Val MAE: 0.1201 - Val CCC: 0.0787 - Val Accuracy: 81.27%\nEpoch 15/30 - Train Loss: 0.0246 - Train Accuracy: 79.24%\nEpoch 15/30 - Val Loss: 0.0224 - Val MAE: 0.1202 - Val CCC: 0.0783 - Val Accuracy: 81.27%\nEpoch 16/30 - Train Loss: 0.0245 - Train Accuracy: 79.37%\nEpoch 16/30 - Val Loss: 0.0225 - Val MAE: 0.1202 - Val CCC: 0.0811 - Val Accuracy: 81.90%\nEpoch 17/30 - Train Loss: 0.0247 - Train Accuracy: 79.24%\nEpoch 17/30 - Val Loss: 0.0224 - Val MAE: 0.1201 - Val CCC: 0.0797 - Val Accuracy: 81.72%\nEpoch 18/30 - Train Loss: 0.0246 - Train Accuracy: 79.18%\nEpoch 18/30 - Val Loss: 0.0223 - Val MAE: 0.1200 - Val CCC: 0.0790 - Val Accuracy: 81.38%\nEpoch 19/30 - Train Loss: 0.0246 - Train Accuracy: 79.26%\nEpoch 19/30 - Val Loss: 0.0222 - Val MAE: 0.1199 - Val CCC: 0.0794 - Val Accuracy: 81.17%\nEpoch 20/30 - Train Loss: 0.0243 - Train Accuracy: 79.59%\nEpoch 20/30 - Val Loss: 0.0222 - Val MAE: 0.1200 - Val CCC: 0.0743 - Val Accuracy: 81.17%\nEpoch 21/30 - Train Loss: 0.0245 - Train Accuracy: 79.29%\nEpoch 21/30 - Val Loss: 0.0223 - Val MAE: 0.1200 - Val CCC: 0.0748 - Val Accuracy: 81.84%\nEpoch 22/30 - Train Loss: 0.0246 - Train Accuracy: 79.24%\nEpoch 22/30 - Val Loss: 0.0222 - Val MAE: 0.1199 - Val CCC: 0.0754 - Val Accuracy: 81.64%\nEpoch 23/30 - Train Loss: 0.0245 - Train Accuracy: 79.22%\nEpoch 23/30 - Val Loss: 0.0223 - Val MAE: 0.1200 - Val CCC: 0.0759 - Val Accuracy: 81.84%\nEpoch 24/30 - Train Loss: 0.0245 - Train Accuracy: 79.17%\nEpoch 24/30 - Val Loss: 0.0223 - Val MAE: 0.1200 - Val CCC: 0.0759 - Val Accuracy: 81.64%\nEpoch 25/30 - Train Loss: 0.0244 - Train Accuracy: 79.44%\nEpoch 25/30 - Val Loss: 0.0223 - Val MAE: 0.1200 - Val CCC: 0.0760 - Val Accuracy: 81.28%\nEpoch 26/30 - Train Loss: 0.0243 - Train Accuracy: 79.45%\nEpoch 26/30 - Val Loss: 0.0224 - Val MAE: 0.1201 - Val CCC: 0.0764 - Val Accuracy: 81.49%\nEpoch 27/30 - Train Loss: 0.0242 - Train Accuracy: 79.67%\nEpoch 27/30 - Val Loss: 0.0223 - Val MAE: 0.1200 - Val CCC: 0.0764 - Val Accuracy: 81.28%\nEpoch 28/30 - Train Loss: 0.0245 - Train Accuracy: 79.34%\nEpoch 28/30 - Val Loss: 0.0223 - Val MAE: 0.1200 - Val CCC: 0.0765 - Val Accuracy: 81.28%\nEpoch 29/30 - Train Loss: 0.0245 - Train Accuracy: 79.30%\nEpoch 29/30 - Val Loss: 0.0223 - Val MAE: 0.1200 - Val CCC: 0.0764 - Val Accuracy: 81.28%\nEpoch 30/30 - Train Loss: 0.0244 - Train Accuracy: 79.45%\nEpoch 30/30 - Val Loss: 0.0223 - Val MAE: 0.1200 - Val CCC: 0.0761 - Val Accuracy: 81.62%\nConfig 4 Metrics - CCC: 0.0917, MAE: 0.1218, Loss: 0.0229, Accuracy: 80.77%\n\n=== Testing Config 5/20 ===\n{'embed_dim': 768, 'num_heads': 4, 'num_layers': 4, 'dropout': 0.3, 'lr': 1e-05, 'batch_size': 16, 'weight_decay': 0.001}\n\n=== Fold 1/3 ===\nEpoch 1/30 - Train Loss: 0.0528 - Train Accuracy: 61.03%\nEpoch 1/30 - Val Loss: 0.0234 - Val MAE: 0.1222 - Val CCC: 0.0928 - Val Accuracy: 80.89%\nEpoch 2/30 - Train Loss: 0.0421 - Train Accuracy: 66.39%\nEpoch 2/30 - Val Loss: 0.0237 - Val MAE: 0.1228 - Val CCC: 0.0619 - Val Accuracy: 80.53%\nEpoch 3/30 - Train Loss: 0.0382 - Train Accuracy: 68.70%\nEpoch 3/30 - Val Loss: 0.0226 - Val MAE: 0.1209 - Val CCC: 0.0931 - Val Accuracy: 81.27%\nEpoch 4/30 - Train Loss: 0.0367 - Train Accuracy: 69.95%\nEpoch 4/30 - Val Loss: 0.0226 - Val MAE: 0.1208 - Val CCC: 0.0840 - Val Accuracy: 80.91%\nEpoch 5/30 - Train Loss: 0.0355 - Train Accuracy: 70.72%\nEpoch 5/30 - Val Loss: 0.0226 - Val MAE: 0.1206 - Val CCC: 0.0890 - Val Accuracy: 81.25%\nEpoch 6/30 - Train Loss: 0.0348 - Train Accuracy: 71.12%\nEpoch 6/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0885 - Val Accuracy: 81.59%\nEpoch 7/30 - Train Loss: 0.0345 - Train Accuracy: 71.24%\nEpoch 7/30 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.0845 - Val Accuracy: 81.32%\nEpoch 8/30 - Train Loss: 0.0335 - Train Accuracy: 71.91%\nEpoch 8/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0965 - Val Accuracy: 81.52%\nEpoch 9/30 - Train Loss: 0.0325 - Train Accuracy: 72.70%\nEpoch 9/30 - Val Loss: 0.0238 - Val MAE: 0.1228 - Val CCC: 0.0705 - Val Accuracy: 80.61%\nEpoch 10/30 - Train Loss: 0.0322 - Train Accuracy: 72.81%\nEpoch 10/30 - Val Loss: 0.0227 - Val MAE: 0.1207 - Val CCC: 0.0871 - Val Accuracy: 81.53%\nEpoch 11/30 - Train Loss: 0.0315 - Train Accuracy: 73.44%\nEpoch 11/30 - Val Loss: 0.0226 - Val MAE: 0.1205 - Val CCC: 0.0939 - Val Accuracy: 81.13%\nEpoch 12/30 - Train Loss: 0.0314 - Train Accuracy: 73.49%\nEpoch 12/30 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.0899 - Val Accuracy: 81.55%\nEpoch 13/30 - Train Loss: 0.0313 - Train Accuracy: 73.51%\nEpoch 13/30 - Val Loss: 0.0229 - Val MAE: 0.1209 - Val CCC: 0.0919 - Val Accuracy: 81.15%\nEpoch 14/30 - Train Loss: 0.0307 - Train Accuracy: 74.04%\nEpoch 14/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0910 - Val Accuracy: 81.51%\nEpoch 15/30 - Train Loss: 0.0308 - Train Accuracy: 73.99%\nEpoch 15/30 - Val Loss: 0.0225 - Val MAE: 0.1203 - Val CCC: 0.0871 - Val Accuracy: 81.13%\nEpoch 16/30 - Train Loss: 0.0307 - Train Accuracy: 74.10%\nEpoch 16/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0892 - Val Accuracy: 81.23%\nEpoch 17/30 - Train Loss: 0.0307 - Train Accuracy: 74.06%\nEpoch 17/30 - Val Loss: 0.0226 - Val MAE: 0.1205 - Val CCC: 0.0886 - Val Accuracy: 81.54%\nEpoch 18/30 - Train Loss: 0.0307 - Train Accuracy: 73.84%\nEpoch 18/30 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.0924 - Val Accuracy: 81.56%\nEpoch 19/30 - Train Loss: 0.0310 - Train Accuracy: 73.89%\nEpoch 19/30 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.0893 - Val Accuracy: 81.36%\nEpoch 20/30 - Train Loss: 0.0311 - Train Accuracy: 73.64%\nEpoch 20/30 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.0824 - Val Accuracy: 81.84%\nEpoch 21/30 - Train Loss: 0.0310 - Train Accuracy: 73.55%\nEpoch 21/30 - Val Loss: 0.0226 - Val MAE: 0.1205 - Val CCC: 0.0832 - Val Accuracy: 81.58%\nEpoch 22/30 - Train Loss: 0.0307 - Train Accuracy: 73.93%\nEpoch 22/30 - Val Loss: 0.0227 - Val MAE: 0.1205 - Val CCC: 0.0844 - Val Accuracy: 81.34%\nEpoch 23/30 - Train Loss: 0.0307 - Train Accuracy: 74.12%\nEpoch 23/30 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.0856 - Val Accuracy: 82.00%\nEpoch 24/30 - Train Loss: 0.0307 - Train Accuracy: 73.97%\nEpoch 24/30 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.0862 - Val Accuracy: 82.00%\nEpoch 25/30 - Train Loss: 0.0316 - Train Accuracy: 73.29%\nEpoch 25/30 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.0852 - Val Accuracy: 81.78%\nEpoch 26/30 - Train Loss: 0.0312 - Train Accuracy: 73.58%\nEpoch 26/30 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.0859 - Val Accuracy: 81.78%\nEpoch 27/30 - Train Loss: 0.0313 - Train Accuracy: 73.73%\nEpoch 27/30 - Val Loss: 0.0226 - Val MAE: 0.1203 - Val CCC: 0.0857 - Val Accuracy: 82.00%\nEpoch 28/30 - Train Loss: 0.0305 - Train Accuracy: 74.39%\nEpoch 28/30 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.0859 - Val Accuracy: 81.78%\nEpoch 29/30 - Train Loss: 0.0305 - Train Accuracy: 74.18%\nEpoch 29/30 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.0856 - Val Accuracy: 82.00%\nEpoch 30/30 - Train Loss: 0.0312 - Train Accuracy: 73.61%\nEpoch 30/30 - Val Loss: 0.0226 - Val MAE: 0.1204 - Val CCC: 0.0856 - Val Accuracy: 82.00%\n\n=== Fold 2/3 ===\nEpoch 1/30 - Train Loss: 0.0525 - Train Accuracy: 61.71%\nEpoch 1/30 - Val Loss: 0.0261 - Val MAE: 0.1316 - Val CCC: 0.0846 - Val Accuracy: 76.50%\nEpoch 2/30 - Train Loss: 0.0418 - Train Accuracy: 66.57%\nEpoch 2/30 - Val Loss: 0.0232 - Val MAE: 0.1234 - Val CCC: 0.0961 - Val Accuracy: 80.16%\nEpoch 3/30 - Train Loss: 0.0403 - Train Accuracy: 67.71%\nEpoch 3/30 - Val Loss: 0.0228 - Val MAE: 0.1223 - Val CCC: 0.1059 - Val Accuracy: 80.72%\nEpoch 4/30 - Train Loss: 0.0383 - Train Accuracy: 68.98%\nEpoch 4/30 - Val Loss: 0.0232 - Val MAE: 0.1235 - Val CCC: 0.0737 - Val Accuracy: 79.91%\nEpoch 5/30 - Train Loss: 0.0370 - Train Accuracy: 69.55%\nEpoch 5/30 - Val Loss: 0.0225 - Val MAE: 0.1207 - Val CCC: 0.0882 - Val Accuracy: 81.24%\nEpoch 6/30 - Train Loss: 0.0367 - Train Accuracy: 69.60%\nEpoch 6/30 - Val Loss: 0.0226 - Val MAE: 0.1211 - Val CCC: 0.0980 - Val Accuracy: 81.20%\nEpoch 7/30 - Train Loss: 0.0352 - Train Accuracy: 70.73%\nEpoch 7/30 - Val Loss: 0.0229 - Val MAE: 0.1226 - Val CCC: 0.0940 - Val Accuracy: 80.26%\nEpoch 8/30 - Train Loss: 0.0346 - Train Accuracy: 71.12%\nEpoch 8/30 - Val Loss: 0.0236 - Val MAE: 0.1229 - Val CCC: 0.0740 - Val Accuracy: 80.86%\nEpoch 9/30 - Train Loss: 0.0337 - Train Accuracy: 71.80%\nEpoch 9/30 - Val Loss: 0.0235 - Val MAE: 0.1226 - Val CCC: 0.0995 - Val Accuracy: 80.73%\nEpoch 10/30 - Train Loss: 0.0337 - Train Accuracy: 71.89%\nEpoch 10/30 - Val Loss: 0.0227 - Val MAE: 0.1209 - Val CCC: 0.0944 - Val Accuracy: 81.35%\nEpoch 11/30 - Train Loss: 0.0321 - Train Accuracy: 72.95%\nEpoch 11/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0895 - Val Accuracy: 81.32%\nEpoch 12/30 - Train Loss: 0.0318 - Train Accuracy: 73.33%\nEpoch 12/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0905 - Val Accuracy: 81.47%\nEpoch 13/30 - Train Loss: 0.0319 - Train Accuracy: 73.03%\nEpoch 13/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0880 - Val Accuracy: 81.45%\nEpoch 14/30 - Train Loss: 0.0324 - Train Accuracy: 72.98%\nEpoch 14/30 - Val Loss: 0.0227 - Val MAE: 0.1208 - Val CCC: 0.0897 - Val Accuracy: 81.27%\nEpoch 15/30 - Train Loss: 0.0319 - Train Accuracy: 73.12%\nEpoch 15/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0917 - Val Accuracy: 81.36%\nEpoch 16/30 - Train Loss: 0.0318 - Train Accuracy: 73.22%\nEpoch 16/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0908 - Val Accuracy: 81.52%\nEpoch 17/30 - Train Loss: 0.0321 - Train Accuracy: 73.09%\nEpoch 17/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0859 - Val Accuracy: 81.36%\nEpoch 18/30 - Train Loss: 0.0320 - Train Accuracy: 73.08%\nEpoch 18/30 - Val Loss: 0.0224 - Val MAE: 0.1204 - Val CCC: 0.0844 - Val Accuracy: 81.32%\nEpoch 19/30 - Train Loss: 0.0318 - Train Accuracy: 73.32%\nEpoch 19/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0831 - Val Accuracy: 81.60%\nEpoch 20/30 - Train Loss: 0.0316 - Train Accuracy: 73.48%\nEpoch 20/30 - Val Loss: 0.0226 - Val MAE: 0.1207 - Val CCC: 0.0795 - Val Accuracy: 81.90%\nEpoch 21/30 - Train Loss: 0.0316 - Train Accuracy: 73.24%\nEpoch 21/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0815 - Val Accuracy: 81.36%\nEpoch 22/30 - Train Loss: 0.0313 - Train Accuracy: 73.67%\nEpoch 22/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0827 - Val Accuracy: 81.77%\nEpoch 23/30 - Train Loss: 0.0312 - Train Accuracy: 73.60%\nEpoch 23/30 - Val Loss: 0.0224 - Val MAE: 0.1202 - Val CCC: 0.0818 - Val Accuracy: 81.56%\nEpoch 24/30 - Train Loss: 0.0314 - Train Accuracy: 73.53%\nEpoch 24/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0818 - Val Accuracy: 81.56%\nEpoch 25/30 - Train Loss: 0.0322 - Train Accuracy: 72.91%\nEpoch 25/30 - Val Loss: 0.0224 - Val MAE: 0.1202 - Val CCC: 0.0824 - Val Accuracy: 81.56%\nEpoch 26/30 - Train Loss: 0.0316 - Train Accuracy: 73.47%\nEpoch 26/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0827 - Val Accuracy: 81.56%\nEpoch 27/30 - Train Loss: 0.0319 - Train Accuracy: 73.20%\nEpoch 27/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0832 - Val Accuracy: 81.56%\nEpoch 28/30 - Train Loss: 0.0317 - Train Accuracy: 73.30%\nEpoch 28/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0830 - Val Accuracy: 81.36%\nEpoch 29/30 - Train Loss: 0.0318 - Train Accuracy: 73.27%\nEpoch 29/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0844 - Val Accuracy: 81.56%\nEpoch 30/30 - Train Loss: 0.0320 - Train Accuracy: 72.97%\nEpoch 30/30 - Val Loss: 0.0224 - Val MAE: 0.1204 - Val CCC: 0.0836 - Val Accuracy: 81.36%\n\n=== Fold 3/3 ===\nEpoch 1/30 - Train Loss: 0.0591 - Train Accuracy: 59.10%\nEpoch 1/30 - Val Loss: 0.0237 - Val MAE: 0.1239 - Val CCC: 0.1250 - Val Accuracy: 80.14%\nEpoch 2/30 - Train Loss: 0.0454 - Train Accuracy: 64.73%\nEpoch 2/30 - Val Loss: 0.0234 - Val MAE: 0.1223 - Val CCC: 0.0920 - Val Accuracy: 80.84%\nEpoch 3/30 - Train Loss: 0.0419 - Train Accuracy: 66.63%\nEpoch 3/30 - Val Loss: 0.0231 - Val MAE: 0.1222 - Val CCC: 0.1316 - Val Accuracy: 80.64%\nEpoch 4/30 - Train Loss: 0.0401 - Train Accuracy: 67.66%\nEpoch 4/30 - Val Loss: 0.0248 - Val MAE: 0.1254 - Val CCC: 0.1022 - Val Accuracy: 79.84%\nEpoch 5/30 - Train Loss: 0.0379 - Train Accuracy: 69.37%\nEpoch 5/30 - Val Loss: 0.0240 - Val MAE: 0.1234 - Val CCC: 0.0923 - Val Accuracy: 80.15%\nEpoch 6/30 - Train Loss: 0.0367 - Train Accuracy: 69.78%\nEpoch 6/30 - Val Loss: 0.0238 - Val MAE: 0.1253 - Val CCC: 0.0870 - Val Accuracy: 79.60%\nEpoch 7/30 - Train Loss: 0.0362 - Train Accuracy: 70.08%\nEpoch 7/30 - Val Loss: 0.0226 - Val MAE: 0.1205 - Val CCC: 0.0717 - Val Accuracy: 81.58%\nEpoch 8/30 - Train Loss: 0.0362 - Train Accuracy: 70.10%\nEpoch 8/30 - Val Loss: 0.0225 - Val MAE: 0.1202 - Val CCC: 0.0861 - Val Accuracy: 81.37%\nEpoch 9/30 - Train Loss: 0.0349 - Train Accuracy: 70.98%\nEpoch 9/30 - Val Loss: 0.0223 - Val MAE: 0.1204 - Val CCC: 0.0888 - Val Accuracy: 81.33%\nEpoch 10/30 - Train Loss: 0.0336 - Train Accuracy: 71.88%\nEpoch 10/30 - Val Loss: 0.0224 - Val MAE: 0.1206 - Val CCC: 0.0779 - Val Accuracy: 81.65%\nEpoch 11/30 - Train Loss: 0.0330 - Train Accuracy: 72.27%\nEpoch 11/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0774 - Val Accuracy: 81.47%\nEpoch 12/30 - Train Loss: 0.0336 - Train Accuracy: 71.63%\nEpoch 12/30 - Val Loss: 0.0226 - Val MAE: 0.1206 - Val CCC: 0.0801 - Val Accuracy: 81.59%\nEpoch 13/30 - Train Loss: 0.0331 - Train Accuracy: 72.22%\nEpoch 13/30 - Val Loss: 0.0224 - Val MAE: 0.1203 - Val CCC: 0.0735 - Val Accuracy: 81.36%\nEpoch 14/30 - Train Loss: 0.0332 - Train Accuracy: 71.97%\nEpoch 14/30 - Val Loss: 0.0224 - Val MAE: 0.1204 - Val CCC: 0.0766 - Val Accuracy: 81.10%\nEpoch 15/30 - Train Loss: 0.0325 - Train Accuracy: 72.59%\nEpoch 15/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0764 - Val Accuracy: 81.19%\nEpoch 16/30 - Train Loss: 0.0329 - Train Accuracy: 72.76%\nEpoch 16/30 - Val Loss: 0.0224 - Val MAE: 0.1202 - Val CCC: 0.0805 - Val Accuracy: 81.23%\nEpoch 17/30 - Train Loss: 0.0327 - Train Accuracy: 72.58%\nEpoch 17/30 - Val Loss: 0.0225 - Val MAE: 0.1211 - Val CCC: 0.0697 - Val Accuracy: 81.80%\nEpoch 18/30 - Train Loss: 0.0326 - Train Accuracy: 72.45%\nEpoch 18/30 - Val Loss: 0.0224 - Val MAE: 0.1204 - Val CCC: 0.0730 - Val Accuracy: 81.36%\nEpoch 19/30 - Train Loss: 0.0321 - Train Accuracy: 72.87%\nEpoch 19/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0726 - Val Accuracy: 81.90%\nEpoch 20/30 - Train Loss: 0.0332 - Train Accuracy: 72.18%\nEpoch 20/30 - Val Loss: 0.0223 - Val MAE: 0.1201 - Val CCC: 0.0816 - Val Accuracy: 81.47%\nEpoch 21/30 - Train Loss: 0.0326 - Train Accuracy: 72.59%\nEpoch 21/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0804 - Val Accuracy: 81.58%\nEpoch 22/30 - Train Loss: 0.0328 - Train Accuracy: 72.46%\nEpoch 22/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0809 - Val Accuracy: 81.37%\nEpoch 23/30 - Train Loss: 0.0325 - Train Accuracy: 72.66%\nEpoch 23/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0807 - Val Accuracy: 81.24%\nEpoch 24/30 - Train Loss: 0.0319 - Train Accuracy: 73.15%\nEpoch 24/30 - Val Loss: 0.0224 - Val MAE: 0.1202 - Val CCC: 0.0808 - Val Accuracy: 81.23%\nEpoch 25/30 - Train Loss: 0.0324 - Train Accuracy: 72.84%\nEpoch 25/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0814 - Val Accuracy: 81.24%\nEpoch 26/30 - Train Loss: 0.0323 - Train Accuracy: 72.98%\nEpoch 26/30 - Val Loss: 0.0224 - Val MAE: 0.1202 - Val CCC: 0.0824 - Val Accuracy: 81.41%\nEpoch 27/30 - Train Loss: 0.0325 - Train Accuracy: 72.66%\nEpoch 27/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0823 - Val Accuracy: 81.24%\nEpoch 28/30 - Train Loss: 0.0324 - Train Accuracy: 73.02%\nEpoch 28/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0815 - Val Accuracy: 81.38%\nEpoch 29/30 - Train Loss: 0.0320 - Train Accuracy: 73.08%\nEpoch 29/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0809 - Val Accuracy: 81.36%\nEpoch 30/30 - Train Loss: 0.0321 - Train Accuracy: 72.98%\nEpoch 30/30 - Val Loss: 0.0223 - Val MAE: 0.1202 - Val CCC: 0.0812 - Val Accuracy: 81.36%\nConfig 5 Metrics - CCC: 0.1114, MAE: 0.1217, Loss: 0.0228, Accuracy: 80.96%\n\n=== Testing Config 6/20 ===\n{'embed_dim': 512, 'num_heads': 4, 'num_layers': 6, 'dropout': 0.1, 'lr': 3e-05, 'batch_size': 16, 'weight_decay': 0.0001}\n\n=== Fold 1/3 ===\nEpoch 1/30 - Train Loss: 0.0305 - Train Accuracy: 74.46%\nEpoch 1/30 - Val Loss: 0.0231 - Val MAE: 0.1225 - Val CCC: 0.0623 - Val Accuracy: 80.81%\nEpoch 2/30 - Train Loss: 0.0275 - Train Accuracy: 76.70%\nEpoch 2/30 - Val Loss: 0.0228 - Val MAE: 0.1217 - Val CCC: 0.0492 - Val Accuracy: 81.02%\nEpoch 3/30 - Train Loss: 0.0264 - Train Accuracy: 77.68%\nEpoch 3/30 - Val Loss: 0.0227 - Val MAE: 0.1214 - Val CCC: 0.0410 - Val Accuracy: 80.72%\nEpoch 4/30 - Train Loss: 0.0260 - Train Accuracy: 77.96%\nEpoch 4/30 - Val Loss: 0.0225 - Val MAE: 0.1206 - Val CCC: 0.0811 - Val Accuracy: 81.31%\nEpoch 5/30 - Train Loss: 0.0254 - Train Accuracy: 78.33%\nEpoch 5/30 - Val Loss: 0.0225 - Val MAE: 0.1207 - Val CCC: 0.0801 - Val Accuracy: 81.25%\nEpoch 6/30 - Train Loss: 0.0255 - Train Accuracy: 78.29%\nEpoch 6/30 - Val Loss: 0.0229 - Val MAE: 0.1210 - Val CCC: 0.0680 - Val Accuracy: 81.30%\nEpoch 7/30 - Train Loss: 0.0251 - Train Accuracy: 78.81%\nEpoch 7/30 - Val Loss: 0.0226 - Val MAE: 0.1212 - Val CCC: 0.0694 - Val Accuracy: 80.99%\nEpoch 8/30 - Train Loss: 0.0249 - Train Accuracy: 78.76%\nEpoch 8/30 - Val Loss: 0.0225 - Val MAE: 0.1208 - Val CCC: 0.0644 - Val Accuracy: 81.02%\nEpoch 9/30 - Train Loss: 0.0247 - Train Accuracy: 79.00%\nEpoch 9/30 - Val Loss: 0.0231 - Val MAE: 0.1229 - Val CCC: 0.0531 - Val Accuracy: 80.48%\nEpoch 10/30 - Train Loss: 0.0248 - Train Accuracy: 79.08%\nEpoch 10/30 - Val Loss: 0.0229 - Val MAE: 0.1210 - Val CCC: 0.0789 - Val Accuracy: 81.07%\nEpoch 11/30 - Train Loss: 0.0245 - Train Accuracy: 79.31%\nEpoch 11/30 - Val Loss: 0.0226 - Val MAE: 0.1205 - Val CCC: 0.0702 - Val Accuracy: 81.59%\nEpoch 12/30 - Train Loss: 0.0243 - Train Accuracy: 79.42%\nEpoch 12/30 - Val Loss: 0.0227 - Val MAE: 0.1206 - Val CCC: 0.0691 - Val Accuracy: 81.34%\nEpoch 13/30 - Train Loss: 0.0243 - Train Accuracy: 79.46%\nEpoch 13/30 - Val Loss: 0.0227 - Val MAE: 0.1206 - Val CCC: 0.0717 - Val Accuracy: 81.23%\nEpoch 14/30 - Train Loss: 0.0242 - Train Accuracy: 79.62%\nEpoch 14/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0704 - Val Accuracy: 81.40%\nEpoch 15/30 - Train Loss: 0.0242 - Train Accuracy: 79.49%\nEpoch 15/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0664 - Val Accuracy: 81.37%\nEpoch 16/30 - Train Loss: 0.0242 - Train Accuracy: 79.70%\nEpoch 16/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0680 - Val Accuracy: 81.14%\nEpoch 17/30 - Train Loss: 0.0241 - Train Accuracy: 79.67%\nEpoch 17/30 - Val Loss: 0.0227 - Val MAE: 0.1206 - Val CCC: 0.0775 - Val Accuracy: 81.77%\nEpoch 18/30 - Train Loss: 0.0243 - Train Accuracy: 79.49%\nEpoch 18/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0700 - Val Accuracy: 81.48%\nEpoch 19/30 - Train Loss: 0.0244 - Train Accuracy: 79.38%\nEpoch 19/30 - Val Loss: 0.0225 - Val MAE: 0.1206 - Val CCC: 0.0728 - Val Accuracy: 81.48%\nEpoch 20/30 - Train Loss: 0.0242 - Train Accuracy: 79.51%\nEpoch 20/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0730 - Val Accuracy: 81.60%\nEpoch 21/30 - Train Loss: 0.0239 - Train Accuracy: 79.82%\nEpoch 21/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0715 - Val Accuracy: 81.60%\nEpoch 22/30 - Train Loss: 0.0242 - Train Accuracy: 79.39%\nEpoch 22/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0717 - Val Accuracy: 81.37%\nEpoch 23/30 - Train Loss: 0.0240 - Train Accuracy: 79.78%\nEpoch 23/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0715 - Val Accuracy: 81.37%\nEpoch 24/30 - Train Loss: 0.0242 - Train Accuracy: 79.63%\nEpoch 24/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0712 - Val Accuracy: 81.59%\nEpoch 25/30 - Train Loss: 0.0242 - Train Accuracy: 79.57%\nEpoch 25/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0715 - Val Accuracy: 81.37%\nEpoch 26/30 - Train Loss: 0.0242 - Train Accuracy: 79.61%\nEpoch 26/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0713 - Val Accuracy: 81.37%\nEpoch 27/30 - Train Loss: 0.0241 - Train Accuracy: 79.65%\nEpoch 27/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0710 - Val Accuracy: 81.37%\nEpoch 28/30 - Train Loss: 0.0241 - Train Accuracy: 79.50%\nEpoch 28/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0725 - Val Accuracy: 81.37%\nEpoch 29/30 - Train Loss: 0.0240 - Train Accuracy: 79.76%\nEpoch 29/30 - Val Loss: 0.0225 - Val MAE: 0.1205 - Val CCC: 0.0713 - Val Accuracy: 81.37%\nEpoch 30/30 - Train Loss: 0.0242 - Train Accuracy: 79.57%\nEpoch 30/30 - Val Loss: 0.0225 - Val MAE: 0.1204 - Val CCC: 0.0717 - Val Accuracy: 81.37%\n\n=== Fold 2/3 ===\nEpoch 1/30 - Train Loss: 0.0298 - Train Accuracy: 75.05%\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Train final model with best config\ndef train_final_model(best_config, full_train_features, full_train_labels, test_features, test_labels, threshold=0.2):\n    final_model = MultimodalTransformer(\n        input_dims=input_dims,\n        embed_dim=best_config[\"embed_dim\"],\n        num_heads=best_config[\"num_heads\"],\n        num_layers=best_config[\"num_layers\"],\n        dropout=best_config[\"dropout\"]\n    ).to(device)\n\n    optimizer = optim.AdamW(final_model.parameters(), lr=best_config[\"lr\"], weight_decay=best_config[\"weight_decay\"])\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n\n    # Train on full dataset\n    train_loader = DataLoader(MultimodalDataset(full_train_features, full_train_labels),\n                             batch_size=int(best_config[\"batch_size\"]), shuffle=True)\n\n    for epoch in range(50):\n        train_loss, train_accuracy = train_model(final_model, train_loader, optimizer, scheduler, criterion, device, threshold)\n        print(f\"Epoch {epoch+1}/50 - Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.2%}\")\n\n    # Evaluate on test set\n    test_loader = DataLoader(MultimodalDataset(test_features, test_labels), batch_size=int(best_config[\"batch_size\"]), shuffle=False)\n    test_loss, test_mae, test_ccc, test_accuracy = evaluate(final_model, test_loader, criterion, device, threshold)\n    print(f\"\\nFinal Test Performance:\")\n    print(f\"CCC: {test_ccc:.4f}, MAE: {test_mae:.4f}, Accuracy: {test_accuracy:.2%}\")\n\n    # Save final model\n    torch.save(final_model.state_dict(), \"tuned_MMTV.pth\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_final_model(best_config, full_train_features, full_train_labels, test_features, test_labels, threshold=0.2)","metadata":{"id":"FL-2DGmW4QEH","trusted":true,"execution":{"execution_failed":"2025-03-17T03:45:42.681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nDone\"*10)","metadata":{"id":"cVd8lAtP4SfV","trusted":true,"execution":{"execution_failed":"2025-03-17T03:45:42.681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"7qBzI4nT5Lf8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"wJiDIVfnar0V"},"outputs":[],"execution_count":null}]}